Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@inproceedings{Manashty2017,
address = {New York, New York, USA},
author = {Manashty, Alireza and Thomson, Janet Light},
booktitle = {Proceedings of the 21st International Database Engineering {\&} Applications Symposium on - IDEAS 2017},
doi = {10.1145/3105831.3105858},
file = {:Users/na399/GitHub/thesis/references/papers/Manashty, Thomson{\_}2017{\_}A New Temporal Abstraction for Health Diagnosis Prediction using Deep Recurrent Networks{\_}Proceedings of the 21st.pdf:pdf},
isbn = {9781450352208},
keywords = {deep learning,diagnosis,healthcare,prediction,rank:n/a,relevancy:C,temporal},
mendeley-tags = {rank:n/a,relevancy:C},
pages = {14--19},
publisher = {ACM Press},
title = {{A New Temporal Abstraction for Health Diagnosis Prediction using Deep Recurrent Networks}},
url = {http://dl.acm.org/citation.cfm?doid=3105831.3105858},
year = {2017}
}
@article{Zhao2011,
abstract = {In this paper, we propose a novel method that combines PubMed knowledge and Electronic Health Records to develop a weighted Bayesian Network Inference (BNI) model for pancreatic cancer prediction. We selected 20 common risk factors associated with pancreatic cancer and used PubMed knowledge to weigh the risk factors. A keyword-based algorithm was developed to extract and classify PubMed abstracts into three categories that represented positive, negative, or neutral associations between each risk factor and pancreatic cancer. Then we designed a weighted BNI model by adding the normalized weights into a conventional BNI model. We used this model to extract the EHR values for patients with or without pancreatic cancer, which then enabled us to calculate the prior probabilities for the 20 risk factors in the BNI. The software iDiagnosis was designed to use this weighted BNI model for predicting pancreatic cancer. In an evaluation using a case-control dataset, the weighted BNI model significantly outperformed the conventional BNI and two other classifiers (k-Nearest Neighbor and Support Vector Machine). We conclude that the weighted BNI using PubMed knowledge and EHR data shows remarkable accuracy improvement over existing representative methods for pancreatic cancer prediction.},
author = {Zhao, Di and Weng, Chunhua},
doi = {10.1016/j.jbi.2011.05.004},
file = {:Users/na399/GitHub/thesis/references/papers/Zhao, Weng{\_}2011{\_}Combining PubMed knowledge and EHR data to develop a weighted bayesian network for pancreatic cancer prediction{\_}Journal.pdf:pdf},
isbn = {1532-0480},
issn = {1532-0480},
journal = {Journal of biomedical informatics},
keywords = {Bayesian method,Electronic Health Records,Pancreatic neoplasms,Text mining,disease:cancer,model:Bayesian,rank:85,relevancy:A,topic:EHR,topic:prediction,type:research},
mendeley-tags = {rank:85,type:research,topic:prediction,topic:EHR,relevancy:A,model:Bayesian,disease:cancer},
month = {oct},
number = {5},
pages = {859--68},
pmid = {21642013},
publisher = {Elsevier Inc.},
title = {{Combining PubMed knowledge and EHR data to develop a weighted bayesian network for pancreatic cancer prediction.}},
url = {http://dx.doi.org/10.1016/j.jbi.2011.05.004 http://linkinghub.elsevier.com/retrieve/pii/S1532046411000955 http://www.ncbi.nlm.nih.gov/pubmed/21642013 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3174321},
volume = {44},
year = {2011}
}
@article{Romero2014,
abstract = {Previous studies have shown that dementia is frequently omitted as a cause of death from the death certificate in patients with long-standing dementia. However, most studies exclude those undiagnosed dementia sufferers in the population. In order to overcome this problem, it is necessary to examine all the participants or to screen the population for symptoms of dementia and confirm the diagnosis with a clinical examination (two-phase approach). We used this latter methodology to estimate the proportion of reporting of dementia on death certificates in a prospective population-based study (NEDICES), involving 4,197 elderly people. Community-dwelling subjects with and without dementia were identified and followed during a median of 12.5 years, after which the death certificates of those who deceased were examined. A total of 1,976 (47.1{\%}) died (403 subjects with dementia). Dementia was rarely reported as the primary cause of death, even in known cases of dementia (20.8{\%}). Indeed it was reported in only 13.3{\%} of those with mild dementia and 24.3{\%} of those with moderate or severe dementia; in 24.9{\%} of those with possible or probable Alzheimer's disease; and in 11.9{\%} of those with non-Alzheimer dementia. In a stepwise multiple logistic regression analysis with the dependent variable being presence or absence of dementia on the death certificate, the significant associated independent variables were age at death, severity of dementia, and etiology of dementia. We conclude that reporting of dementia on death certificates remains poor. This suggests a lack of awareness of the importance of dementia as a cause of death.},
author = {Romero, Juan Pablo and Benito-Le{\'{o}}n, Juli{\'{a}}n and Mitchell, Alex J. and Trincado, Roc{\'{i}}o and Bermejo-Pareja, F{\'{e}}lix},
doi = {10.3233/JAD-131622},
file = {:Users/na399/GitHub/thesis/references/papers/Romero et al.{\_}2014{\_}Under reporting of dementia deaths on death certificates using data from a population-based study (NEDICES){\_}Journal o.pdf:pdf},
isbn = {1875-8908 (Electronic)$\backslash$r1387-2877 (Linking)},
issn = {13872877},
journal = {Journal of Alzheimer's Disease},
keywords = {Death certificates,dementia,disease:dementia,elderly,epidemiology,model:logisticRegression,population-based study,rank:95,relevancy:B,topic:diagnosis,type:research,underreporting},
mendeley-tags = {disease:dementia,model:logisticRegression,rank:95,relevancy:B,topic:diagnosis,type:research},
number = {4},
pages = {741--748},
pmid = {24254704},
title = {{Under reporting of dementia deaths on death certificates using data from a population-based study (NEDICES)}},
volume = {39},
year = {2014}
}
@article{Hohman2016,
abstract = {Late-onset Alzheimer disease (AD) has a complex genetic etiology, involving locus heterogeneity, polygenic inheritance, and gene-gene interactions; however, the investigation of interactions in recent genome-wide association studies has been limited. We used a biological knowledge-driven approach to evaluate gene-gene interactions for consistency across 13 data sets from the Alzheimer Disease Genetics Consortium. Fifteen single nucleotide polymorphism (SNP)-SNP pairs within 3 gene-gene combinations were identified: SIRT1 × ABCB1, PSAP × PEBP4, and GRIN2B × ADRA1A. In addition, we extend a previously identified interaction from an endophenotype analysis between RYR3 × CACNA1C. Finally, post hoc gene expression analyses of the implicated SNPs further implicate SIRT1 and ABCB1, and implicate CDH23 which was most recently identified as an AD risk locus in an epigenetic analysis of AD. The observed interactions in this article highlight ways in which genotypic variation related to disease may depend on the genetic context in which it occurs. Further, our results highlight the utility of evaluating genetic interactions to explain additional variance in AD risk and identify novel molecular mechanisms of AD pathogenesis.},
author = {Hohman, Timothy J. and Bush, William S. and Jiang, Lan and Brown-Gentry, Kristin D. and Torstenson, Eric S. and Dudek, Scott M. and Mukherjee, Shubhabrata and Naj, Adam and Kunkle, Brian W. and Ritchie, Marylyn D. and Martin, Eden R. and Schellenberg, Gerard D. and Mayeux, Richard and Farrer, Lindsay A. and Pericak-Vance, Margaret A. and Haines, Jonathan L. and Thornton-Wells, Tricia A.},
doi = {10.1016/j.neurobiolaging.2015.10.031},
file = {:Users/na399/GitHub/thesis/references/papers/Hohman et al.{\_}2016{\_}Discovery of gene-gene interactions across multiple independent data sets of late onset Alzheimer disease from the Al.pdf:pdf},
isbn = {1558-1497 (Electronic)$\backslash$r0197-4580 (Linking)},
issn = {15581497},
journal = {Neurobiology of Aging},
keywords = {Alzheimer disease,Biofilter,Epistasis,Gene-gene interactions,disease:dementia,rank:95,relevancy:C,topic:GWAS,topic:bioinformatics,type:research},
mendeley-tags = {disease:dementia,rank:95,relevancy:C,topic:GWAS,topic:bioinformatics,type:research},
pages = {141--150},
pmid = {26827652},
publisher = {Elsevier Inc},
title = {{Discovery of gene-gene interactions across multiple independent data sets of late onset Alzheimer disease from the Alzheimer Disease Genetics Consortium}},
url = {http://dx.doi.org/10.1016/j.neurobiolaging.2015.10.031},
volume = {38},
year = {2016}
}
@article{Guo2018,
abstract = {Event sequence data such as electronic health records, a person's academic records, or car service records, are ordered series of events which have occurred over a period of time. Analyzing collections of event sequences can reveal common or semantically important sequential patterns. For example, event sequence analysis might reveal frequently used care plans for treating a disease, typical publishing patterns of professors, and the patterns of service that result in a well-maintained car. It is challenging, however, to visually explore large numbers of event sequences, or sequences with large numbers of event types. Existing methods focus on extracting explicitly matching patterns of events using statistical analysis to create stages of event progression over time. However, these methods fail to capture latent clusters of similar but not identical evolutions of event sequences. In this paper, we introduce a novel visualization system named EventThread which clusters event sequences into threads based on tensor analysis and visualizes the latent stage categories and evolution patterns by interactively grouping the threads by similarity into time-specific clusters. We demonstrate the effectiveness of EventThread through usage scenarios in three different application domains and via interviews with an expert user.},
author = {Guo, Shunan and Xu, Ke and Zhao, Rongwen and Gotz, David and Zha, Hongyuan and Cao, Nan},
doi = {10.1109/TVCG.2017.2745320},
file = {:Users/na399/GitHub/thesis/references/papers/Guo et al.{\_}2018{\_}EventThread Visual Summarization and Stage Analysis of Event Sequence Data{\_}IEEE Transactions on Visualization and Comput.pdf:pdf},
isbn = {1077-2626 VO - PP},
issn = {10772626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Data Clustering,Illustrative Visualization,Time Series Data,Visual Knowledge Discovery,Visual Knowledge Representation,rank:90,relevancy:C,topic:visualisation,type:method},
mendeley-tags = {rank:90,relevancy:C,topic:visualisation,type:method},
number = {1},
pages = {56--65},
pmid = {28866586},
title = {{EventThread: Visual Summarization and Stage Analysis of Event Sequence Data}},
volume = {24},
year = {2018}
}
@article{Smits2015,
abstract = {BACKGROUND: To investigate trajectories of cognitive decline in patients with different types of dementia compared to controls in a longitudinal study.$\backslash$n$\backslash$nMETHOD: In 199 patients with Alzheimer's disease (AD), 10 with vascular dementia (VaD), 26 with dementia with Lewy bodies (DLB), 20 with behavioural variant frontotemporal dementia (bvFTD), 15 with language variant frontotemporal dementia (lvFTD) and 112 controls we assessed five cognitive domains: memory, language, attention, executive and visuospatial functioning, and global cognition (Mini-Mental State Examination, MMSE). All subjects had at least two neuropsychological assessments (median 2, range 2-7). Neuropsychological data were standardized into z scores using baseline performance of controls as reference. Linear mixed models (LMMs) were used to estimate baseline cognitive functioning and cognitive decline over time for each group, adjusted for age, gender and education.$\backslash$n$\backslash$nRESULTS: At baseline, patients with dementia performed worse than controls in all cognitive domains (p {\textless} 0.05) except visuospatial functioning, which was only impaired in patients with AD and DLB (p {\textless} 0.001). During follow-up, patients with AD declined in all cognitive domains (p {\textless} 0.001). DLB showed decline in every cognitive domain except language and global cognition. bvFTD showed rapid decline in memory, language, attention and executive functioning (all p {\textless} 0.01) whereas visuospatial functioning remained fairly stable. lvFTD declined mostly in attention and executive functioning (p {\textless} 0.01). VaD showed decline in attention and executive functioning.$\backslash$n$\backslash$nCONCLUSIONS: We show cognitive trajectories of different types of dementia. These estimations of natural disease course have important value for the design of clinical trials as neuropsychological measures are increasingly being used as outcome measures.},
author = {Smits, L. L. and van Harten, A. C. and Pijnenburg, Y. A L and Koedam, E. L G E and Bouwman, F. H. and Sistermans, N. and Reuling, I. E W and Prins, N. D. and Lemstra, A. W. and Scheltens, P. and van der Flier, W. M.},
doi = {10.1017/S0033291714002153},
file = {:Users/na399/GitHub/thesis/references/papers/Smits et al.{\_}2015{\_}Trajectories of cognitive decline in different types of dementia{\_}Psychological Medicine.pdf:pdf},
isbn = {0033-2917},
issn = {0033-2917},
journal = {Psychological Medicine},
keywords = {Alzheimer's disease,behavioural variant frontotemporal dementia,cognitive decline,cognitive neuropsychology,dementia with Lewy bodies,disease:dementia,language variant frontotemporal dementia,longitudinal design,model:frequentist,rank:99,relevancy:A,topic:progression,type:research,vascular dementia},
mendeley-tags = {disease:dementia,model:frequentist,rank:99,relevancy:A,topic:progression,type:research},
month = {apr},
number = {05},
pages = {1051--1059},
pmid = {25229325},
title = {{Trajectories of cognitive decline in different types of dementia}},
url = {http://www.journals.cambridge.org/abstract{\_}S0033291714002153},
volume = {45},
year = {2015}
}
@article{Wen2016,
abstract = {Dementia is one of the most disabling and burdensome health conditions worldwide. In this study, we identified new potential risk factors for dementia from nationwide longitudinal population-based data by using Bayesian statistics.We first tested the consistency of the results obtained using Bayesian statistics with those obtained using classical frequentist probability for 4 recognized risk factors for dementia, namely severe head injury, depression, diabetes mellitus, and vascular diseases. Then, we used Bayesian statistics to verify 2 new potential risk factors for dementia, namely hearing loss and senile cataract, determined from the Taiwan's National Health Insurance Research Database.We included a total of 6546 (6.0{\%}) patients diagnosed with dementia. We observed older age, female sex, and lower income as independent risk factors for dementia. Moreover, we verified the 4 recognized risk factors for dementia in the older Taiwanese population; their odds ratios (ORs) ranged from 3.469 to 1.207. Furthermore, we observed that hearing loss (OR = 1.577) and senile cataract (OR = 1.549) were associated with an increased risk of dementia.We found that the results obtained using Bayesian statistics for assessing risk factors for dementia, such as head injury, depression, DM, and vascular diseases, were consistent with those obtained using classical frequentist probability. Moreover, hearing loss and senile cataract were found to be potential risk factors for dementia in the older Taiwanese population. Bayesian statistics could help clinicians explore other potential risk factors for dementia and for developing appropriate treatment strategies for these patients.},
author = {Wen, Yen-Hsia and Wu, Shihn-Sheng and Lin, Chun-Hung Richard and Tsai, Jui-Hsiu and Yang, Pinchen and Chang, Yang-Pei and Tseng, Kuan-Hua},
doi = {10.1097/MD.0000000000003658},
file = {:Users/na399/GitHub/thesis/references/papers/Wen et al.{\_}2016{\_}A Bayesian Approach to Identifying New Risk Factors for Dementia{\_}Medicine.pdf:pdf},
isbn = {0000000000},
issn = {0025-7974},
journal = {Medicine},
keywords = {disease:dementia,model:Bayesian,rank:70,relevancy:A,topic:prediction,type:research},
mendeley-tags = {rank:70,relevancy:A,disease:dementia,model:Bayesian,topic:prediction,type:research},
month = {may},
number = {21},
pages = {e3658},
pmid = {27227925},
title = {{A Bayesian Approach to Identifying New Risk Factors for Dementia}},
url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage{\&}an=00005792-201605240-00018},
volume = {95},
year = {2016}
}
@article{Denny2012,
abstract = {The combination of improved genomic analysis methods, decreasing genotyping costs, and increasing computing resources has led to an explosion of clinical genomic knowledge in the last decade. Similarly, healthcare systems are increasingly adopting robust electronic health record (EHR) systems that not only can improve health care, but also contain a vast repository of disease and treatment data that could be mined for genomic research. Indeed, institutions are creating EHR-linked DNA biobanks to enable genomic and pharmacogenomic research, using EHR data for phenotypic information. However, EHRs are designed primarily for clinical care, not research, so reuse of clinical EHR data for research purposes can be challenging. Difficulties in use of EHR data include: data availability, missing data, incorrect data, and vast quantities of unstructured narrative text data. Structured information includes billing codes, most laboratory reports, and other variables such as physiologic measurements and demographic information. Significant information, however, remains locked within EHR narrative text documents, including clinical notes and certain categories of test results, such as pathology and radiology reports. For relatively rare observations, combinations of simple free-text searches and billing codes may prove adequate when followed by manual chart review. However, to extract the large cohorts necessary for genome-wide association studies, natural language processing methods to process narrative text data may be needed. Combinations of structured and unstructured textual data can be mined to generate high-validity collections of cases and controls for a given condition. Once high-quality cases and controls are identified, EHR-derived cases can be used for genomic discovery and validation. Since EHR data includes a broad sampling of clinically-relevant phenotypic information, it may enable multiple genomic investigations upon a single set of genotyped individuals. This chapter reviews several examples of phenotype extraction and their application to genetic research, demonstrating a viable future for genomic discovery using EHR-linked data.},
author = {Denny, Joshua C.},
doi = {10.1371/journal.pcbi.1002823},
editor = {Lewitter, Fran and Kann, Maricel},
file = {:Users/na399/GitHub/thesis/references/papers/Denny{\_}2012{\_}Chapter 13 Mining Electronic Health Records in the Genomics Era{\_}PLoS Computational Biology.PDF:PDF},
isbn = {1553-7358},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {disease:general,rank:99,relevancy:A,topic:EHR,topic:bioinformatics,type:education},
mendeley-tags = {disease:general,rank:99,relevancy:A,topic:EHR,topic:bioinformatics,type:education},
month = {dec},
number = {12},
pages = {e1002823},
pmid = {23300414},
title = {{Chapter 13: Mining Electronic Health Records in the Genomics Era}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002823},
volume = {8},
year = {2012}
}
@article{Sylvestre2018,
abstract = {Medical coding is used for a variety of activities, from observational studies to hospital billing. However, comorbidities tend to be under-reported by medical coders. The aim of this study was to develop an algorithm to detect comorbidities in electronic health records (EHR) by using a clinical data warehouse (CDW) and a knowledge database. We enriched the Theriaque pharmaceutical database with the French national Comorbidities List to identify drugs associated with at least one major comorbid condition and diagnoses associated with a drug indication. Then, we compared the drug indications in the Theriaque database with the ICD-10 billing codes in EHR to detect potentially missing comorbidities based on drug prescriptions. Finally, we improved comorbidity detection by matching drug prescriptions and laboratory test results. We tested the obtained algorithm by using two retrospective datasets extracted from the Rennes University Hospital (RUH) CDW. The first dataset included all adult patients hospitalized in the ear, nose, throat (ENT) surgical ward between October and December 2014 (ENT dataset). The second included all adult patients hospitalized at RUH between January and February 2015 (general dataset). We reviewed medical records to find written evidence of the suggested comorbidities in current or past stays. Among the 22,132 Common Units of Dispensation (CUD) codes present in the Theriaque database, 19,970 drugs (90.2{\%}) were associated with one or several ICD-10 diagnoses, based on their indication, and 11,162 (50.4{\%}) with at least one of the 4878 comorbidities from the comorbidity list. Among the 122 patients of the ENT dataset, 75.4{\%} had at least one drug prescription without corresponding ICD-10 code. The comorbidity diagnoses suggested by the algorithm were confirmed in 44.6{\%} of the cases. Among the 4312 patients of the general dataset, 68.4{\%} had at least one drug prescription without corresponding ICD-10 code. The comorbidity diagnoses suggested by the algorithm were confirmed in 20.3{\%} of reviewed cases. This simple algorithm based on combining accessible and immediately reusable data from knowledge databases, drug prescriptions and laboratory test results can detect comorbidities.},
author = {Sylvestre, Emmanuelle and Bouzill{\'{e}}, Guillaume and Chazard, Emmanuel and His-Mahier, C{\'{e}}cil and Riou, Christine and Cuggia, Marc},
doi = {10.1186/s12911-018-0586-x},
file = {:Users/na399/GitHub/thesis/references/papers/Sylvestre et al.{\_}2018{\_}Combining information from a clinical data warehouse and a pharmaceutical database to generate a framework to dete.pdf:pdf},
isbn = {14726947 (Electronic)},
issn = {14726947},
journal = {BMC Medical Informatics and Decision Making},
keywords = {Billing codes,Clinical data warehouse,Comorbidity,Databases,Drug prescriptions,Laboratory test results,Pharmaceutical,rank:80,relevancy:C,topic:EHR,topic:comorbidity,type:research},
mendeley-tags = {rank:80,type:research,topic:EHR,topic:comorbidity,relevancy:C},
number = {1},
pages = {1--8},
pmid = {29368609},
publisher = {BMC Medical Informatics and Decision Making},
title = {{Combining information from a clinical data warehouse and a pharmaceutical database to generate a framework to detect comorbidities in electronic health records}},
volume = {18},
year = {2018}
}
@article{Choi2015,
abstract = {Leveraging large historical data in electronic health record (EHR), we developed Doctor AI, a generic predictive model that covers observed medical conditions and medication uses. Doctor AI is a temporal model using recurrent neural networks (RNN) and was developed and applied to longitudinal time stamped EHR data from 260K patients over 8 years. Encounter records (e.g. diagnosis codes, medication codes or procedure codes) were input to RNN to predict (all) the diagnosis and medication categories for a subsequent visit. Doctor AI assesses the history of patients to make multilabel predictions (one label for each diagnosis or medication category). Based on separate blind test set evaluation, Doctor AI can perform differential diagnosis with up to 79{\%} recall@30, significantly higher than several baselines. Moreover, we demonstrate great generalizability of Doctor AI by adapting the resulting models from one institution to another without losing substantial accuracy.},
archivePrefix = {arXiv},
arxivId = {1511.05942},
author = {Choi, Edward and Bahadori, Mohammad Taha and Schuetz, Andy and Stewart, Walter F and Sun, Jimeng},
doi = {10.1002/aur.1474.Replication},
eprint = {1511.05942},
file = {:Users/na399/GitHub/thesis/references/papers/Choi et al.{\_}2015{\_}Doctor AI Predicting Clinical Events via Recurrent Neural Networks{\_}Proceedings of Machine Learning for Healthcare 2016.pdf:pdf},
isbn = {0000000000000},
issn = {1938-7288 (Electronic)},
journal = {Proceedings of Machine Learning for Healthcare 2016 JMLR W{\&}C Track},
keywords = {rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
pages = {1--12},
pmid = {28286600},
title = {{Doctor AI: Predicting Clinical Events via Recurrent Neural Networks}},
url = {http://nematilab.info/bmijc/assets/170607{\_}paper.pdf{\%}0Ahttp://arxiv.org/abs/1511.05942},
volume = {56},
year = {2015}
}
@article{Pradhan1994,
abstract = {We present several techniques for knowledge engineering of large belief networks (BNs) based on the our experiences with a network derived from a large medical knowledge base. The noisyMAX, a generalization of the noisy-OR gate, is used to model causal in dependence in a BN with multi-valued variables. We describe the use of leak probabilities to enforce the closed-world assumption in our model. We present Netview, a visualization tool based on causal independence and the use of leak probabilities. The Netview software allows knowledge engineers to dynamically view sub-networks for knowledge engineering, and it provides version control for editing a BN. Netview generates sub-networks in which leak probabilities are dynamically updated to reflect the missing portions of the network.},
archivePrefix = {arXiv},
arxivId = {1302.6839},
author = {Pradhan, Malcolm and Provan, Gregory M. and Middleton, Blackford and Henrion, Max},
eprint = {1302.6839},
file = {:Users/na399/GitHub/thesis/references/papers/Pradhan et al.{\_}1994{\_}Knowledge Engineering for Large Belief Networks{\_}Proceedings of the Tenth Conference on Uncertainty in Artificial Int.pdf:pdf},
isbn = {1-55860-332-8},
journal = {Proceedings of the Tenth Conference on Uncertainty in Artificial Intelligence (UAI1994)},
keywords = {rank:n/a,relevancy:A},
mendeley-tags = {rank:n/a,relevancy:A},
month = {feb},
pages = {484--490},
title = {{Knowledge Engineering for Large Belief Networks}},
url = {http://arxiv.org/abs/1302.6839},
year = {2013}
}
@article{Hripcsak2017,
author = {Hripcsak, George and Albers, David J},
doi = {10.1093/jamia/ocx110},
file = {:Users/na399/GitHub/thesis/references/papers/Hripcsak, Albers{\_}2018{\_}High-fidelity phenotyping richness and freedom from bias{\_}Journal of the American Medical Informatics Association.pdf:pdf},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
keywords = {rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:commentary},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:commentary},
month = {mar},
number = {3},
pages = {289--294},
title = {{High-fidelity phenotyping: richness and freedom from bias}},
url = {http://fdslive.oup.com/www.oup.com/pdf/production{\_}in{\_}progress.pdf https://academic.oup.com/jamia/article/25/3/289/4484121},
volume = {25},
year = {2018}
}
@inproceedings{Dai2016,
abstract = {{\textcopyright} 2016 IEEE.Healthcare is a complex process. It is difficult to choose an effective strategy from numerous possible treatment courses. Whether a healthcare strategy is good or bad? The statistic evidence of instances can tell the truth. Recently, many models of machine learning can handle the static data sets well. They usually use classification methods for disease diagnosis, which relates features to diseases. However, few data sets comprise healthcare processes, and few models relate healthcare actions to healthcare results. We propose a Bayesian inference graph for acquiring the experience of experts and the healthcare statistic evidence. We use a set of states to represent the physical condition of a person, and use a set of actions to represent the healthcare methods. Our aim is to build a probabilistic inference graph of each state transition, which shows the probability of a state transition through a certain action. The inference graph, like the experience of human beings, can be enriched. It begins from the prior experience, and then it will increase its knowledge by increasing evidential instances.},
author = {Dai, Yinglong and Jiang, Wenjun and Wang, Guojun},
booktitle = {2016 45th International Conference on Parallel Processing Workshops (ICPPW)},
doi = {10.1109/ICPPW.2016.65},
file = {:Users/na399/GitHub/thesis/references/papers/Dai, Jiang, Wang{\_}2016{\_}Building Bayesian Inference Graphs for Healthcare Statistic Evidence{\_}Proceedings of the International Conference o.pdf:pdf},
isbn = {978-1-5090-2825-2},
issn = {15302016},
keywords = {Dirichlet distribution,graphical model,healthcare,rank:n/a,relevancy:A,state transition,statistic evidence},
mendeley-tags = {rank:n/a,relevancy:A},
month = {aug},
pages = {415--420},
publisher = {IEEE},
title = {{Building Bayesian Inference Graphs for Healthcare Statistic Evidence}},
url = {http://ieeexplore.ieee.org/document/7576493/},
volume = {2016-Septe},
year = {2016}
}
@article{Stewart2016,
abstract = {PURPOSE 'Big data' are accumulating in a multitude of domains and offer novel opportunities for research. The role of these resources in mental health investigations remains relatively unexplored, although a number of datasets are in use and supporting a range of projects. We sought to review big data resources and their use in mental health research to characterise applications to date and consider directions for innovation in future. METHODS A narrative review. RESULTS Clear disparities were evident in geographic regions covered and in the disorders and interventions receiving most attention. DISCUSSION We discuss the strengths and weaknesses of the use of different types of data and the challenges of big data in general. Current research output from big data is still predominantly determined by the information and resources available and there is a need to reverse the situation so that big data platforms are more driven by the needs of clinical services and service users.},
author = {Stewart, Robert and Davis, Katrina},
doi = {10.1007/s00127-016-1266-8},
file = {:Users/na399/GitHub/thesis/references/papers/Stewart, Davis{\_}2016{\_}‘Big data' in mental health research current status and emerging possibilities{\_}Social Psychiatry and Psychiatric.pdf:pdf},
isbn = {0933-7954},
issn = {09337954},
journal = {Social Psychiatry and Psychiatric Epidemiology},
keywords = {Big data,Electronic health records,Epidemiology,Mental disorders,rank:90,relevancy:B,topic:EHR,type:review},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,type:review},
number = {8},
pages = {1055--1072},
pmid = {27465245},
publisher = {Springer Berlin Heidelberg},
title = {{‘Big data' in mental health research: current status and emerging possibilities}},
volume = {51},
year = {2016}
}
@article{Wang2015g,
abstract = {BACKGROUND Google Trends has demonstrated the capability to both monitor and predict epidemic outbreaks. The connection between Internet searches for dementia information and dementia incidence and dementia-related outpatient visits remains unknown. OBJECTIVE This study aimed to determine whether Google Trends could provide insight into trends in dementia incidence and related outpatient visits in Taiwan. We investigated and validated the local search terms that would be the best predictors of new dementia cases and outpatient visits. We further evaluated the nowcasting (ie, forecasting the present) and forecasting effects of Google Trends search trends for new dementia cases and outpatient visits. The long-term goal is to develop a surveillance system to help early detection and interventions for dementia in Taiwan. METHODS This study collected (1) dementia data from Taiwan's National Health Insurance Research Database and (2) local Internet search data from Google Trends, both from January 2009 to December 2011. We investigated and validated search terms that would be the best predictors of new dementia cases and outpatient visits. We then evaluated both the nowcasting and the forecasting effects of Google Trends search trends through cross-correlation analysis of the dementia incidence and outpatient visit data with the Google Trends data. RESULTS The search term "dementia + Alzheimer's disease" demonstrated a 3-month lead effect for new dementia cases and a 6-month lead effect for outpatient visits (r=.503, P=.002; r=.431, P=.009, respectively). When gender was included in the analysis, the search term "dementia" showed 6-month predictive power for new female dementia cases (r=.520, P=.001), but only a nowcasting effect for male cases (r=.430, P=.009). The search term "neurology" demonstrated a 3-month leading effect for new dementia cases (r=.433, P=.008), for new male dementia cases (r=.434, P=.008), and for outpatient visits (r=.613, P{\textless}.001). CONCLUSIONS Google Trends established a plausible relationship between search terms and new dementia cases and dementia-related outpatient visits in Taiwan. This data may allow the health care system in Taiwan to prepare for upcoming outpatient and dementia screening visits. In addition, the validated search term results can be used to provide caregivers with caregiving-related health, skills, and social welfare information by embedding dementia-related search keywords in relevant online articles.},
author = {Wang, Ho-Wei and Chen, Duan-Rung and Yu, Hsiao-Wei and Chen, Ya-Mei},
doi = {10.2196/jmir.4516},
file = {:Users/na399/GitHub/thesis/references/papers/Wang et al.{\_}2015{\_}Forecasting the Incidence of Dementia and Dementia-Related Outpatient Visits With Google Trends Evidence From Taiwan{\_}Jo.pdf:pdf},
isbn = {1438-8871 (Electronic)$\backslash$r1438-8871 (Linking)},
issn = {1438-8871},
journal = {Journal of Medical Internet Research},
keywords = {Alzheimer's disease,Google Trends,Internet search,big data,dementia,disease:dementia,early detection,health-seeking behaviors,incidence,model:correlation,rank:95,relevancy:C,self-diagnosis,topic:prediction,type:research},
mendeley-tags = {rank:95,type:research,topic:prediction,disease:dementia,model:correlation,relevancy:C},
month = {nov},
number = {11},
pages = {e264},
pmid = {26586281},
title = {{Forecasting the Incidence of Dementia and Dementia-Related Outpatient Visits With Google Trends: Evidence From Taiwan}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26586281 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4704919 http://www.jmir.org/2015/11/e264/},
volume = {17},
year = {2015}
}
@article{Jeong2017,
author = {Jeong, Eugene and Ko, Kyungmin and Oh, Seungbin and Han, Hyun Wook},
doi = {10.1038/s41598-017-15647-4},
file = {:Users/na399/GitHub/thesis/references/papers/Jeong et al.{\_}2017{\_}Network-based analysis of diagnosis progression patterns using claims data{\_}Scientific Reports.pdf:pdf},
isbn = {4159801715647},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {disease:general,model:network,rank:95,relevancy:A,topic:EHR,topic:prediction,topic:progression,type:research},
mendeley-tags = {disease:general,model:network,rank:95,relevancy:A,topic:EHR,topic:prediction,topic:progression,type:research},
month = {dec},
number = {1},
pages = {15561},
publisher = {Springer US},
title = {{Network-based analysis of diagnosis progression patterns using claims data}},
url = {http://dx.doi.org/10.1038/s41598-017-15647-4 http://www.nature.com/articles/s41598-017-15647-4},
volume = {7},
year = {2017}
}
@article{Lappenschaar2013,
abstract = {Objective: Large health care datasets normally have a hierarchical structure, in terms of levels, as the data have been obtained from different practices, hospitals, or regions. Multilevel regression is the technique commonly used to deal with such multilevel data. However, for the statistical analysis of interactions between entities from a domain, multilevel regression yields little to no insight. While Bayesian networks have proved to be useful for analysis of interactions, they do not have the capability to deal with hierarchical data. In this paper, we describe a new formalism, which we call multilevel Bayesian networks; its effectiveness for the analysis of hierarchically structured health care data is studied from the perspective of multimorbidity. Methods: Multilevel Bayesian networks are formally defined and applied to analyze clinical data from family practices in The Netherlands with the aim to predict interactions between heart failure and diabetes mellitus. We compare the results obtained with multilevel regression. Results: The results obtained by multilevel Bayesian networks closely resembled those obtained by multilevel regression. For both diseases, the area under the curve of the prediction model improved, and the net reclassification improvements were significantly positive. In addition, the models offered considerable more insight, through its internal structure, into the interactions between the diseases. Conclusions: Multilevel Bayesian networks offer a suitable alternative to multilevel regression when analyzing hierarchical health care data. They provide more insight into the interactions between multiple diseases. Moreover, a multilevel Bayesian network model can be used for the prediction of the occurrence of multiple diseases, even when some of the predictors are unknown, which is typically the case in medicine. {\textcopyright} 2013 Elsevier B.V.},
author = {Lappenschaar, Martijn and Hommersom, Arjen and Lucas, Peter J.F. and Lagro, Joep and Visscher, Stefan},
doi = {10.1016/j.artmed.2012.12.007},
file = {:Users/na399/GitHub/thesis/references/papers/Lappenschaar et al.{\_}2013{\_}Multilevel Bayesian networks for the analysis of hierarchical health care data{\_}Artificial Intelligence in Medic.pdf:pdf},
issn = {09333657},
journal = {Artificial Intelligence in Medicine},
keywords = {Bayesian network,Cardiovascular disease,Disease prediction,Inter-practice variation,Multilevel analysis,Multimorbidity,model:Bayesian,rank:70,relevancy:A},
mendeley-tags = {rank:70,relevancy:A,model:Bayesian},
number = {3},
pages = {171--183},
pmid = {23419697},
publisher = {Elsevier B.V.},
title = {{Multilevel Bayesian networks for the analysis of hierarchical health care data}},
url = {http://dx.doi.org/10.1016/j.artmed.2012.12.007},
volume = {57},
year = {2013}
}
@article{Aubry2015,
abstract = {Alzheimer's disease (AD) is a complex multifactorial disorder with poorly characterized pathogenesis. Our understanding of this disease would thus benefit from an approach that addresses this complexity by elucidating the regulatory networks that are dysregulated in the neural compartment of AD patients, across distinct brain regions. Here, we use a Systems Biology (SB) approach, which has been highly successful in the dissection of cancer related phenotypes, to reverse engineer the transcriptional regulation layer of human neuronal cells and interrogate it to infer candidate Master Regulators (MRs) responsible for disease progression. Analysis of gene expression profiles from laser-captured neurons from AD and controls subjects, using the Algorithm for the Reconstruction of Accurate Cellular Networks (ARACNe), yielded an interactome consisting of 488,353 transcription-factor/target interactions. Interrogation of this interactome, using the Master Regulator INference algorithm (MARINa), identified an unbiased set of candidate MRs causally responsible for regulating the transcriptional signature of AD progression. Experimental assays in autopsy-derived human brain tissue showed that three of the top candidate MRs (YY1, p300 and ZMYM3) are indeed biochemically and histopathologically dysregulated in AD brains compared to controls. Our results additionally implicate p53 and loss of acetylation homeostasis in the neurodegenerative process. This study suggests that an integrative, SB approach can be applied to AD and other neurodegenerative diseases, and provide significant novel insight on the disease progression.},
author = {Aubry, Soline and Shin, William and Crary, John F. and Lefort, Roger and Qureshi, Yasir H. and Lefebvre, Celine and Califano, Andrea and Shelanski, Michael L.},
doi = {10.1371/journal.pone.0120352},
editor = {Iijima, Koichi M},
file = {:Users/na399/GitHub/thesis/references/papers/Aubry et al.{\_}2015{\_}Assembly and interrogation of Alzheimer's disease genetic networks reveal novel regulators of progression{\_}PLoS ONE.PDF:PDF},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {disease:dementia,rank:90,relevancy:C,topic:bioinformatics,type:research},
mendeley-tags = {disease:dementia,rank:90,relevancy:C,topic:bioinformatics,type:research},
month = {mar},
number = {3},
pages = {e0120352},
pmid = {25781952},
title = {{Assembly and Interrogation of Alzheimer's Disease Genetic Networks Reveal Novel Regulators of Progression}},
url = {http://dx.plos.org/10.1371/journal.pone.0120352},
volume = {10},
year = {2015}
}
@article{Yu2018,
abstract = {Objective: Electronic health record (EHR)-based phenotyping infers whether a patient has a disease based on the information in his or her EHR. A human-annotated training set with gold-standard disease status labels is usually required to build an algorithm for phenotyping based on a set of predictive features. The time intensive-ness of annotation and feature curation severely limits the ability to achieve high-throughput phenotyping. While previous studies have successfully automated feature curation, annotation remains a major bottleneck. In this paper, we present PheNorm, a phenotyping algorithm that does not require expert-labeled samples for training. Methods: The most predictive features, such as the number of International Classification of Diseases, Ninth Re-vision, Clinical Modification (ICD-9-CM) codes or mentions of the target phenotype, are normalized to resemble a normal mixture distribution with high area under the receiver operating curve (AUC) for prediction. The trans-formed features are then denoised and combined into a score for accurate disease classification. Results: We validated the accuracy of PheNorm with 4 phenotypes: coronary artery disease, rheumatoid arthri-tis, Crohn's disease, and ulcerative colitis. The AUCs of the PheNorm score reached 0.90, 0.94, 0.95, and 0.94 for the 4 phenotypes, respectively, which were comparable to the accuracy of supervised algorithms trained with sample sizes of 100–300, with no statistically significant difference. Conclusion: The accuracy of the PheNorm algorithms is on par with algorithms trained with annotated samples. PheNorm fully automates the generation of accurate phenotyping algorithms and demonstrates the capacity for EHR-driven annotations to scale to the next level – phenotypic big data.},
author = {Yu, Sheng and Ma, Yumeng and Gronsbell, Jessica and Cai, Tianrun and Ananthakrishnan, Ashwin N. and Gainer, Vivian S. and Churchill, Susanne E. and Szolovits, Peter and Murphy, Shawn N. and Kohane, Isaac S. and Liao, Katherine P. and Cai, Tianxi},
doi = {10.1093/jamia/ocx111},
file = {:Users/na399/GitHub/thesis/references/papers/Yu et al.{\_}2018{\_}Enabling phenotypic big data with PheNorm{\_}Journal of the American Medical Informatics Association.pdf:pdf},
isbn = {1527-974X (Electronic) 1067-5027 (Linking)},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Electronic health records,High-throughput phenotyping,Phenotypic big data,Precision medicine,model:logisticRegression,rank:90,relevancy:A,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {model:logisticRegression,rank:90,relevancy:A,topic:EHR,topic:phenotyping,type:research},
number = {1},
pages = {54--60},
pmid = {29126253},
title = {{Enabling phenotypic big data with PheNorm}},
volume = {25},
year = {2018}
}
@article{Cho2013,
abstract = {Background: Hospital-acquired pressure ulcers (HAPU) are common among inpatients and create substantial morbidity, mortality, and costs, but prevention strategies have been only variably effective. Objectives: To develop and assess the impact of a decision support intervention to predict HAPU on the prevalence of ulcers and length of stay in an intensive care unit (ICU), and on the user adoption rate and attitudes. Methods: We compared the HAPU prevalence before and after introducing the intervention, and surveyed the users. We used a Bayesian Network model that was validated in previous studies and linked to the electronic health record system in an application called Pressure Ulcer (PU) Manager. The intervention group included 866 at-risk patients in the surgical ICUs of a tertiary teaching hospital over a 6-month period in 2009 and 2010; the controls were 348 patients from a 6-month baseline period in 2006 and 2007. Results: In the intervention group, the overall HAPU prevalence rate fell from 21{\%} to 4.0{\%} and the ICU length of stay shortened from 7.6 to 5.2 days. After adjustment for primary diagnoses and illness severity, the intervention group was significantly less likely than the baseline group to develop HAPU [odds ratio (OR)=0.1, p{\textless}. 0.0001] and had a shorter ICU length of stay (OR=0.67, p{\textless}. 0.0001). Data entry regarding ulcer severity and body site increased, and the participants used PU Manager more than once a day for over 80{\%} of eligible cases. Attitudes toward PU Manager were positive. Conclusions: This decision support approach reduced the prevalence of HAPU tenfold and the ICU length of stay by about one-third. Furthermore, the nurses had favorable attitudes toward using it. {\textcopyright} 2013 Elsevier Ireland Ltd.},
author = {Cho, Insook and Park, Ihnsook and Kim, Eunman and Lee, Eunjoon and Bates, David W.},
doi = {10.1016/j.ijmedinf.2013.06.012},
file = {:Users/na399/GitHub/thesis/references/papers/Cho et al.{\_}2013{\_}Using EHR data to predict hospital-acquired pressure ulcers A prospective study of a Bayesian Network model{\_}Internationa.pdf:pdf},
isbn = {1872-8243 (Electronic)$\backslash$r1386-5056 (Linking)},
issn = {13865056},
journal = {International Journal of Medical Informatics},
keywords = {Clinical decision support,Electronic health records,Hospital-acquired pressure ulcers,Prevalence,Prevention,model:Bayesian,rank:85,relevancy:A,topic:prediction,type:research},
mendeley-tags = {rank:85,type:research,relevancy:A,topic:prediction,model:Bayesian},
number = {11},
pages = {1059--1067},
pmid = {23891086},
publisher = {Elsevier Ireland Ltd},
title = {{Using EHR data to predict hospital-acquired pressure ulcers: A prospective study of a Bayesian Network model}},
url = {http://dx.doi.org/10.1016/j.ijmedinf.2013.06.012},
volume = {82},
year = {2013}
}
@inproceedings{Xiao2017,
abstract = {Diabetes is a serious disease a{\"{i}}¿¿ecting a large number of people. Al-though there is no cure for diabetes, it can be managed. Especially, with advances in sensor technology, lots of data may lead to the improvement of diabetes management, if properly mined. However, there usually exists noise or errors in the observed behavioral data which poses challenges in extracting meaningful knowledge. To overcome this challenge, we learn the latent state which represents the patient's condition. Such states should be inferred from the behavioral data but unknown a priori. In this paper, we propose a novel framework to capture the trajectory of latent states for patients from behavioral data while exploiting their demographic di{\"{i}}¿¿erences and similarities to other patients. We conduct a hypoth-esis test to illustrate the importance of the demographic data in diabetes management, and validate that each behavioral feature follows an exponential or a Gaussian distribution. Integrating these aspects, we use a Demographic feature restricted hidden Markov model (DfrHMM) to estimate the trajectory of latent states by in-tegrating the demographic and behavioral data. In DfrHMM, the latent state is mainly determined by the previous state and the de-mographic features in a nonlinear way. Markov Chain Monte Carlo techniques are used for model parameter estimation. Experiments on synthetic and real datasets show that DfrHMM is e{\"{i}}¿¿ective in diabetes management.},
address = {New York, New York, USA},
author = {Xiao, Houping and Gao, Jing and Vu, Long and Turaga, Deepak S.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '17},
doi = {10.1145/3097983.3098100},
file = {:Users/na399/GitHub/thesis/references/papers/Xiao et al.{\_}2017{\_}Learning Temporal State of Diabetes Patients via Combining Behavioral and Demographic Data{\_}Proceedings of the 23rd ACM.pdf:pdf},
isbn = {9781450348874},
keywords = {diabetes management,disease:diabetes,hidden markov model,hypothesis testing,model:Markov,rank:90,relevancy:B,topic:prediction,type:research,•Information systems  Data mining},
mendeley-tags = {disease:diabetes,model:Markov,rank:90,relevancy:B,topic:prediction,type:research},
pages = {2081--2089},
publisher = {ACM Press},
title = {{Learning Temporal State of Diabetes Patients via Combining Behavioral and Demographic Data}},
url = {http://dl.acm.org/citation.cfm?doid=3097983.3098100},
year = {2017}
}
@article{Hong2016,
abstract = {Background: With recent advances in computerized patient records system, there is an urgent need for producing computable and standards-based clinical diagnostic criteria. Notably, constructing rule-based clinical diagnosis criteria has become one of the goals in the International Classification of Diseases (ICD)-11 revision. However, few studies have been done in building a unified architecture to support the need for diagnostic criteria computerization. In this study, we present a modular architecture for enabling the creation of rule-based clinical diagnostic criteria leveraging Semantic Web technologies. Methods and results: The architecture consists of two modules: an authoring module that utilizes a standards-based information model and a translation module that leverages Semantic Web Rule Language (SWRL). In a prototype implementation, we created a diagnostic criteria upper ontology (DCUO) that integrates ICD-11 content model with the Quality Data Model (QDM). Using the DCUO, we developed a transformation tool that converts QDM-based diagnostic criteria into Semantic Web Rule Language (SWRL) representation. We evaluated the domain coverage of the upper ontology model using randomly selected diagnostic criteria from broad domains (n = 20). We also tested the transformation algorithms using 6 QDM templates for ontology population and 15 QDM-based criteria data for rule generation. As the results, the first draft of DCUO contains 14 root classes, 21 subclasses, 6 object properties and 1 data property. Investigation Findings, and Signs and Symptoms are the two most commonly used element types. All 6 HQMF templates are successfully parsed and populated into their corresponding domain specific ontologies and 14 rules (93.3 {\%}) passed the rule validation. Conclusion: Our efforts in developing and prototyping a modular architecture provide useful insight into how to build a scalable solution to support diagnostic criteria representation and computerization. Copyright {\textcopyright} 2016 The Author(s).},
author = {Hong, Na and Pathak, Jyotishman and Chute, Christopher G. and Jiang, Guoqian},
doi = {10.1186/s13040-016-0113-5},
file = {:Users/na399/GitHub/thesis/references/papers/Hong et al.{\_}2016{\_}Developing a modular architecture for creation of rule-based clinical diagnostic criteria{\_}BioData Mining.pdf:pdf},
isbn = {1304001601},
issn = {17560381},
journal = {BioData Mining},
keywords = {Diagnostic Criteria,ICD-11,Ontology,QDM,SWRL,rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
number = {1},
pages = {1--16},
pmid = {27785153},
publisher = {BioData Mining},
title = {{Developing a modular architecture for creation of rule-based clinical diagnostic criteria}},
url = {http://dx.doi.org/10.1186/s13040-016-0113-5},
volume = {9},
year = {2016}
}
@inproceedings{Vasiljeva2016,
abstract = {Computer based analysis of Electronic Health Records (EHRs) has the potential to provide major novel insights of benefit both to specific individuals in the context of personalized medicine, as well as on the level of population-wide health care and policy. The present paper introduces a novel algorithm that uses machine learning for the discovery of longitudinal patterns in the diagnoses of diseases. Two key technical novelties are introduced: one in the form of a novel learning paradigm which enables greater learning specificity, and another in the form of a risk driven identification of confounding diagnoses. We present a series of experiments which demonstrate the effectiveness of the proposed techniques, and which reveal novel insights regarding the most promising future research directions.},
author = {Vasiljeva, Ieva and Arandjelovic, Ognjen},
booktitle = {2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
doi = {10.1109/EMBC.2016.7591226},
file = {:Users/na399/GitHub/thesis/references/papers/Vasiljeva, Arandjelovic{\_}2016{\_}Towards sophisticated learning from EHRs Increasing prediction specificity and accuracy using clinically me.pdf:pdf},
isbn = {978-1-4577-0220-4},
issn = {1557170X},
keywords = {rank:n/a,relevancy:A},
mendeley-tags = {rank:n/a,relevancy:A},
month = {aug},
pages = {2452--2455},
publisher = {IEEE},
title = {{Towards sophisticated learning from EHRs: Increasing prediction specificity and accuracy using clinically meaningful risk criteria}},
url = {http://ieeexplore.ieee.org/document/7591226/},
volume = {2016-Octob},
year = {2016}
}
@article{Brookmeyer2017,
abstract = {Abstract Introduction We forecast the prevalence of preclinical and clinical Alzheimer's disease (AD) and evaluated potential impacts of primary and secondary preventions in the United States. Methods We used a multistate model incorporating biomarkers for preclinical AD with US population projections. Results Approximately 6.08 million Americans had either clinical AD or mild cognitive impairment due to AD in 2017 and that will grow to 15.0 million by 2060. In 2017, 46.7 million Americans had preclinical AD (amyloidosis, neurodegeneration, or both), although many may not progress to clinical disease during their lifetimes. Primary and secondary preventions have differential impact on future disease burden. Discussion Because large numbers of persons are living with preclinical AD, our results underscore the need for secondary preventions for persons with existing AD brain pathology who are likely to develop clinical disease during their lifetimes as well as primary preventions for persons without preclinical disease.},
author = {Brookmeyer, Ron and Abdalla, Nada and Kawas, Claudia H. and Corrada, Mar{\'{i}}a M.},
doi = {10.1016/j.jalz.2017.10.009},
file = {:Users/na399/GitHub/thesis/references/papers/Brookmeyer et al.{\_}2017{\_}Forecasting the prevalence of preclinical and clinical Alzheimer's disease in the United States{\_}Alzheimer's {\&} Dem.pdf:pdf},
issn = {15525260},
journal = {Alzheimer's {\&} Dementia},
keywords = {Alzheimer's disease,Forecast,Intervention,Prediction,Prevalence,Prevention,Statistics,disease:dementia,rank:99,relevancy:C,topic:prevalence,type:research},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:prevalence,type:research},
number = {0},
pages = {1--9},
pmid = {29233480},
title = {{Forecasting the prevalence of preclinical and clinical Alzheimer's disease in the United States}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S155252601733813X},
volume = {0},
year = {2017}
}
@article{Huang2017b,
abstract = {ObjectivesThis study proposes a novel Prior knowledge guided Integrated likelihood Estimation (PIE) method to correct bias in estimations of associations due to misclassification of electronic health record (EHR)-derived binary phenotypes, and evaluates the performance of the proposed method by comparing it to 2 methods in common practice.MethodsWe conducted simulation studies and data analysis of real EHR-derived data on diabetes from Kaiser Permanente Washington to compare the estimation bias of associations using the proposed method, the method ignoring phenotyping errors, the maximum likelihood method with misspecified sensitivity and specificity, and the maximum likelihood method with correctly specified sensitivity and specificity (gold standard). The proposed method effectively leverages available information on phenotyping accuracy to construct a prior distribution for sensitivity and specificity, and incorporates this prior information through the integrated likelihood for bias reduction.ResultsOur simulation studies and real data application demonstrated that the proposed method effectively reduces the estimation bias compared to the 2 current methods. It performed almost as well as the gold standard method when the prior had highest density around true sensitivity and specificity. The analysis of EHR data from Kaiser Permanente Washington showed that the estimated associations from PIE were very close to the estimates from the gold standard method and reduced bias by 60{\%}–100{\%} compared to the 2 commonly used methods in current practice for EHR data.ConclusionsThis study demonstrates that the proposed method can effectively reduce estimation bias caused by imperfect phenotyping in EHR-derived data by incorporating prior information through integrated likelihood.},
author = {Huang, Jing and Duan, Rui and Hubbard, Rebecca A and Wu, Yonghui and Moore, Jason H and Xu, Hua and Chen, Yong},
doi = {10.1093/jamia/ocx137},
file = {:Users/na399/GitHub/thesis/references/papers/Huang et al.{\_}2017{\_}PIE A prior knowledge guided integrated likelihood estimation method for bias reduction in association studies using e.pdf:pdf},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
keywords = {association study,bias reduction,disease:diabetes,electronic health record,misclassification,prior information,rank:90,relevancy:B,topic:EHR,topic:bias,type:research},
mendeley-tags = {disease:diabetes,rank:90,relevancy:B,topic:EHR,topic:bias,type:research},
number = {December 2017},
pages = {345--352},
title = {{PIE: A prior knowledge guided integrated likelihood estimation method for bias reduction in association studies using electronic health records data}},
url = {http://academic.oup.com/jamia/advance-article/doi/10.1093/jamia/ocx137/4683155},
volume = {25},
year = {2017}
}
@article{Vedel2013,
abstract = {Objective To review, categorize, and synthesize findings from the literature about the application of health information technologies in geriatrics and gerontology (GGHIT). This mixed-method systematic review is based on a comprehensive search of Medline, Embase, PsychInfo and ABI/Inform Global. Study selection and coding were performed independently by two researchers and were followed by a narrative synthesis. To move beyond a simple description of the technologies, we employed and adapted the diffusion of innovation theory (DOI). 112 papers were included. Analysis revealed five main types of GGHIT: (1) telecare technologies (representing half of the studies)},
author = {Vedel, Isabelle and Akhlaghpour, Saeed and Vaghefi, Isaac and Bergman, Howard and Lapointe, Liette},
doi = {10.1136/amiajnl-2013-001705},
file = {:Users/na399/GitHub/thesis/references/papers/Vedel et al.{\_}2013{\_}Health information technologies in geriatrics and gerontology A mixed systematic review{\_}Journal of the American Medica.pdf:pdf},
isbn = {1527-974X (Electronic)$\backslash$r1067-5027 (Linking)},
issn = {10675027},
journal = {Journal of the American Medical Informatics Association},
keywords = {disease:dementia,rank:90,relevancy:B,topic:CDSS,topic:EHR,type:review},
mendeley-tags = {disease:dementia,rank:90,relevancy:B,topic:CDSS,topic:EHR,type:review},
number = {6},
pages = {1109--1119},
pmid = {23666776},
title = {{Health information technologies in geriatrics and gerontology: A mixed systematic review}},
volume = {20},
year = {2013}
}
@inproceedings{Yao2017,
author = {Yao, Xiaohui and Yan, Jingwen and Risacher, Shannon and Moore, Jason and Saykin, Andrew and Shen, Li},
booktitle = {2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
doi = {10.1109/ICASSP.2017.7953342},
file = {:Users/na399/GitHub/thesis/references/papers/Yao et al.{\_}2017{\_}Network-based genome wide study of hippocampal imaging phenotype in Alzheimer's Disease to identify functional interacti.pdf:pdf},
isbn = {978-1-5090-4117-6},
keywords = {rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
month = {mar},
pages = {6170--6174},
publisher = {IEEE},
title = {{Network-based genome wide study of hippocampal imaging phenotype in Alzheimer's Disease to identify functional interaction modules}},
url = {http://ieeexplore.ieee.org/document/7953342/},
year = {2017}
}
@article{Huddar2016,
author = {Huddar, Vijay and Desiraju, Bapu Koundinya and Rajan, Vaibhav and Bhattacharya, Sakyajit and Roy, Shourya and Reddy, Chandan K},
doi = {10.1109/ACCESS.2016.2618775},
file = {:Users/na399/GitHub/thesis/references/papers/Huddar et al.{\_}2016{\_}Predicting Complications in Critical Care Using Heterogeneous Clinical Data{\_}IEEE Access.pdf:pdf},
issn = {2169-3536},
journal = {IEEE Access},
keywords = {disease:critical,model:CMF,model:NLP,rank:95,relevancy:A,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:critical,model:CMF,model:NLP,rank:95,relevancy:A,topic:EHR,topic:prediction,type:research},
pages = {7988--8001},
title = {{Predicting Complications in Critical Care Using Heterogeneous Clinical Data}},
url = {http://ieeexplore.ieee.org/document/7593335/},
volume = {4},
year = {2016}
}
@article{Li2016,
abstract = {Electronic Medical Record (EMR) has established itself as a valuable resource for large scale analysis of health data. A hospital EMR dataset typically consists of medical records of hospitalized patients. A medical record contains diagnostic information (diagnosis codes), procedures performed (procedure codes) and admission details. Traditional topic models, such as latent Dirichlet allocation (LDA) and hierarchical Dirichlet process (HDP), can be employed to discover disease topics from EMR data by treating patients as documents and diagnosis codes as words. This topic modeling helps to understand the constitution of patient diseases and offers a tool for better planning of treatment. In this paper, we propose a novel and flexible hierarchical Bayesian nonparametric model, the word distance dependent Chinese restaurant franchise (wddCRF), which incorporates word-to-word distances to discover semantically-coherent disease topics. We are motivated by the fact that diagnosis codes are connected in the form of ICD-10 tree structure which presents semantic relationships between codes. We exploit a decay function to incorporate distances between words at the bottom level of wddCRF. Efficient inference is derived for the wddCRF by using MCMC technique. Furthermore, since procedure codes are often correlated with diagnosis codes, we develop the correspondence wddCRF (Corr-wddCRF) to explore conditional relationships of procedure codes for a given disease pattern. Efficient collapsed Gibbs sampling is derived for the Corr-wddCRF. We evaluate the proposed models on two real-world medical datasets - PolyVascular disease and Acute Myocardial Infarction disease. We demonstrate that the Corr-wddCRF model discovers more coherent topics than the Corr-HDP. We also use disease topic proportions as new features and show that using features from the Corr-wddCRF outperforms the baselines on 14-days readmission prediction. Beside these, the prediction for procedure codes based on the Corr-wddCRF also shows considerable accuracy.},
author = {Li, Cheng and Rana, Santu and Phung, Dinh and Venkatesh, Svetha},
doi = {10.1016/j.knosys.2016.02.005},
file = {:Users/na399/GitHub/thesis/references/papers/Li et al.{\_}2016{\_}Hierarchical Bayesian nonparametric models for knowledge discovery from electronic medical records{\_}Knowledge-Based System.pdf:pdf},
isbn = {0950-7051$\backslash$r1872-7409},
issn = {09507051},
journal = {Knowledge-Based Systems},
keywords = {Bayesian nonparametric models,Correspondence models,Disease topics,Procedure codes prediction,Readmission prediction,Word distances,disease:general,model:NLP,model:wddCRF,rank:95,relevancy:B,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:general,model:NLP,model:wddCRF,rank:95,relevancy:B,topic:EHR,topic:prediction,type:research},
pages = {168--182},
publisher = {Elsevier B.V.},
title = {{Hierarchical Bayesian nonparametric models for knowledge discovery from electronic medical records}},
url = {http://dx.doi.org/10.1016/j.knosys.2016.02.005},
volume = {99},
year = {2016}
}
@inproceedings{Zheng2017,
abstract = {Electronic Medical Records (EMR) are the most fundamental re-sources used in healthcare data analytics. Since people visit hospital more frequently when they feel sick and doctors prescribe lab ex-aminations when they feel necessary, we argue that there could be a strong bias in EMR observations compared with the hidden conditions of patients. Directly using such EMR for analytical tasks without considering the bias may lead to misinterpretation. To this end, we propose a general method to resolve the bias by transforming EMR to regular patient hidden condition series using a Hidden Markov Model (HMM) variant. Compared with the biased EMR series with irregular time stamps, the unbiased regular time series is much easier to be processed by most analytical models and yields better results. Extensive experimental results demonstrate that our bias resolving method imputes missing data more accurately than baselines and improves the performance of the state-of-the-art methods on typical medical data analytics.},
address = {New York, New York, USA},
author = {Zheng, Kaiping and Gao, Jinyang and Ngiam, Kee Yuan and Ooi, Beng Chin and Yip, Wei Luen James},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '17},
doi = {10.1145/3097983.3098149},
file = {:Users/na399/GitHub/thesis/references/papers/Zheng et al.{\_}2017{\_}Resolving the Bias in Electronic Medical Records{\_}Proceedings of the 23rd ACM SIGKDD International Conference on Knowle.pdf:pdf},
isbn = {9781450348874},
keywords = {-  Applied computing  -{\textgreater}  Health informatics,-  Computing methodologies  -{\textgreater}  Learning in probab,-  Mathematics of computing  -{\textgreater}  Time series analy,model:Bayesian,rank:90,relevancy:B,topic:EHR,topic:ML,type:research},
mendeley-tags = {model:Bayesian,rank:90,relevancy:B,topic:EHR,topic:ML,type:research},
pages = {2171--2180},
publisher = {ACM Press},
title = {{Resolving the Bias in Electronic Medical Records}},
url = {http://dl.acm.org/citation.cfm?doid=3097983.3098149},
year = {2017}
}
@article{Stucki2014,
abstract = {BACKGROUND: The number of older adults in the global population is increasing. This demographic shift leads to an increasing prevalence of age-associated disorders, such as Alzheimer's disease and other types of dementia. With the progression of the disease, the risk for institutional care increases, which contrasts with the desire of most patients to stay in their home environment. Despite doctors' and caregivers' awareness of the patient's cognitive status, they are often uncertain about its consequences on activities of daily living (ADL). To provide effective care, they need to know how patients cope with ADL, in particular, the estimation of risks associated with the cognitive decline. The occurrence, performance, and duration of different ADL are important indicators of functional ability. The patient's ability to cope with these activities is traditionally assessed with questionnaires, which has disadvantages (eg, lack of reliability and sensitivity). Several groups have proposed sensor-based systems to recognize and quantify these activities in the patient's home. Combined with Web technology, these systems can inform caregivers about their patients in real-time (e.g., via smartphone). OBJECTIVE: We hypothesize that a non-intrusive system, which does not use body-mounted sensors, video-based imaging, and microphone recordings would be better suited for use in dementia patients. Since it does not require patient's attention and compliance, such a system might be well accepted by patients. We present a passive, Web-based, non-intrusive, assistive technology system that recognizes and classifies ADL. METHODS: The components of this novel assistive technology system were wireless sensors distributed in every room of the participant's home and a central computer unit (CCU). The environmental data were acquired for 20 days (per participant) and then stored and processed on the CCU. In consultation with medical experts, eight ADL were classified. RESULTS: In this study, 10 healthy participants (6 women, 4 men; mean age 48.8 years; SD 20.0 years; age range 28-79 years) were included. For explorative purposes, one female Alzheimer patient (Montreal Cognitive Assessment score=23, Timed Up and Go=19.8 seconds, Trail Making Test A=84.3 seconds, Trail Making Test B=146 seconds) was measured in parallel with the healthy subjects. In total, 1317 ADL were performed by the participants, 1211 ADL were classified correctly, and 106 ADL were missed. This led to an overall sensitivity of 91.27{\%} and a specificity of 92.52{\%}. Each subject performed an average of 134.8 ADL (SD 75). CONCLUSIONS: The non-intrusive wireless sensor system can acquire environmental data essential for the classification of activities of daily living. By analyzing retrieved data, it is possible to distinguish and assign data patterns to subjects' specific activities and to identify eight different activities in daily living. The Web-based technology allows the system to improve care and provides valuable information about the patient in real-time.},
author = {Stucki, Reto A. and Urwyler, Prabitha and Rampa, Luca and M{\"{u}}ri, Ren{\'{e}} and Mosimann, Urs P. and Nef, Tobias},
doi = {10.2196/jmir.3465},
file = {:Users/na399/GitHub/thesis/references/papers/Stucki et al.{\_}2014{\_}A web-based non-intrusive ambient system to measure and classify activities of daily living{\_}Journal of Medical Intern.pdf:pdf},
isbn = {1438-8871 (Electronic)$\backslash$r1438-8871 (Linking)},
issn = {14388871},
journal = {Journal of Medical Internet Research},
keywords = {ADL classifier,Activity monitoring,Alzheimer,Assistive technology,Behavior pattern,Dementia,Forward chaining inference engine,Rule-based,Smart homes,Wireless sensor system,disease:dementia,rank:95,relevancy:D,topic:monitor,topic:sensor,type:research},
mendeley-tags = {disease:dementia,rank:95,relevancy:D,topic:monitor,topic:sensor,type:research},
number = {7},
pages = {1--12},
pmid = {25048461},
title = {{A web-based non-intrusive ambient system to measure and classify activities of daily living}},
volume = {16},
year = {2014}
}
@inproceedings{Liu2015c,
abstract = {The rapid growth in the development of healthcare information systems has led to an increased interest in utilizing the patient Electronic Health Records (EHR) for assisting disease diagnosis and phenotyping. The patient EHRs are generally longitudinal and naturally represented as medical event sequences, where the events include clinical notes, problems, medications, vital signs, laboratory reports, etc. The longitudinal and heterogeneous properties make EHR analysis an inherently difficult challenge. To address this challenge, in this paper, we develop a novel representation, namely the temporal graph, for such event sequences. The temporal graph is informative for a variety of challenging analytic tasks, such as predictive modeling, since it can capture temporal relationships of the medical events in each event sequence. By summarizing the longitudinal data, the temporal graphs are also robust and resistant to noisy and irregular observations. Based on the temporal graph representation, we further develop an approach for temporal phenotyping to identify the most significant and interpretable graph basis as phenotypes. This helps us better understand the disease evolving patterns. Moreover, by expressing the temporal graphs with the phenotypes, the expressing coefficients can be used for applications such as personalized medicine, disease diagnosis, and patient segmentation. Our temporal phenotyping framework is also flexible to incorporate semi-supervised/supervised information. Finally, we validate our framework on two real-world tasks. One is predicting the onset risk of heart failure. Another is predicting the risk of heart failure related hospitalization for patients with COPD pre-condition. Our results show that the diagnosis performance in both tasks can be improved significantly by the proposed approaches. Also, we illustrate some interesting phenotypes derived from the data.},
address = {New York, New York, USA},
author = {Liu, Chuanren and Wang, Fei and Hu, Jianying and Xiong, Hui},
booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '15},
doi = {10.1145/2783258.2783352},
file = {:Users/na399/GitHub/thesis/references/papers/Liu et al.{\_}2015{\_}Temporal Phenotyping from Longitudinal Electronic Health Records{\_}Proceedings of the 21th ACM SIGKDD International Confer.pdf:pdf},
isbn = {9781450336642},
keywords = {electronic health records,rank:90,regularization,relevancy:B,temporal graph,temporal phenotyping,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:research},
pages = {705--714},
publisher = {ACM Press},
title = {{Temporal Phenotyping from Longitudinal Electronic Health Records}},
url = {http://dl.acm.org/citation.cfm?doid=2783258.2783352},
year = {2015}
}
@article{Association2017,
abstract = {This article describes the public health impact of Alzheimer's disease (AD), including incidence and prevalence, mortality rates, costs of care, and the overall impact on caregivers and society. The Special Report examines how the use of biomarkers may influence the AD diagnostic process and estimates of prevalence and incidence of the disease. An estimated 5.5 million Americans have Alzheimer's dementia. By mid-century, the number of people living with Alzheimer's dementia in the United States is projected to grow to 13.8 million, fueled in large part by the aging baby boom generation. Today, someone in the country develops Alzheimer's dementia every 66 seconds. By 2050, one new case of Alzheimer's dementia is expected to develop every 33 seconds, resulting in nearly 1 million new cases per year. In 2014, official death certificates recorded 93,541 deaths from AD, making AD the sixth leading cause of death in the United States and the fifth leading cause of death in Americans age ≥65 years. Between 2000 and 2014, deaths resulting from stroke, heart disease, and prostate cancer decreased 21{\%}, 14{\%}, and 9{\%}, respectively, whereas deaths from AD increased 89{\%}. The actual number of deaths to which AD contributes is likely much larger than the number of deaths from AD recorded on death certificates. In 2017, an estimated 700,000 Americans age ≥65 years will have AD when they die, and many of them will die because of the complications caused by AD. In 2016, more than 15 million family members and other unpaid caregivers provided an estimated 18.2 billion hours of care to people with Alzheimer's or other dementias. This care is valued at more than {\$}230 billion. Average per-person Medicare payments for services to beneficiaries age ≥65 years with Alzheimer's or other dementias are more than three times as great as payments for beneficiaries without these conditions, and Medicaid payments are more than 23 times as great. Total payments in 2017 for health care, long-term care, and hospice services for people age ≥65 years with dementia are estimated to be {\$}259 billion. In recent years, efforts to develop and validate AD biomarkers, including those detectable with brain imaging and in the blood and cerebrospinal fluid, have intensified. Such efforts could transform the practice of diagnosing AD from one that focuses on cognitive and functional symptoms to one that incorporates biomarkers. This new approach could promote diagnosis at an earlier stage of disease and lead to a more accurate understanding of AD prevalence and incidence.},
author = {Association, Alzheimer},
doi = {10.1016/j.jalz.2017.02.001},
file = {:Users/na399/Downloads/Research Papers/Association{\_}2017{\_}2017 Alzheimer's disease facts and figures{\_}Alzheimer's {\&} Dementia.pdf:pdf},
issn = {15525260},
journal = {Alzheimer's {\&} Dementia},
keywords = {1,2017 alzheimer,about this report,data related to alzheimer,disease:dementia,figures is a,rank:99,relevancy:B,s,s disease facts and,statistical resource for u,topic:impact,topic:prevalence,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:B,topic:impact,topic:prevalence,type:commentary},
number = {4},
pages = {325--373},
publisher = {Elsevier Inc.},
title = {{2017 Alzheimer's disease facts and figures}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1552526017300511},
volume = {13},
year = {2017}
}
@article{Ritchie2015,
abstract = {The members of the Genomics Workgroup in the Electronic Medical Records and Genomics (eMERGE) network (Gottesman et al., 2013) led the development of a Special Topic in Frontiers in Genetics titled " Genetics Research in Electronic Health Records Linked to DNA Biobanks 1 . " The goal was to publish papers representing the diverse research ongoing in the integration of elec-tronic health records (EHR) with genomics through basic, clinical, and translational research. The special topic with its 18 papers is extremely timely given the recent announcement of the Precision Medicine initiative by the White House 2 , which includes the potential to build a biobank of 1 mil-lion Americans with rich, phenotypic data—likely from EHR. eMERGE has, therefore, served as an excellent test case for how a 1 million person project might work across several medical centers, EHR systems, and genetic datasets. The first group of papers (Almoguera et al., 2014; Crawford et al., 2014; Crosslin et al., 2014; Verma et al., 2014) belonging to this special issue presents the eMERGE network and its contribu-tion to genomics. The paper by Crawford et al. (2014) describes the initial goal of eMERGE network that was to explore the utility of EHRs in genomics and whether the phenotypes identified through algorithms using EHRs combined with the genome-wide genotypes could lead to fruitful results. The beginning of the network included individual genotype datasets that were later combined to form the merged eMERGE datasets and the combination with phenotypes from EHRs has led to new genomic discoveries. All of these steps subsequently lead to new goals that have included next generation sequencing and clinical practice. The second paper (Verma et al., 2014) introduces the new challenges involved in merging genotype data from different eMERGE sites. Since genotypes at different sites were derived from different genotyping platforms it was impossible to create a single merged data file based on raw genotype data alone. The solution was first to impute each site separately using the same software and pipeline, and then merge the imputed genotype data sets to form a combined dataset. The authors used two different imputation software packages and describe the challenges involved in using diverse ethnic populations and different genotype platforms, which lead to a complete pipeline that not only performs imputation but also ensures appropriate quality control for merging genotype data sets. The final eMERGE imputed data set is 1 Available online at: http://journal.frontiersin.org/ResearchTopic/2198 2 Available online at: WH.GOV/PRECISION-MEDICINE},
author = {Ritchie, Marylyn D. and de Andrade, Mariza and Kuivaniemi, Helena},
doi = {10.3389/fgene.2015.00104},
file = {:Users/na399/GitHub/thesis/references/papers/Ritchie, de Andrade, Kuivaniemi{\_}2015{\_}The foundation of precision medicine Integration of electronic health records with genomics through.pdf:pdf},
issn = {16648021},
journal = {Frontiers in Genetics},
keywords = {EHR,Electronic health records,Genomic medicine,Genomics,Precision medicine,rank:75,relevancy:C},
mendeley-tags = {rank:75,relevancy:C},
number = {MAR},
pages = {1--4},
pmid = {25852745},
title = {{The foundation of precision medicine: Integration of electronic health records with genomics through basic, clinical, and translational research}},
volume = {6},
year = {2015}
}
@inproceedings{Yang2014,
abstract = {Event sequences, such as patients' medical histories or users' se- quences of product reviews, trace how individuals progress over time. Identifying common patterns, or progression stages, in such event sequences is a challenging task because not every individual follows the same evolutionary pattern, stages may have very differ- ent lengths, and individuals may progress at different rates. In this paper, we develop a model-based method for discover- ing common progression stages in general event sequences. We develop a generative model in which each sequence belongs to a class, and sequences from a given class pass through a common set of stages, where each sequence evolves at its own rate. We then de- velop a scalable algorithm to infer classes of sequences, while also segmenting each sequence into a set of stages. We evaluate our method on event sequences, ranging from patients' medical his- tories to online news and navigational traces from the Web. The evaluation shows that our methodology can predict future events in a sequence, while also accurately inferring meaningful progression stages, and effectively grouping sequences based on common pro- gression patterns. More generally, our methodology allows us to reason about how event sequences progress over time, by discov- ering patterns and categories of temporal evolution in large-scale datasets of events.},
address = {New York, New York, USA},
author = {Yang, Jaewon and McAuley, Julian and Leskovec, Jure and LePendu, Paea and Shah, Nigam},
booktitle = {Proceedings of the 23rd international conference on World wide web - WWW '14},
doi = {10.1145/2566486.2568044},
file = {:Users/na399/GitHub/thesis/references/papers/Yang et al.{\_}2014{\_}Finding progression stages in time-evolving event sequences{\_}Proceedings of the 23rd international conference on World w.pdf:pdf},
isbn = {9781450327442},
keywords = {event sequences,rank:n/a,relevancy:A,time series,user modeling},
mendeley-tags = {rank:n/a,relevancy:A},
pages = {783--794},
publisher = {ACM Press},
title = {{Finding progression stages in time-evolving event sequences}},
url = {http://dl.acm.org/citation.cfm?doid=2566486.2568044},
year = {2014}
}
@article{Hripcsak2013,
abstract = {The national adoption of electronic health records (EHR) promises to make an unprecedented amount of data available for clinical research, but the data are complex, inaccurate, and frequently missing, and the record reflects complex processes aside from the patient's physiological state. We believe that the path forward requires studying the EHR as an object of interest in itself, and that new models, learning from data, and collaboration will lead to efficient use of the valuable information currently locked in health records.},
author = {Hripcsak, George and Albers, David J.},
doi = {10.1136/amiajnl-2012-001145},
file = {:Users/na399/GitHub/thesis/references/papers/Hripcsak, Albers{\_}2013{\_}Next-generation phenotyping of electronic health records{\_}Journal of the American Medical Informatics Association.pdf:pdf},
isbn = {1527-974X (Electronic)$\backslash$n1067-5027 (Linking)},
issn = {10675027},
journal = {Journal of the American Medical Informatics Association},
keywords = {rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:commentary},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:commentary},
number = {1},
pages = {117--121},
pmid = {22955496},
title = {{Next-generation phenotyping of electronic health records}},
volume = {20},
year = {2013}
}
@article{Shen2010,
abstract = {A genome-wide, whole brain approach to investigate genetic effects on neuroimaging phenotypes for identifying quantitative trait loci is described. The Alzheimer's Disease Neuroimaging Initiative 1.5 T MRI and genetic dataset was investigated using voxel-based morphometry (VBM) and FreeSurfer parcellation followed by genome-wide association studies (GWAS). One hundred forty-two measures of grey matter (GM) density, volume, and cortical thickness were extracted from baseline scans. GWAS, using PLINK, were performed on each phenotype using quality-controlled genotype and scan data including 530,992 of 620,903 single nucleotide polymorphisms (SNPs) and 733 of 818 participants (175 AD, 354 amnestic mild cognitive impairment, MCI, and 204 healthy controls, HC). Hierarchical clustering and heat maps were used to analyze the GWAS results and associations are reported at two significance thresholds (p{\textless}10-7and p{\textless}10-6). As expected, SNPs in the APOE and TOMM40 genes were confirmed as markers strongly associated with multiple brain regions. Other top SNPs were proximal to the EPHA4, TP63 and NXPH1 genes. Detailed image analyses of rs6463843 (flanking NXPH1) revealed reduced global and regional GM density across diagnostic groups in TT relative to GG homozygotes. Interaction analysis indicated that AD patients homozygous for the T allele showed differential vulnerability to right hippocampal GM density loss. NXPH1 codes for a protein implicated in promotion of adhesion between dendrites and axons, a key factor in synaptic integrity, the loss of which is a hallmark of AD. A genome-wide, whole brain search strategy has the potential to reveal novel candidate genes and loci warranting further investigation and replication. {\textcopyright} 2010 Elsevier Inc.},
author = {Shen, Li and Kim, Sungeun and Risacher, Shannon L. and Nho, Kwangsik and Swaminathan, Shanker and West, John D. and Foroud, Tatiana and Pankratz, Nathan and Moore, Jason H. and Sloan, Chantel D. and Huentelman, Matthew J. and Craig, David W. and DeChairo, Bryan M. and Potkin, Steven G. and Jack, Clifford R. and Weiner, Michael W. and Saykin, Andrew J.},
doi = {10.1016/j.neuroimage.2010.01.042},
file = {:Users/na399/GitHub/thesis/references/papers/Shen et al.{\_}2010{\_}Whole genome association study of brain-wide imaging phenotypes for identifying quantitative trait loci in MCI and AD A.pdf:pdf},
isbn = {1095-9572 (Electronic)$\backslash$r1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {disease:dementia,rank:99,relevancy:C,topic:GWAS,topic:neuroimaging,type:research},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:GWAS,topic:neuroimaging,type:research},
number = {3},
pages = {1051--1063},
pmid = {20100581},
publisher = {Elsevier Inc.},
title = {{Whole genome association study of brain-wide imaging phenotypes for identifying quantitative trait loci in MCI and AD: A study of the ADNI cohort}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2010.01.042},
volume = {53},
year = {2010}
}
@inproceedings{Ji2015a,
author = {{Xiang Ji} and {Soon Ae Chun} and Geller, James and Oria, Vincent},
booktitle = {2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
doi = {10.1109/BIBM.2015.7359771},
file = {:Users/na399/GitHub/thesis/references/papers/Xiang Ji et al.{\_}2015{\_}Collaborative and trajectory prediction models of medical conditions by mining patients' Social Data{\_}2015 IEEE Inte.pdf:pdf},
isbn = {978-1-4673-6799-8},
keywords = {collaborative prediction,disease progression,in patient social media,lack of privacy issues,letting,mining social media,predictive analytics,rank:n/a,relevancy:B,status,the patients,trajectory prediction,voluntarily post their health,with the purpose of},
mendeley-tags = {rank:n/a,relevancy:B},
month = {nov},
pages = {695--700},
publisher = {IEEE},
title = {{Collaborative and trajectory prediction models of medical conditions by mining patients' Social Data}},
url = {http://ieeexplore.ieee.org/document/7359771/},
year = {2015}
}
@article{Kavakiotis2017,
abstract = {The remarkable advances in biotechnology and health sciences have led to a significant production of data, such as high throughput genetic data and clinical information, generated from large Electronic Health Records (EHRs). To this end, application of machine learning and data mining methods in biosciences is presently, more than ever before, vital and indispensable in efforts to transform intelligently all available information into valuable knowledge. Diabetes mellitus (DM) is defined as a group of metabolic disorders exerting significant pressure on human health worldwide. Extensive research in all aspects of diabetes (diagnosis, etiopathophysiology, therapy, etc.) has led to the generation of huge amounts of data. The aim of the present study is to conduct a systematic review of the applications of machine learning, data mining techniques and tools in the field of diabetes research with respect to a) Prediction and Diagnosis, b) Diabetic Complications, c) Genetic Background and Environment, and e) Health Care and Management with the first category appearing to be the most popular. A wide range of machine learning algorithms were employed. In general, 85{\%} of those used were characterized by supervised learning approaches and 15{\%} by unsupervised ones, and more specifically, association rules. Support vector machines (SVM) arise as the most successful and widely used algorithm. Concerning the type of data, clinical datasets were mainly used. The title applications in the selected articles project the usefulness of extracting valuable knowledge leading to new hypotheses targeting deeper understanding and further investigation in DM.},
author = {Kavakiotis, Ioannis and Tsave, Olga and Salifoglou, Athanasios and Maglaveras, Nicos and Vlahavas, Ioannis and Chouvarda, Ioanna},
doi = {10.1016/j.csbj.2016.12.005},
file = {:Users/na399/GitHub/thesis/references/papers/Kavakiotis et al.{\_}2017{\_}Machine Learning and Data Mining Methods in Diabetes Research{\_}Computational and Structural Biotechnology Journal.pdf:pdf},
isbn = {2001-0370},
issn = {20010370},
journal = {Computational and Structural Biotechnology Journal},
keywords = {Biomarker(s) identification,Data mining,Diabetes mellitus,Diabetic complications,Disease prediction models,Machine learning,disease:diabetes,rank:85,relevancy:A,topic:EHR,topic:ML,topic:prediction,type:review},
mendeley-tags = {rank:85,topic:ML,disease:diabetes,relevancy:A,topic:EHR,topic:prediction,type:review},
pages = {104--116},
pmid = {28138367},
publisher = {The Authors},
title = {{Machine Learning and Data Mining Methods in Diabetes Research}},
url = {https://doi.org/10.1016/j.csbj.2016.12.005},
volume = {15},
year = {2017}
}
@article{Frost2016,
abstract = {Although gene-environment (Gx E) interactions play an important role in many biological systems, detecting these interactions within genome-wide data can be challenging due to the loss in statistical power incurred by multiple hypothesis correction. To address the challenge of poor power and the limitations of existing multistage methods, we recently developed a screening-testing approach for Gx E interaction detection that combines elastic net penalized regression with joint estimation to support a single omnibus test for the presence of Gx E interactions. In our original work on this technique, however, we did not assess type I error control or power and evaluated the method using just a single, small bladder cancer data set. In this paper, we extend the original method in two important directions and provide a more rigorous performance evaluation. First, we introduce a hierarchical false discovery rate approach to formally assess the significance of individual Gx E interactions. Second, to support the analysis of truly genome-wide data sets, we incorporate a score statistic-based prescreening step to reduce the number of single nucleotide polymorphisms prior to fitting the first stage penalized regression model. To assess the statistical properties of our method, we compare the type I error rate and statistical power of our approach with competing techniques using both simple simulation designs as well as designs based on real disease architectures. Finally, we demonstrate the ability of our approach to identify biologically plausible SNP-education interactions relative to Alzheimer's disease status using genome-wide association study data from the Alzheimer's Disease Neuroimaging Initiative (ADNI). Copyright {\{}$\backslash$copyright{\}}2016 The Authors Genetic Epidemiology Published by Wiley Periodicals, Inc.},
author = {Frost, H. Robert and Shen, Li and Saykin, Andrew J. and Williams, Scott M. and Moore, Jason H.},
doi = {10.1002/gepi.21997},
file = {:Users/na399/GitHub/thesis/references/papers/Frost et al.{\_}2016{\_}Identifying significant gene-environment interactions using a combination of screening testing and hierarchical false.pdf:pdf},
isbn = {1098-2272},
issn = {10982272},
journal = {Genetic Epidemiology},
keywords = {gene-environment interactions,hierarchical FDR,penalized regression,rank:60,relevancy:C,screening testing},
mendeley-tags = {rank:60,relevancy:C},
number = {7},
pages = {544--557},
pmid = {27578615},
title = {{Identifying significant gene-environment interactions using a combination of screening testing and hierarchical false discovery rate control}},
volume = {40},
year = {2016}
}
@article{Shivade2014,
abstract = {Objective To summarize literature describing approaches aimed at automatically identifying patients with a common phenotype. Materials and methods We performed a review of studies describing systems or reporting techniques developed for identifying cohorts of patients with specific phenotypes. Every full text article published in (1) Journal of American Medical Informatics Association, (2) Journal of Biomedical Informatics, (3) Proceedings of the Annual American Medical Informatics Association Symposium, and (4) Proceedings of Clinical Research Informatics Conference within the past 3years was assessed for inclusion in the review. Only articles using automated techniques were included. Results Ninety-seven articles met our inclusion criteria. Forty-six used natural language processing (NLP)-based techniques, 24 described rule-based systems, 41 used statistical analyses, data mining, or machine learning techniques, while 22 described hybrid systems. Nine articles described the architecture of large-scale systems developed for determining cohort eligibility of patients. Discussion We observe that there is a rise in the number of studies associated with cohort identification using electronic medical records. Statistical analyses or machine learning, followed by NLP techniques, are gaining popularity over the years in comparison with rule-based systems. Conclusions There are a variety of approaches for classifying patients into a particular phenotype. Different techniques and data sources are used, and good performance is reported on datasets at respective institutions. However, no system makes comprehensive use of electronic medical records addressing all of their known weaknesses.},
author = {Shivade, Chaitanya and Raghavan, Preethi and Fosler-Lussier, Eric and Embi, Peter J. and Elhadad, Noemie and Johnson, Stephen B. and Lai, Albert M.},
doi = {10.1136/amiajnl-2013-001935},
file = {:Users/na399/GitHub/thesis/references/papers/Shivade et al.{\_}2014{\_}A review of approaches to identifying patient phenotype cohorts using electronic health records{\_}Journal of the Ameri.pdf:pdf},
isbn = {1067-5027},
issn = {10675027},
journal = {Journal of the American Medical Informatics Association},
keywords = {rank:90,relevancy:A,topic:EHR,topic:phenotyping,type:review},
mendeley-tags = {rank:90,relevancy:A,topic:EHR,topic:phenotyping,type:review},
number = {2},
pages = {221--230},
pmid = {24201027},
title = {{A review of approaches to identifying patient phenotype cohorts using electronic health records}},
volume = {21},
year = {2014}
}
@article{Montine2012,
abstract = {A consensus panel from the United States and Europe was convened recently to update and revise the 1997 consensus guidelines for the neuropathologic evaluation of Alzheimer's disease (AD) and other diseases of brain that are common in the elderly. The new guidelines recognize the pre-clinical stage of AD, enhance the assessment of AD to include amyloid accumulation as well as neurofibrillary change and neuritic plaques, establish protocols for the neuropathologic assessment of Lewy body disease, vascular brain injury, hippocampal sclerosis, and TDP-43 inclusions, and recommend standard approaches for the workup of cases and their clinico-pathologic correlation. {\textcopyright} 2012 The Alzheimers Association. All rights reserved.},
author = {Hyman, Bradley T. and Phelps, Creighton H. and Beach, Thomas G. and Bigio, Eileen H. and Cairns, Nigel J. and Carrillo, Maria C. and Dickson, Dennis W. and Duyckaerts, Charles and Frosch, Matthew P. and Masliah, Eliezer and Mirra, Suzanne S. and Nelson, Peter T. and Schneider, Julie A. and Thal, Dietmar Rudolf and Thies, Bill and Trojanowski, John Q. and Vinters, Harry V. and Montine, Thomas J.},
doi = {10.1016/j.jalz.2011.10.007},
file = {:Users/na399/Downloads/Research Papers/Hyman et al.{\_}2012{\_}National Institute on Aging–Alzheimer's Association guidelines for the neuropathologic assessment of Alzheimer's dis.pdf:pdf},
isbn = {0040101109103},
issn = {15525260},
journal = {Alzheimer's {\&} Dementia},
keywords = {disease:dementia,rank:99,relevancy:B,topic:diagnostic criteria,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:B,topic:diagnostic criteria,type:commentary},
month = {jan},
number = {1},
pages = {1--13},
pmid = {22265587},
publisher = {Elsevier Ltd},
title = {{National Institute on Aging–Alzheimer's Association guidelines for the neuropathologic assessment of Alzheimer's disease}},
url = {http://dx.doi.org/10.1016/j.jalz.2011.10.007 http://link.springer.com/10.1007/s00401-011-0910-3 http://linkinghub.elsevier.com/retrieve/pii/S1552526011029803},
volume = {8},
year = {2012}
}
@article{Roberts2017,
abstract = {The field of biomedical informatics experienced a productive 2015 in terms of research. In order to highlight the accomplishments of that research, elicit trends, and identify shortcomings at a macro level, a 19-person team conducted an extensive review of the literature in clinical and consumer informatics. The result of this process included a year-in-review presentation at the American Medical Informatics Association Annual Symposium and a written report (see supplemental data). Key findings are detailed in the report and summarized here. This article organizes the clinical and consumer health informatics research from 2015 under 3 themes: the electronic health record (EHR), the learning health system (LHS), and consumer engagement. Key findings include the following: (1) There are significant advances in establishing policies for EHR feature implementation, but increased interoperability is necessary for these to gain traction. (2) Decision support systems improve practice behaviors, but evidence of their impact on clinical outcomes is still lacking. (3) Progress in natural language processing (NLP) suggests that we are approaching but have not yet achieved truly interactive NLP systems. (4) Prediction models are becoming more robust but remain hampered by the lack of interoperable clinical data records. (5) Consumers can and will use mobile applications for improved engagement, yet EHR integration remains elusive.},
author = {Roberts, Kirk and Boland, Mary Regina and Pruinelli, Lisiane and Dcruz, Jina and Berry, Andrew and Georgsson, Mattias and Hazen, Rebecca and Sarmiento, Raymond F. and Backonja, Uba and Yu, Kun-Hsing and Jiang, Yun and Brennan, Patricia Flatley},
doi = {10.1093/jamia/ocw103},
file = {:Users/na399/GitHub/thesis/references/papers/Roberts et al.{\_}2017{\_}Biomedical informatics advancing the national health agenda the AMIA 2015 year-in-review in clinical and consumer in.pdf:pdf},
isbn = {1527-974X (Electronic) 1067-5027 (Linking)},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
keywords = {biomedical informatics,consumer engagement,electronic health records,learning health system,rank:90,relevancy:B,topic:EHR,type:review,year in review},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,type:review},
month = {aug},
number = {e1},
pages = {ocw103},
pmid = {27497798},
title = {{Biomedical informatics advancing the national health agenda: the AMIA 2015 year-in-review in clinical and consumer informatics}},
url = {https://academic.oup.com/jamia/article-lookup/doi/10.1093/jamia/ocw103},
volume = {24},
year = {2016}
}
@article{Saeys2007,
abstract = {Feature selection techniques have become an apparent need in many bioinformatics applications. In addition to the large pool of techniques that have already been developed in the machine learning and data mining fields, specific applications in bioinformatics have led to a wealth of newly proposed techniques. In this article, we make the interested reader aware of the possibilities of feature selection, providing a basic taxonomy of feature selection techniques, and discussing their use, variety and potential in a number of both common as well as upcoming bioinformatics applications.},
archivePrefix = {arXiv},
arxivId = {10.1093/bioinformatics/btm344},
author = {Saeys, Yvan and Inza, I{\~{n}}aki and Larra{\~{n}}aga, Pedro},
doi = {10.1093/bioinformatics/btm344},
eprint = {bioinformatics/btm344},
file = {:Users/na399/GitHub/thesis/references/papers/Saeys, Inza, Larra{\~{n}}aga{\_}2007{\_}A review of feature selection techniques in bioinformatics{\_}Bioinformatics.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$r1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {rank:99,relevancy:D,topic:bioinformatics,type:review},
mendeley-tags = {rank:99,relevancy:D,topic:bioinformatics,type:review},
number = {19},
pages = {2507--2517},
pmid = {17720704},
primaryClass = {10.1093},
title = {{A review of feature selection techniques in bioinformatics}},
volume = {23},
year = {2007}
}
@inproceedings{Zhou2012,
abstract = {Alzheimer's Disease (AD) is the most common neurodegenerative disorder associated with aging. Understanding how the disease progresses and identifying related pathological biomarkers for the progression is of primary importance in Alzheimer's disease research. In this paper, we develop novel multi-task learning techniques to predict the disease progression measured by cognitive scores and select biomarkers predictive of the progression. In multi-task learning, the prediction of cognitive scores at each time point is considered as a task, and multiple prediction tasks at different time points are performed simultaneously to capture the temporal smoothness of the prediction models across different time points. Specifically, we propose a novel convex fused sparse group Lasso (cFSGL) formulation that allows the simultaneous selection of a common set of biomarkers for multiple time points and specific sets of biomarkers for different time points using the sparse group Lasso penalty and in the meantime incorporates the temporal smoothness using the fused Lasso penalty. The proposed formulation is challenging to solve due to the use of several non-smooth penalties. We show that the proximal operator associated with the proposed formulation exhibits a certain decomposition property and can be computed efficiently; thus cFSGL can be solved efficiently using the accelerated gradient method. To further improve the model, we propose two non-convex formulations to reduce the shrinkage bias inherent in the convex formulation. We employ the difference of convex programming technique to solve the non-convex formulations. Our extensive experiments using data from the Alzheimer's Disease Neuroimaging Initiative demonstrate the effectiveness of the proposed progression models in comparison with existing methods for disease progression. We also perform longitudinal stability selection to identify and analyze the temporal patterns of biomarkers in disease progression. {\textcopyright} 2012 ACM.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Zhou, Jiayu and Liu, Jun and Narayan, Vaibhav A. and Ye, Jieping},
booktitle = {Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '12},
doi = {10.1145/2339530.2339702},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/Zhou et al.{\_}2012{\_}Modeling disease progression via fused sparse group lasso{\_}Proceedings of the 18th ACM SIGKDD international conference o.pdf:pdf},
isbn = {9781450314626},
issn = {2154-817X},
keywords = {alzheimer,cognitive score,disease:dementia,fused,lasso,model:Lasso,multi-task learning,rank:90,regression,relevancy:A,s disease,sparse group lasso,topic:progression,type:research},
mendeley-tags = {disease:dementia,model:Lasso,rank:90,relevancy:A,topic:progression,type:research},
pages = {1095},
pmid = {25309808},
publisher = {ACM Press},
title = {{Modeling disease progression via fused sparse group lasso}},
url = {http://dl.acm.org/citation.cfm?doid=2339530.2339702},
year = {2012}
}
@article{Ramati2012,
abstract = {In many fields observations are performed irregularly along time, due to either measurement limitations or lack of a constant immanent rate. While discrete-time Markov models (as Dynamic Bayesian Networks) introduce either inefficient computation or an information loss to reasoning about such processes, continuous-time Markov models assume either a discrete state space (as Continuous-Time Bayesian Networks), or a flat continuous state space (as stochastic differential equations). To address these problems, we present a new modeling class called Irregular-Time Bayesian Networks (ITBNs), generalizing Dynamic Bayesian Networks, allowing substantially more compact representations, and increasing the expressivity of the temporal dynamics. In addition, a globally optimal solution is guaranteed when learning temporal systems, provided that they are fully observed at the same irregularly spaced time-points, and a semiparametric subclass of ITBNs is introduced to allow further adaptation to the irregular nature of the available data.},
archivePrefix = {arXiv},
arxivId = {1203.3510},
author = {Ramati, Michael and Shahar, Yuval},
eprint = {1203.3510},
file = {:Users/na399/GitHub/thesis/references/papers/Ramati, Shahar{\_}2012{\_}Irregular-Time Bayesian Networks{\_}Unknown.pdf:pdf},
isbn = {978-0-9749039-6-5},
keywords = {rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
month = {mar},
pages = {484--491},
title = {{Irregular-Time Bayesian Networks}},
url = {http://arxiv.org/abs/1203.3510},
year = {2012}
}
@article{Geerts2016,
abstract = {Massive investment and technological advances in the collection of extensive and longitudinal information on thousands of Alzheimer patients results in large amounts of data. These "big-data" databases can potentially advance CNS research and drug development. However, although necessary, they are not sufficient, and we posit that they must be matched with analytical methods that go beyond retrospective data-driven associations with various clinical phenotypes. Although these empirically derived associations can generate novel and useful hypotheses, they need to be organically integrated in a quantitative understanding of the pathology that can be actionable for drug discovery and development. We argue that mechanism-based modeling and simulation approaches, where existing domain knowledge is formally integrated using complexity science and quantitative systems pharmacology can be combined with data-driven analytics to generate predictive actionable knowledge for drug discovery programs, target validation, and optimization of clinical development.},
author = {Geerts, Hugo and Dacks, Penny A. and Devanarayan, Viswanath and Haas, Magali and Khachaturian, Zaven S. and Gordon, Mark Forrest and Maudsley, Stuart and Romero, Klaus and Stephenson, Diane},
doi = {10.1016/j.jalz.2016.04.008},
file = {:Users/na399/GitHub/thesis/references/papers/Geerts et al.{\_}2016{\_}Big data to smart data in Alzheimer's disease The brain health modeling initiative to foster actionable knowledge{\_}Alz.pdf:pdf},
isbn = {1552-5279 (Electronic)$\backslash$r1552-5260 (Linking)},
issn = {15525260},
journal = {Alzheimer's {\&} Dementia},
keywords = {Alzheimer's dementia,Brain disorders,Complexity theory,Drug discovery and development,Systems biology,Systems pharmacology,disease:dementia,rank:99,relevancy:B,topic:dataMining,type:review},
mendeley-tags = {rank:99,disease:dementia,topic:dataMining,relevancy:B,type:review},
month = {sep},
number = {9},
pages = {1014--1021},
pmid = {27238630},
publisher = {Elsevier Inc.},
title = {{Big data to smart data in Alzheimer's disease: The brain health modeling initiative to foster actionable knowledge}},
url = {http://dx.doi.org/10.1016/j.jalz.2016.04.008 http://www.ncbi.nlm.nih.gov/pubmed/27238630 http://linkinghub.elsevier.com/retrieve/pii/S1552526016302461},
volume = {12},
year = {2016}
}
@article{Prince2013,
abstract = {Background: The evidence base on the prevalence of dementia is expanding rapidly, particularly in countries with low and middle incomes. A reappraisal of global prevalence and numbers is due, given the significant implications for social and public policy and planning. Methods: In this study we provide a systematic review of the global literature on the prevalence of dementia (1980-2009) and metaanalysis to estimate the prevalence and numbers of those affected, aged ≥60 years in 21 Global Burden of Disease regions. Results: Age-standardized prevalence for those aged ≥60 years varied in a narrow band, 5{\%}-7{\%} in most world regions, with a higher prevalence in Latin America (8.5{\%}), and a distinctively lower prevalence in the four sub-Saharan African regions (2{\%}-4{\%}). It was estimated that 35.6 million people lived with dementia worldwide in 2010, with numbers expected to almost double every 20 years, to 65.7 million in 2030 and 115.4 million in 2050. In 2010, 58{\%} of all people with dementia lived in countries with low or middle incomes, with this proportion anticipated to rise to 63{\%} in 2030 and 71{\%} in 2050. Conclusion: The detailed estimates in this study constitute the best current basis for policymaking, planning, and allocation of health and welfare resources in dementia care. The age-specific prevalence of dementia varies little between world regions, and may converge further. Future projections of numbers of people with dementia may be modified substantially by preventive interventions (lowering incidence), improvements in treatment and care (prolonging survival), and disease-modifying interventions (preventing or slowing progression). All countries need to commission nationally representative surveys that are repeated regularly to monitor trends. {\textcopyright} 2013 The Alzheimer's Association. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Prince, Martin and Bryce, Renata and Albanese, Emiliano and Wimo, Anders and Ribeiro, Wagner and Ferri, Cleusa P.},
doi = {10.1016/j.jalz.2012.11.007},
eprint = {NIHMS150003},
file = {:Users/na399/OneDrive/Documents/NN/Alz/Awareness/Papers/Prince et al.{\_}2013{\_}The global prevalence of dementia A systematic review and metaanalysis{\_}Alzheimer's and Dementia.pdf:pdf},
isbn = {1552-5279 (Electronic)$\backslash$r1552-5260 (Linking)},
issn = {15525260},
journal = {Alzheimer's and Dementia},
keywords = {Dementia,Epidemiology,Metaanalysis,Prevalence,Projection,Systematic review,WHO Global Burden of Disease regions,Worldwide,disease:dementia,rank:99,relevancy:B,topic:impact,topic:prevalence,type:research},
mendeley-tags = {disease:dementia,rank:99,relevancy:B,topic:impact,topic:prevalence,type:research},
number = {1},
pages = {63--75},
pmid = {23305823},
publisher = {Elsevier Ltd},
title = {{The global prevalence of dementia: A systematic review and metaanalysis}},
url = {http://dx.doi.org/10.1016/j.jalz.2012.11.007},
volume = {9},
year = {2013}
}
@inproceedings{Choi2016,
abstract = {Modeling disease relationships and temporal progression are two key problems in health analytics, which have not been studied together due to data and technical challenges. Thanks to the increasing adoption of Electronic Health Records (EHR), rich patient information is being collected over time. Using EHR data as input, we propose a multivariate context-sensitive Hawkes process or cHawkes, which simultaneously infers the disease relationship network and models temporal progression of patients. Besides learning disease network and temporal progression model, cHawkes is able to predict when a specific patient might have other related diseases in future given the patient history, which in turn can have many potential applications in predictive health analytics, public health policy development and customized patient care. Extensive experiments on real EHR data demonstrate that cHawkes not only can uncover meaningful disease relations and model accurate temporal progression of patients, but also has significantly better predictive performance compared to several baseline models.},
author = {Choi, Edward and Du, Nan and Chen, Robert and Song, Le and Sun, Jimeng},
booktitle = {2015 IEEE International Conference on Data Mining},
doi = {10.1109/ICDM.2015.144},
file = {:Users/na399/GitHub/thesis/references/papers/Choi et al.{\_}2016{\_}Constructing disease network and temporal progression model via context-sensitive hawkes process{\_}Proceedings - IEEE Int.pdf:pdf},
isbn = {978-1-4673-9504-5},
issn = {15504786},
keywords = {Disease Prediction,Disease Relation,EHR,Hawkes Process,Health Analytics,Point Process,rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
month = {nov},
pages = {721--726},
publisher = {IEEE},
title = {{Constructing Disease Network and Temporal Progression Model via Context-Sensitive Hawkes Process}},
url = {http://ieeexplore.ieee.org/document/7373379/},
volume = {2016-Janua},
year = {2015}
}
@article{Salvatier2015,
abstract = {Probabilistic programming allows for automatic Bayesian inference on user-defined probabilistic models. Recent advances in Markov chain Monte Carlo (MCMC) sampling allow inference on increasingly complex models. This class of MCMC, known as Hamiltonian Monte Carlo, requires gradient information which is often not readily available. PyMC3 is a new open source probabilistic programming framework written in Python that uses Theano to compute gradients via automatic differentiation as well as compile probabilistic programs on-the-fly to C for increased speed. Contrary to other probabilistic programming languages, PyMC3 allows model specification directly in Python code. The lack of a domain specific language allows for great flexibility and direct interaction with the model. This paper is a tutorial-style introduction to this software package.},
archivePrefix = {arXiv},
arxivId = {1507.08050},
author = {Salvatier, John and Wiecki, Thomas V. and Fonnesbeck, Christopher},
doi = {10.7717/peerj-cs.55},
eprint = {1507.08050},
file = {:Users/na399/GitHub/thesis/references/papers/Salvatier, Wiecki, Fonnesbeck{\_}2016{\_}Probabilistic programming in Python using PyMC3{\_}PeerJ Computer Science.pdf:pdf},
isbn = {9783319238258},
issn = {2376-5992},
journal = {PeerJ Computer Science},
keywords = {bayesian statistic,markov chain monte carlo,probabilistic programming,python,rank:90,relevancy:A,statistical modeling,topic:platform,type:method},
mendeley-tags = {rank:90,relevancy:A,topic:platform,type:method},
month = {apr},
pages = {e55},
title = {{Probabilistic programming in Python using PyMC3}},
url = {http://arxiv.org/abs/1507.08050 https://peerj.com/articles/cs-55},
volume = {2},
year = {2016}
}
@article{Eapen2013,
abstract = {Objectives: The study sought to derive and validate risk-prediction tools from a large nationwide registry linked with Medicare claims data. Background: Few clinical models have been developed utilizing data elements readily available in electronic health records (EHRs) to facilitate " real-time" risk estimation. Methods: Heart failure (HF) patients ≥65 years of age hospitalized in the GWTG-HF (Get With The Guidelines-Heart Failure) program were linked with Medicare claims from January 2005 to December 2009. Multivariable models were developed for 30-day mortality after admission, 30-day rehospitalization after discharge, and 30-day mortality/rehospitalization after discharge. Candidate variables were selected based on availability in EHRs and prognostic value. The models were validated in a 30{\%} random sample and separately in patients with reduced and preserved ejection fraction (EF). Results: Among 33,349 patients at 160 hospitals, 3,002 (9.1{\%}) died within 30 days of admission, 7,020 (22.8{\%}) were rehospitalized within 30 days of discharge, and 8,374 (27.2{\%}) died or were rehospitalized within 30 days of discharge. Compared with patients classified as low risk, high-risk patients had significantly higher odds of death (odds ratio [OR]: 8.82, 95{\%} confidence interval [CI]: 7.58 to 10.26), rehospitalization (OR: 1.99, 95{\%} CI: 1.86 to 2.13), and death/rehospitalization (OR: 2.65, 95{\%} CI: 2.44 to 2.89). The 30-day mortality model demonstrated good discrimination (c-index 0.75) while the rehospitalization and death/rehospitalization models demonstrated more modest discrimination (c-indices of 0.59 and 0.62), with similar performance in the validation cohort and for patients with preserved and reduced EF. Conclusions: These predictive models allow for risk stratification of 30-day outcomes for patients hospitalized with HF and may provide a validated, point-of-care tool for clinical decision making. {\textcopyright} 2013 American College of Cardiology Foundation.},
author = {Eapen, Zubin J. and Liang, Li and Fonarow, Gregg C. and Heidenreich, Paul A. and Curtis, Lesley H. and Peterson, Eric D. and Hernandez, Adrian F.},
doi = {10.1016/j.jchf.2013.01.008},
file = {:Users/na399/GitHub/thesis/references/papers/Eapen et al.{\_}2013{\_}Validated, electronic health record deployable prediction models for assessing patient risk of 30-day rehospitalizatio.pdf:pdf},
isbn = {22131779 (ISSN)},
issn = {22131779},
journal = {JACC: Heart Failure},
keywords = {Electronic health records,Heart failure,Predictive models,Risk stratification,disease:CVD,model:logisticRegression,rank:95,relevancy:A,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:CVD,model:logisticRegression,rank:95,relevancy:A,topic:EHR,topic:prediction,type:research},
number = {3},
pages = {245--251},
pmid = {24621877},
title = {{Validated, electronic health record deployable prediction models for assessing patient risk of 30-day rehospitalization and mortality in older heart failure patients}},
volume = {1},
year = {2013}
}
@article{Moore2016a,
abstract = {BACKGROUND BioBin is a bioinformatics software package developed to automate the process of binning rare variants into groups for statistical association analysis using a biological knowledge-driven framework. BioBin collapses variants into biological features such as genes, pathways, evolutionary conserved regions (ECRs), protein families, regulatory regions, and others based on user-designated parameters. BioBin provides the infrastructure to create complex and interesting hypotheses in an automated fashion thereby circumventing the necessity for advanced and time consuming scripting. PURPOSE OF THE STUDY In this manuscript, we describe the software package for BioBin, along with type I error and power simulations to demonstrate the strengths and various customizable features and analysis options of this variant binning tool. RESULTS Simulation testing highlights the utility of BioBin as a fast, comprehensive and expandable tool for the biologically-inspired binning and analysis of low-frequency variants in sequence data. CONCLUSIONS AND POTENTIAL IMPLICATIONS The BioBin software package has the capability to transform and streamline the analysis pipelines for researchers analyzing rare variants. This automated bioinformatics tool minimizes the manual effort of creating genomic regions for binning such that time can be spent on the much more interesting task of statistical analyses. This software package is open source and freely available from http://ritchielab.com/software/biobin-download.},
author = {Moore, Carrie Colleen Buchanan and Basile, Anna Okula and Wallace, John Robert and Frase, Alex Thomas and Ritchie, Marylyn Deriggi},
doi = {10.1186/s13040-016-0107-3},
file = {:Users/na399/GitHub/thesis/references/papers/Moore et al.{\_}2016{\_}A biologically informed method for detecting rare variant associations{\_}BioData Mining.pdf:pdf},
isbn = {1304001601},
issn = {17560381},
journal = {BioData Mining},
keywords = {rank:70,relevancy:D},
mendeley-tags = {rank:70,relevancy:D},
number = {1},
pages = {1--15},
pmid = {27582876},
publisher = {BioData Mining},
title = {{A biologically informed method for detecting rare variant associations}},
url = {http://dx.doi.org/10.1186/s13040-016-0107-3},
volume = {9},
year = {2016}
}
@article{Castro2015,
abstract = {Objective: The study was designed to validate use of electronic health records (EHRs) for diagnosing bipolar disorder and classifying control subjects. Method: EHR data were obtained from a health care system of more than 4.6 million patients spanning more than 20 years. Experienced clinicians reviewed charts to identify text features and coded data consistent or inconsistent with a diagnosis of bipolar disorder. Natural language processing was used to train a diagnostic algorithm with 95{\%} specificity for classifying bipolar disorder. Filtered coded data were used to derive three additional classification rules for case subjects and one for control subjects. The positive predictive value (PPV) of EHR-based bipolar disorder and subphenotype diagnoses was calculated against diagnoses from direct semi-structured interviews of 190 patients by trained clinicians blind to EHR diagnosis. Results: The PPV of bipolar disorder defined by natural language processing was 0.85. Coded classification based on strict filtering achieved a value of 0.79, but classifications based on less stringent criteria performed less well. No EHR-classified control subject received a diagnosis of bipolar disorder on the basis of direct interview (PPV=1.0). For most subphenotypes, values exceeded 0.80. The EHR-based classifications were used to accrue 4,500 bipolar disorder cases and 5,000 controls for genetic analyses. Conclusions: Semiautomated mining of EHRs can be used to ascertain bipolar disorder patients and control subjects with high specificity and predictive value compared with diagnostic interviews. EHRs provide a powerful resource for high-throughput phenotyping for genetic and clinical research.},
author = {Castro, Victor M. and Minnier, Jessica and Murphy, Shawn N. and Kohane, Isaac and Churchill, Susanne E. and Gainer, Vivian and Cai, Tianxi and Hoffnagle, Alison G. and Dai, Yael and Block, Stefanie and Weill, Sydney R. and Nadal-Vicens, Mireya and Pollastri, Alisha R. and Rosenquist, J. Niels and Goryachev, Sergey and Ongur, Dost and Sklar, Pamela and Perlis, Roy H. and Smoller, Jordan W. and Lee, Phil Hyoun and Stahl, Eli A. and Purcell, Shaun M. and Ruderfer, Douglas M. and Charney, Alexander W. and Roussos, Panos and Pato, Carlos and Pato, Michele and Medeiros, Helen and Sobel, Janet and Craddock, Nick and Jones, Ian and Forty, Liz and DiFlorio, Arianna and Green, Elaine and Jones, Lisa and Dunjewski, Katherine and Land{\'{e}}n, Mikael and Hultman, Christina and Jur{\'{e}}us, Anders and Bergen, Sarah and Svantesson, Oscar and McCarroll, Steven and Moran, Jennifer and Chambert, Kimberly and Belliveau, Richard A.},
doi = {10.1176/appi.ajp.2014.14030423},
file = {:Users/na399/GitHub/thesis/references/papers/Castro et al.{\_}2015{\_}Validation of electronic health record phenotyping of bipolar disorder cases and controls{\_}American Journal of Psychia.pdf:pdf},
isbn = {0002-953X},
issn = {15357228},
journal = {American Journal of Psychiatry},
keywords = {disease:psychiatry,model:NLP,rank:99,relevancy:B,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {disease:psychiatry,model:NLP,rank:99,relevancy:B,topic:EHR,topic:phenotyping,type:research},
number = {4},
pages = {363--372},
pmid = {25827034},
title = {{Validation of electronic health record phenotyping of bipolar disorder cases and controls}},
volume = {172},
year = {2015}
}
@article{Choi2017a,
abstract = {Objective: We explored whether use of deep learning to model temporal relations among events in electronic health records (EHRs) would improve model performance in predicting initial diagnosis of heart failure (HF) compared to conventional methods that ignore temporality. Materials and Methods: Data were from a health system's EHR on 3884 incident HF cases and 28 903 controls, identified as primary care patients, between May 16, 2000, and May 23, 2013. Recurrent neural network (RNN) models using gated recurrent units (GRUs) were adapted to detect relations among time-stamped events (eg, disease diagnosis, medication orders, procedure orders, etc.) with a 12-to 18-month observation window of cases and controls. Model performance metrics were compared to regularized logistic regression, neural net-work, support vector machine, and K-nearest neighbor classifier approaches. Results: Using a 12-month observation window, the area under the curve (AUC) for the RNN model was 0.777, compared to AUCs for logistic regression (0.747), multilayer perceptron (MLP) with 1 hidden layer (0.765), sup-port vector machine (SVM) (0.743), and K-nearest neighbor (KNN) (0.730). When using an 18-month observation window, the AUC for the RNN model increased to 0.883 and was significantly higher than the 0.834 AUC for the best of the baseline methods (MLP). Conclusion: Deep learning models adapted to leverage temporal relations appear to improve performance of models for detection of incident heart failure with a short observation window of 12–18 months. OBJECTIVE Before diagnosis of a disease, an individual's progression mediated by pathophysiologic changes distinguishes those who will eventually get the disease from those who will not. Detection of temporal event sequences that reliably distinguish disease cases from controls may be particularly useful in improving predictive model performance. We investigated whether recurrent neural network (RNN) models could be adapted for this purpose, converting clinical event se-quences and related time-stamped data into pathways relevant to early detection of disease. Electronic health record (EHR) data capture rich clinical and re-lated temporal information. Patient health care encounters are well documented (eg, diagnoses, medications, and procedures) and time-stamped. However, EHR data are highly complex, given the struc-ture and breadth of information captured (spanning provider behav-ior, care utilization, treatment pathways, and patient disease state) and irregular sampling frequency. To date, most predictive modeling work using EHR data rely on aggregate features (eg, event count and event average). Temporal relations among disaggregated fea-tures (eg, medication ordered at one time and procedure performed at another) are not captured using these methods. We applied RNN models to heart failure (HF) cases and controls using longitudinal EHR data, and compared the model performance to traditional machine learning approaches. HF is one of the leading causes of morbidity and mortality among elderly individuals in de-veloped economies and accounts for significant and growing health care expenditures. 1,2 Improved early detection could open new op-portunities for delaying or preventing progression to diagnosis of HF and reduce cost.},
author = {Choi, Edward and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
doi = {10.1093/jamia/ocw112},
file = {:Users/na399/GitHub/thesis/references/papers/Choi et al.{\_}2017{\_}Using recurrent neural network models for early detection of heart failure onset{\_}Journal of the American Medical Inf(2).pdf:pdf},
isbn = {1527-974X (Electronic) 1067-5027 (Linking)},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Deep learning,Electronic health records,Heart failure prediction,Patient progression model,Recurrent neural network,disease:CVD,model:DeepLearning,rank:90,relevancy:B,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:CVD,model:DeepLearning,rank:90,relevancy:B,topic:EHR,topic:prediction,type:research},
number = {2},
pages = {361--370},
pmid = {27521897},
title = {{Using recurrent neural network models for early detection of heart failure onset}},
volume = {24},
year = {2017}
}
@article{Weuve2015,
abstract = {Clinical and population research on dementia and related neurologic conditions, including Alzheimer's disease, faces several unique methodological challenges. Progress to identify preventive and therapeutic strategies rests on valid and rigorous analytic approaches, but the research literature reflects little consensus on "best practices." We present findings from a large scientific working group on research methods for clinical and population studies of dementia, which identified five categories of methodological challenges as follows: (1) attrition/sample selection, including selective survival; (2) measurement, including uncertainty in diagnostic criteria, measurement error in neuropsychological assessments, and practice or retest effects; (3) specification of longitudinal models when participants are followed for months, years, or even decades; (4) time-varying measurements; and (5) high-dimensional data. We explain why each challenge is important in dementia research and how it could compromise the translation of research findings into effective prevention or care strategies. We advance a checklist of potential sources of bias that should be routinely addressed when reporting dementia research.},
author = {Weuve, Jennifer and Proust-Lima, C{\'{e}}cile and Power, Melinda C. and Gross, Alden L. and Hofer, Scott M. and Thi{\'{e}}baut, Rodolphe and Ch{\^{e}}ne, Genevi{\`{e}}ve and Glymour, M. Maria and Dufouil, Carole},
doi = {10.1016/j.jalz.2015.06.1885},
file = {:Users/na399/GitHub/thesis/references/papers/Weuve et al.{\_}2015{\_}Guidelines for reporting methodological challenges and evaluating potential bias in dementia research{\_}Alzheimer's {\&} De.pdf:pdf},
isbn = {1552-5279 (Electronic)$\backslash$r1552-5260 (Linking)},
issn = {15525260},
journal = {Alzheimer's {\&} Dementia},
keywords = {Alzheimer disease,Big data,Brain imaging,Dementia,Epidemiologic factors,Genomics,Longitudinal studies,Neuropsychological tests,Selection bias,Statistical models,Survival bias,disease:dementia,rank:99,relevancy:A,topic:bias,topic:diagnosis,type:review},
mendeley-tags = {rank:99,type:review,disease:dementia,topic:bias,topic:diagnosis,relevancy:A},
month = {sep},
number = {9},
pages = {1098--1109},
pmid = {26397878},
title = {{Guidelines for reporting methodological challenges and evaluating potential bias in dementia research}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1552526015021226},
volume = {11},
year = {2015}
}
@article{Sperling2011,
abstract = {The pathophysiological process of Alzheimer's disease (AD) is thought to begin many years before the diagnosis of AD dementia. This long "preclinical" phase of AD would provide a critical opportunity for therapeutic intervention; however, we need to further elucidate the link between the pathological cascade of AD and the emergence of clinical symptoms. The National Institute on Aging and the Alzheimer's Association convened an international workgroup to review the biomarker, epidemiological, and neuropsychological evidence, and to develop recommendations to determine the factors which best predict the risk of progression from "normal" cognition to mild cognitive impairment and AD dementia. We propose a conceptual framework and operational research criteria, based on the prevailing scientific evidence to date, to test and refine these models with longitudinal clinical research studies. These recommendations are solely intended for research purposes and do not have any clinical implications at this time. It is hoped that these recommendations will provide a common rubric to advance the study of preclinical AD, and ultimately, aid the field in moving toward earlier intervention at a stage of AD when some disease-modifying therapies may be most efficacious. {\textcopyright} 2011 The Alzheimer's Association. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Sperling, Reisa A. and Aisen, Paul S. and Beckett, Laurel A. and Bennett, David A. and Craft, Suzanne and Fagan, Anne M. and Iwatsubo, Takeshi and Jack, Clifford R. and Kaye, Jeffrey and Montine, Thomas J. and Park, Denise C. and Reiman, Eric M. and Rowe, Christopher C. and Siemers, Eric and Stern, Yaakov and Yaffe, Kristine and Carrillo, Maria C. and Thies, Bill and Morrison-Bogorad, Marcelle and Wagster, Molly V. and Phelps, Creighton H.},
doi = {10.1016/j.jalz.2011.03.003},
eprint = {NIHMS150003},
file = {:Users/na399/OneDrive/Documents/NN/Alz/Papers/Sperling et al.{\_}2011{\_}Toward defining the preclinical stages of Alzheimer's disease Recommendations from the National Institute on Aging-.pdf:pdf},
isbn = {1552-5279 (Electronic)$\backslash$r1552-5260 (Linking)},
issn = {15525260},
journal = {Alzheimer's and Dementia},
keywords = {Amyloid,Biomarker,Neurodegeneration,Preclinical Alzheimer's disease,Prevention,disease:dementia,rank:99,relevancy:A,topic:diagnostic criteria,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:A,topic:diagnostic criteria,type:commentary},
number = {3},
pages = {280--292},
pmid = {21514248},
publisher = {Elsevier Ltd},
title = {{Toward defining the preclinical stages of Alzheimer's disease: Recommendations from the National Institute on Aging-Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease}},
url = {http://dx.doi.org/10.1016/j.jalz.2011.03.003},
volume = {7},
year = {2011}
}
@article{Ji2016,
abstract = {Many patients suffer from comorbidity conditions; for example, obese patients often develop type-2 diabetes and hypertension. In the U.S., 80{\%} of Medicare spending is for managing patients with these multiple coexisting conditions. Predicting potential comorbidity conditions for an individual patient can promote preventive care and reduce costs. Predicting possible comorbidity progression paths can provide important insights into population heath and aid with decisions in public health policies. Discovering the comorbidity relationships is complex and difficult, due to limited access to electronic health records by privacy laws. In this paper, we present a collaborative comorbidity prediction method to predict likely comorbid conditions for individual patients, and a trajectory prediction graph model to reveal progression paths of comorbid conditions. Our prediction approaches utilize patient generated health reports on online social media, called social health records (SHR). The experimental results based on one SHR source show that our method is able to predict future comorbid conditions for a patient with coverage values of 48{\%} and 75{\%} for a top-20 and a top-100 ranked list, respectively. For risk trajectory prediction, our approach is able to reveal each potential progression trajectory between any two conditions and infer the confidence of the future trajectory, given any observed condition. The predicted trajectories are validated with existing comorbidity relations from the medical literature.},
author = {Ji, Xiang and Chun, Soon Ae and Geller, James},
doi = {10.1109/TNB.2016.2564299},
file = {:Users/na399/GitHub/thesis/references/papers/Ji, Chun, Geller{\_}2016{\_}Predicting Comorbid Conditions and Trajectories Using Social Health Records{\_}IEEE Transactions on Nanobioscience.pdf:pdf},
issn = {15361241},
journal = {IEEE Transactions on Nanobioscience},
keywords = {Collaborative prediction,comorbidity prediction,disease progression,mining social media,rank:85,relevancy:B,topic:comorbidity,topic:prediction,topic:trajectory,trajectory prediction,type:research},
mendeley-tags = {rank:85,type:research,topic:comorbidity,topic:trajectory,topic:prediction,relevancy:B},
number = {4},
pages = {371--379},
pmid = {27168600},
title = {{Predicting Comorbid Conditions and Trajectories Using Social Health Records}},
volume = {15},
year = {2016}
}
@article{Capobianco2017,
abstract = {Big Data, and in particular Electronic Health Records, provide the medical community with a great opportunity to analyze multiple pathological conditions at an unprecedented depth for many complex diseases, including diabetes. How can we infer on diabetes from large heterogeneous datasets? A possible solution is provided by invoking next-generation computational methods and data analytics tools within systems medicine approaches. By deciphering the multi-faceted complexity of biological systems, the potential of emerging diagnostic tools and therapeutic functions can be ultimately revealed. In diabetes, a multidimensional approach to data analysis is needed to better understand the disease conditions, trajectories and the associated comorbidities. Elucidation of multidimensionality comes from the analysis of factors such as disease phenotypes, marker types, and biological motifs while seeking to make use of multiple levels of information including genetics, omics, clinical data, and environmental and lifestyle factors. Examining the synergy between multiple dimensions represents a challenge. In such regard, the role of Big Data fuels the rise of Precision Medicine by allowing an increasing number of descriptions to be captured from individuals. Thus, data curations and analyses should be designed to deliver highly accurate predicted risk profiles and treatment recommendations. It is important to establish linkages between systems and precision medicine in order to translate their principles into clinical practice. Equivalently, to realize their full potential, the involved multiple dimensions must be able to process information ensuring inter-exchange, reducing ambiguities and redundancies, and ultimately improving health care solutions by introducing clinical decision support systems focused on reclassified phenotypes (or digital biomarkers) and community-driven patient stratifications.},
author = {Capobianco, Enrico},
doi = {10.1186/s40169-017-0155-4},
file = {:Users/na399/GitHub/thesis/references/papers/Capobianco{\_}2017{\_}Systems and precision medicine approaches to diabetes heterogeneity a Big Data perspective{\_}Clinical and Translational Me.pdf:pdf},
issn = {2001-1326},
journal = {Clinical and Translational Medicine},
keywords = {Diabetes,Electronic,Systems and precision medicine,diabetes,disease:diabetes,electronic health records,rank:85,relevancy:B,systems and precision medicine,topic:EHR,type:analysis},
mendeley-tags = {rank:85,type:analysis,disease:diabetes,topic:EHR,relevancy:B},
number = {1},
pages = {23},
pmid = {28744848},
publisher = {Springer Berlin Heidelberg},
title = {{Systems and precision medicine approaches to diabetes heterogeneity: a Big Data perspective}},
url = {http://clintransmed.springeropen.com/articles/10.1186/s40169-017-0155-4},
volume = {6},
year = {2017}
}
@incollection{Payne2016,
abstract = {The field of Biomedical Informatics (BMI) is concerned with multimethod approaches to generating contextualized information and actionable knowledge from a variety of biological and healthcare-relevant data types. In doing so, BMI practitioners adopt and adapt a number of methods drawn from the computational, quantitative, and qualitative sciences. In this chapter, we provide an overview of such methods and a rationale for how they can be applied to address driving biological and clinical problems. Such use cases span a range from the biomolecular characterization of disease states to the comprehensive phenotyping of patients to the promotion of population health. In doing so, we hope to equip readers with the ability to critically understand and evaluate the use of multimethod approaches as are commonly encountered in the aforementioned application areas.},
author = {Payne, Philip R.O.},
booktitle = {Genomic and Precision Medicine},
doi = {10.1016/B978-0-12-800681-8.00006-2},
edition = {Third Edit},
file = {:Users/na399/GitHub/thesis/references/papers/Payne{\_}2016{\_}From Data to Knowledge An Introduction to Biomedical Informatics{\_}Genomic and Precision Medicine Foundations, Translation, and.pdf:pdf},
isbn = {9780128006818},
keywords = {Biomedical informatics,Computer science,Data science,Evaluation,Qualitative research,Research design,rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
pages = {89--104},
publisher = {Elsevier},
title = {{From Data to Knowledge}},
url = {http://dx.doi.org/10.1016/B978-0-12-800681-8.00006-2 http://linkinghub.elsevier.com/retrieve/pii/B9780128006818000062},
year = {2017}
}
@article{Adkins2017,
author = {Adkins, Daniel E.},
doi = {10.1176/appi.ajp.2016.16101169},
file = {:Users/na399/GitHub/thesis/references/papers/Adkins{\_}2017{\_}Machine learning and electronic health records A paradigm shift{\_}American Journal of Psychiatry.pdf:pdf},
issn = {15357228},
journal = {American Journal of Psychiatry},
keywords = {disease:psychiatry,rank:99,relevancy:A,topic:EHR,topic:prediction,type:commentary},
mendeley-tags = {disease:psychiatry,rank:99,relevancy:A,topic:EHR,topic:prediction,type:commentary},
number = {2},
pages = {93--94},
pmid = {28142275},
title = {{Machine learning and electronic health records: A paradigm shift}},
volume = {174},
year = {2017}
}
@article{Denaxas2017,
abstract = {The ability of external investigators to reproduce published scientific findings is critical for the evaluation and validation of biomedical research by the wider community. However, a substantial proportion of health research using electronic health records (EHR), data collected and generated during clinical care, is potentially not reproducible mainly due to the fact that the implementation details of most data preprocessing, cleaning, phenotyping and analysis approaches are not systematically made available or shared. With the complexity, volume and variety of electronic health record data sources made available for research steadily increasing, it is critical to ensure that scientific findings from EHR data are reproducible and replicable by researchers. Reporting guidelines, such as RECORD and STROBE, have set a solid foundation by recommending a series of items for researchers to include in their research outputs. Researchers however often lack the technical tools and methodological approaches to actuate such recommendations in an efficient and sustainable manner. In this paper, we review and propose a series of methods and tools utilized in adjunct scientific disciplines that can be used to enhance the reproducibility of research using electronic health records and enable researchers to report analytical approaches in a transparent manner. Specifically, we discuss the adoption of scientific software engineering principles and best-practices such as test-driven development, source code revision control systems, literate programming and the standardization and re-use of common data management and analytical approaches. The adoption of such approaches will enable scientists to systematically document and share EHR analytical workflows and increase the reproducibility of biomedical research using such complex data sources.},
author = {Denaxas, Spiros and Direk, Kenan and Gonzalez-Izquierdo, Arturo and Pikoula, Maria and Cakiroglu, Aylin and Moore, Jason and Hemingway, Harry and Smeeth, Liam},
doi = {10.1186/s13040-017-0151-7},
file = {:Users/na399/GitHub/thesis/references/papers/Denaxas et al.{\_}2017{\_}Methods for enhancing the reproducibility of biomedical research findings using electronic health records{\_}BioData Mi.pdf:pdf},
issn = {17560381},
journal = {BioData Mining},
keywords = {Biomedical research,Electronic health records,Reproducibility,Transparency,rank:70,relevancy:B},
mendeley-tags = {rank:70,relevancy:B},
number = {1},
pages = {1--19},
pmid = {28912836},
publisher = {BioData Mining},
title = {{Methods for enhancing the reproducibility of biomedical research findings using electronic health records}},
volume = {10},
year = {2017}
}
@inproceedings{Ma2017a,
abstract = {Predicting the future health information of patients from the historical Electronic Health Records (EHR) is a core research task in the development of personalized healthcare. Patient EHR data consist of sequences of visits over time, where each visit contains multiple medical codes, including diagnosis, medication, and procedure codes. The most important challenges for this task are to model the temporality and high dimensionality of sequential EHR data and to interpret the prediction results. Existing work solves this problem by employing recurrent neural networks (RNNs) to model EHR data and utilizing simple attention mechanism to interpret the results. However, RNN-based approaches suffer from the problem that the performance of RNNs drops when the length of sequences is large, and the relationships between subsequent visits are ignored by current RNN-based approaches. To address these issues, we propose {\{}$\backslash$sf Dipole{\}}, an end-to-end, simple and robust model for predicting patients' future health information. Dipole employs bidirectional recurrent neural networks to remember all the information of both the past visits and the future visits, and it introduces three attention mechanisms to measure the relationships of different visits for the prediction. With the attention mechanisms, Dipole can interpret the prediction results effectively. Dipole also allows us to interpret the learned medical code representations which are confirmed positively by medical experts. Experimental results on two real world EHR datasets show that the proposed Dipole can significantly improve the prediction accuracy compared with the state-of-the-art diagnosis prediction approaches and provide clinically meaningful interpretation.},
address = {New York, New York, USA},
archivePrefix = {arXiv},
arxivId = {1706.05764},
author = {Ma, Fenglong and Chitta, Radha and Zhou, Jing and You, Quanzeng and Sun, Tong and Gao, Jing},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '17},
doi = {10.1145/3097983.3098088},
eprint = {1706.05764},
file = {:Users/na399/GitHub/thesis/references/papers/Ma et al.{\_}2017{\_}Dipole{\_}Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining - KDD '17.pdf:pdf},
isbn = {9781450348874},
keywords = {bidirectional recurrent neural networks,disease:diabetes,healthcare informatics,model:DeepLearning,rank:90,relevancy:B,topic:prediction,type:research},
mendeley-tags = {disease:diabetes,model:DeepLearning,rank:90,relevancy:B,topic:prediction,type:research},
month = {jun},
pages = {1903--1911},
publisher = {ACM Press},
title = {{Dipole: Diagnosis Prediction in Healthcare via Attention-based Bidirectional Recurrent Neural Networks}},
url = {http://arxiv.org/abs/1706.05764{\%}0Ahttp://dx.doi.org/10.1145/3097983.3098088 http://arxiv.org/abs/1706.05764 http://dx.doi.org/10.1145/3097983.3098088 http://dl.acm.org/citation.cfm?doid=3097983.3098088},
year = {2017}
}
@article{Wu2016a,
abstract = {Dementia is receiving increasing attention from governments and politicians. Epidemiological research based on western European populations done 20 years ago provided key initial evidence for dementia policy making, but these estimates are now out of date because of changes in life expectancy, living conditions, and health profiles. To assess whether dementia occurrence has changed during the past 20–30 years, investigators of five different studies done in western Europe (Sweden [Stockholm and Gothenburg], the Netherlands [Rotterdam], the UK [England], and Spain [Zaragoza]) have compared dementia occurrence using consistent research methods between two timepoints in well-defined geographical areas. Findings from four of the five studies showed non-significant changes in overall dementia occurrence. The only significant reduction in overall prevalence was found in the study done in the UK, powered and designed explicitly from its outset to detect change across generations (decrease in prevalence of 22{\%}; p=0{\textperiodcentered}003). Findings from the study done in Zaragoza (Spain) showed a significant reduction in dementia prevalence in men (43{\%}; p=0{\textperiodcentered}0002). The studies estimating incidence done in Stockholm and Rotterdam reported non-significant reductions. Such reductions could be the outcomes from earlier population-level investments such as improved education and living conditions, and better prevention and treatment of vascular and chronic conditions. This evidence suggests that attention to optimum health early in life might benefit cognitive health late in life. Policy planning and future research should be balanced across primary (policies reducing risk and increasing cognitive reserve), secondary (early detection and screening), and tertiary (once dementia is present) prevention. Each has their place, but upstream primary prevention has the largest effect on reduction of later dementia occurrence and disability.},
author = {Wu, Yu-Tzu and Fratiglioni, Laura and Matthews, Fiona E and Lobo, Antonio and Breteler, Monique M B and Skoog, Ingmar and Brayne, Carol},
doi = {10.1016/S1474-4422(15)00092-7},
file = {:Users/na399/Downloads/Research Papers/Wu et al.{\_}2016{\_}Dementia in western Europe epidemiological evidence and implications for policy making{\_}The Lancet Neurology.pdf:pdf},
isbn = {1474-4422(Print)},
issn = {14744422},
journal = {The Lancet Neurology},
keywords = {disease:dementia,rank:99,relevancy:C,topic:impact,type:analysis},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:impact,type:analysis},
number = {1},
pages = {116--124},
pmid = {26300044},
publisher = {Elsevier Ltd},
title = {{Dementia in western Europe: epidemiological evidence and implications for policy making}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474442215000927},
volume = {15},
year = {2016}
}
@article{Litvin2012,
abstract = {Innovative methods are needed to incorporate effective geriatric education into internal medicine residency programs. The purpose of this report is to describe the development and use of clinical decision-support (CDS) tools to facilitate geriatric education and improve the care delivered to older adults in an academic internal medicine residency ambulatory care clinic. Starting in 2009, CDS tools were implemented as a major strategy of an initiative to improve resident physician clinical competencies in geriatrics and improve the quality of care and quality of life of older adults. These tools, designed to improve resident assessment and action for each of three educational modules (falls, vision, and dementia) were embedded within the ambulatory electronic medical record (EMR) and provided a method of point-of-care training to residents caring for older adults. One hundred internal medicine residents supervised by 17 general internal medicine faculty members participated. Data regarding CDS use and associated outcomes were recorded and extracted from the ambulatory clinic EMR. Residents screened between 67{\%} and 88{\%} of eligible patients using CDS algorithms; rates of additional assessment and referral or further examination reflected the prevalence of the condition in the patient population. Although further development may be necessary, CDS tools are a promising modality to supplement geriatric postgraduate education while simultaneously improving patient care.},
author = {Litvin, Cara B. and Davis, Kimberly S. and Moran, William P. and Iverson, Patty J. and Zhao, Yumin and Zapka, Jane},
doi = {10.1111/j.1532-5415.2012.03960.x},
file = {:Users/na399/GitHub/thesis/references/papers/Litvin et al.{\_}2012{\_}The use of clinical decision-support tools to facilitate geriatric education{\_}Journal of the American Geriatrics Socie.pdf:pdf},
isbn = {1532-5415 (Electronic)$\backslash$r0002-8614 (Linking)},
issn = {00028614},
journal = {Journal of the American Geriatrics Society},
keywords = {Ambulatory care,Clinical decision support,Electronic health records,Geriatrics,Medical education,rank:75,relevancy:D},
mendeley-tags = {rank:75,relevancy:D},
number = {6},
pages = {1145--1149},
pmid = {22642270},
title = {{The use of clinical decision-support tools to facilitate geriatric education}},
volume = {60},
year = {2012}
}
@article{Razavian2016,
abstract = {Disparate areas of machine learning have benefited from models that can take raw data with little preprocessing as input and learn rich representations of that raw data in order to perform well on a given prediction task. We evaluate this approach in healthcare by using longitudinal measurements of lab tests, one of the more raw signals of a patient's health state widely available in clinical data, to predict disease onsets. In particular, we train a Long Short-Term Memory (LSTM) recurrent neural network and two novel convolutional neural networks for multi-task prediction of disease onset for 133 conditions based on 18 common lab tests measured over time in a cohort of 298K patients derived from 8 years of administrative claims data. We compare the neural networks to a logistic regression with several hand-engineered, clinically relevant features. We find that the representation-based learning approaches significantly outperform this baseline. We believe that our work suggests a new avenue for patient risk stratification based solely on lab results.},
archivePrefix = {arXiv},
arxivId = {1608.00647},
author = {Razavian, Narges and Marcus, Jake and Sontag, David},
eprint = {1608.00647},
file = {:Users/na399/GitHub/thesis/references/papers/Razavian, Marcus, Sontag{\_}2016{\_}Multi-task Prediction of Disease Onsets from Longitudinal Lab Tests{\_}Unknown.pdf:pdf},
issn = {1938-7228},
keywords = {rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
pages = {1--27},
title = {{Multi-task Prediction of Disease Onsets from Longitudinal Lab Tests}},
url = {http://arxiv.org/abs/1608.00647},
year = {2016}
}
@inproceedings{Rallapalli2016,
author = {Rallapalli, Sreekanth and Suryakanthi, T.},
booktitle = {2016 International Conference on Advances in Computing and Communication Engineering (ICACCE)},
doi = {10.1109/ICACCE.2016.8073762},
file = {:Users/na399/GitHub/thesis/references/papers/Rallapalli, Suryakanthi{\_}2016{\_}Predicting the risk of diabetes in big data electronic health Records by using scalable random forest class.pdf:pdf},
isbn = {978-1-5090-2576-3},
keywords = {algorithm,big data,classification,cloud,ehr,predictive model,random forest,rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
month = {nov},
pages = {281--284},
publisher = {IEEE},
title = {{Predicting the risk of diabetes in big data electronic health Records by using scalable random forest classification algorithm}},
url = {http://ieeexplore.ieee.org/document/8073762/},
year = {2016}
}
@article{Hickman2016,
abstract = {Alzheimer disease (AD) represents one of the greatest medical challenges of this century; the condition is becoming increasingly prevalent worldwide and no effective treatments have been developed for this terminal disease. Because the disease manifests at a late stage after a long period of clinically silent neurodegeneration, knowledge of the modifiable risk factors and the implementation of biomarkers is crucial in the primary prevention of the disease and presymptomatic detection of AD, respectively. This article discusses the growing epidemic of AD and antecedent risk factors in the disease process. Disease biomarkers are discussed, and the implications that this may have for the treatment of this currently incurable disease.},
author = {Hickman, Richard A. and Faustin, Arline and Wisniewski, Thomas},
doi = {10.1016/j.ncl.2016.06.009},
file = {:Users/na399/Downloads/Research Papers/Hickman, Faustin, Wisniewski{\_}2016{\_}Alzheimer Disease and Its Growing Epidemic Risk Factors, Biomarkers, and the Urgent Need for Therapeut.pdf:pdf},
isbn = {9780323476904},
issn = {15579875},
journal = {Neurologic Clinics},
keywords = {Alzheimer disease,Biomarkers,Epidemiology,Risk factors,disease:dementia,rank:75,relevancy:C},
mendeley-tags = {rank:75,relevancy:C,disease:dementia},
number = {4},
pages = {941--953},
pmid = {27720002},
title = {{Alzheimer Disease and Its Growing Epidemic: Risk Factors, Biomarkers, and the Urgent Need for Therapeutics}},
volume = {34},
year = {2016}
}
@article{McKhann2011,
abstract = {The National Institute on Aging and the Alzheimer's Association charged a workgroup with the task of revising the 1984 criteria for Alzheimer's disease (AD) dementia. The workgroup sought to ensure that the revised criteria would be flexible enough to be used by both general healthcare providers without access to neuropsychological testing, advanced imaging, and cerebrospinal fluid measures, and specialized investigators involved in research or in clinical trial studies who would have these tools available. We present criteria for all-cause dementia and for AD dementia. We retained the general framework of probable AD dementia from the 1984 criteria. On the basis of the past 27 years of experience, we made several changes in the clinical criteria for the diagnosis. We also retained the term possible AD dementia, but redefined it in a manner more focused than before. Biomarker evidence was also integrated into the diagnostic formulations for probable and possible AD dementia for use in research settings. The core clinical criteria for AD dementia will continue to be the cornerstone of the diagnosis in clinical practice, but biomarker evidence is expected to enhance the pathophysiological specificity of the diagnosis of AD dementia. Much work lies ahead for validating the biomarker diagnosis of AD dementia. {\textcopyright} 2011 The Alzheimer's Association. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {McKhann, Guy M. and Knopman, David S. and Chertkow, Howard and Hyman, Bradley T. and Jack, Clifford R. and Kawas, Claudia H. and Klunk, William E. and Koroshetz, Walter J. and Manly, Jennifer J. and Mayeux, Richard and Mohs, Richard C. and Morris, John C. and Rossor, Martin N. and Scheltens, Philip and Carrillo, Maria C. and Thies, Bill and Weintraub, Sandra and Phelps, Creighton H.},
doi = {10.1016/j.jalz.2011.03.005},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/McKhann et al.{\_}2011{\_}The diagnosis of dementia due to Alzheimer's disease Recommendations from the National Institute on Aging-Alzheimer'.pdf:pdf},
isbn = {1552-5279 (Electronic)$\backslash$n1552-5260 (Linking)},
issn = {15525260},
journal = {Alzheimer's and Dementia},
keywords = {Alzheimer's disease,Cerebrospinal fluid,Dementia,Diagnosis,Magnetic resonance brain imaging,Positron emission tomography,disease:dementia,rank:99,relevancy:B,topic:diagnosis,topic:diagnostic criteria,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:B,topic:diagnosis,topic:diagnostic criteria,type:commentary},
number = {3},
pages = {263--269},
pmid = {21514250},
publisher = {Elsevier Ltd},
title = {{The diagnosis of dementia due to Alzheimer's disease: Recommendations from the National Institute on Aging-Alzheimer's Association workgroups on diagnostic guidelines for Alzheimer's disease}},
url = {http://dx.doi.org/10.1016/j.jalz.2011.03.005},
volume = {7},
year = {2011}
}
@article{Kirby2016,
abstract = {OBJECTIVE Health care generated data have become an important source for clinical and genomic research. Often, investigators create and iteratively refine phenotype algorithms to achieve high positive predictive values (PPVs) or sensitivity, thereby identifying valid cases and controls. These algorithms achieve the greatest utility when validated and shared by multiple health care systems.Materials and MethodsWe report the current status and impact of the Phenotype KnowledgeBase (PheKB,http://phekb.org), an online environment supporting the workflow of building, sharing, and validating electronic phenotype algorithms. We analyze the most frequent components used in algorithms and their performance at authoring institutions and secondary implementation sites. RESULTS As of June 2015, PheKB contained 30 finalized phenotype algorithms and 62 algorithms in development spanning a range of traits and diseases. Phenotypes have had over 3500 unique views in a 6-month period and have been reused by other institutions. International Classification of Disease codes were the most frequently used component, followed by medications and natural language processing. Among algorithms with published performance data, the median PPV was nearly identical when evaluated at the authoring institutions (n = 44; case 96.0{\%}, control 100{\%}) compared to implementation sites (n = 40; case 97.5{\%}, control 100{\%}). DISCUSSION These results demonstrate that a broad range of algorithms to mine electronic health record data from different health systems can be developed with high PPV, and algorithms developed at one site are generally transportable to others. CONCLUSION By providing a central repository, PheKB enables improved development, transportability, and validity of algorithms for research-grade phenotypes using health care generated data.},
author = {Kirby, Jacqueline C. and Speltz, Peter and Rasmussen, Luke V. and Basford, Melissa and Gottesman, Omri and Peissig, Peggy L. and Pacheco, Jennifer A. and Tromp, Gerard and Pathak, Jyotishman and Carrell, David S. and Ellis, Stephen B. and Lingren, Todd and Thompson, Will K. and Savova, Guergana and Haines, Jonathan and Roden, Dan M. and Harris, Paul A. and Denny, Joshua C.},
doi = {10.1093/jamia/ocv202},
file = {:Users/na399/GitHub/thesis/references/papers/Kirby et al.{\_}2016{\_}PheKB A catalog and workflow for creating electronic phenotype algorithms for transportability{\_}Journal of the American.pdf:pdf},
isbn = {1527-974X (Electronic) 1067-5027 (Linking)},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Clinical research,Electronic health records,Electronic phenotyping,Genomic research,Natural language processing,rank:90,relevancy:C,topic:EHR,topic:phenotyping,topic:platform,type:research},
mendeley-tags = {rank:90,relevancy:C,topic:EHR,topic:phenotyping,topic:platform,type:research},
number = {6},
pages = {1046--1052},
pmid = {27026615},
title = {{PheKB: A catalog and workflow for creating electronic phenotype algorithms for transportability}},
volume = {23},
year = {2016}
}
@article{Chen2012,
abstract = {Considerable evidence suggests that during the progression of complex diseases, the deteriorations are not necessarily smooth but are abrupt, and may cause a critical transition from one state to another at a tipping point. Here, we develop a model-free method to detect early-warning signals of such critical transitions, even with only a small number of samples. Specifically, we theoretically derive an index based on a dynamical network biomarker (DNB) that serves as a general early-warning signal indicating an imminent bifurcation or sudden deterioration before the critical transition occurs. Based on theoretical analyses, we show that predicting a sudden transition from small samples is achievable provided that there are a large number of measurements for each sample, e.g., high-throughput data. We employ microarray data of three diseases to demonstrate the effectiveness of our method. The relevance of DNBs with the diseases was also validated by related experimental data and functional analysis.},
author = {Chen, Luonan and Liu, Rui and Liu, Zhi Ping and Li, Meiyi and Aihara, Kazuyuki},
doi = {10.1038/srep00342},
file = {:Users/na399/GitHub/thesis/references/papers/Chen et al.{\_}2012{\_}Detecting early-warning signals for sudden deterioration of complex diseases by dynamical network biomarkers{\_}Scientific.pdf:pdf},
isbn = {2045-2322 (Electronic)$\backslash$r2045-2322 (Linking)},
issn = {20452322},
journal = {Scientific Reports},
keywords = {disease:general,model:network,rank:95,relevancy:C,topic:bioinformatics,topic:prediction,type:research},
mendeley-tags = {disease:general,model:network,rank:95,relevancy:C,topic:bioinformatics,topic:prediction,type:research},
pages = {18--20},
pmid = {22461973},
title = {{Detecting early-warning signals for sudden deterioration of complex diseases by dynamical network biomarkers}},
volume = {2},
year = {2012}
}
@article{Bright2012,
author = {Bright, Tiffani J. and Wong, Anthony and Dhurjati, Ravi and Bristow, Erin and Bastian, Lori and Coeytaux, Remy R. and Samsa, Gregory and Hasselblad, Vic and Williams, John W. and Musty, Michael D. and Wing, Liz and Kendrick, Amy S. and Sanders, Gillian D. and Lobach, David},
doi = {10.7326/0003-4819-157-1-201207030-00450},
file = {:Users/na399/GitHub/thesis/references/papers/Bright, Wong, ...{\_}2012{\_}Annals of Internal Medicine Review Effect of Clinical Decision-Support Systems{\_}Annals of Internal Medicine.pdf:pdf},
issn = {0003-4819},
journal = {Annals of Internal Medicine},
keywords = {disease:general,rank:95,relevancy:C,topic:CDSS,type:review},
mendeley-tags = {disease:general,rank:95,relevancy:C,topic:CDSS,type:review},
month = {jul},
number = {1},
pages = {29},
title = {{Effect of Clinical Decision-Support Systems}},
url = {http://annals.org/article.aspx?doi=10.7326/0003-4819-157-1-201207030-00450},
volume = {157},
year = {2012}
}
@article{Jiang2016,
abstract = {The Quality Data Model (QDM) is an information model developed by the National Quality Forum for representing electronic health record (EHR)-based electronic clinical quality measures (eCQMs). In conjunction with the HL7 Health Quality Measures Format (HQMF), QDM contains core elements that make it a promising model for representing EHR-driven phenotype algorithms for clinical research. However, the current QDM specification is available only as descriptive documents suitable for human readability and interpretation, but not for machine consumption. The objective of the present study is to develop and evaluate a data element repository (DER) for providing machine-readable QDM data element service APIs to support phenotype algorithm authoring and execution. We used the ISO/IEC 11179 metadata standard to capture the structure for each data element, and leverage Semantic Web technologies to facilitate semantic representation of these metadata. We observed there are a number of underspecified areas in the QDM, including the lack of model constraints and pre-defined value sets. We propose a harmonization with the models developed in HL7 Fast Healthcare Interoperability Resources (FHIR) and Clinical Information Modeling Initiatives (CIMI) to enhance the QDM specification and enable the extensibility and better coverage of the DER. We also compared the DER with the existing QDM implementation utilized within the Measure Authoring Tool (MAT) to demonstrate the scalability and extensibility of our DER-based approach.},
author = {Jiang, Guoqian and Kiefer, Richard C. and Rasmussen, Luke V. and Solbrig, Harold R. and Mo, Huan and Pacheco, Jennifer A. and Xu, Jie and Montague, Enid and Thompson, William K. and Denny, Joshua C. and Chute, Christopher G. and Pathak, Jyotishman},
doi = {10.1016/j.jbi.2016.07.008},
file = {:Users/na399/GitHub/thesis/references/papers/Jiang et al.{\_}2016{\_}Developing a data element repository to support EHR-driven phenotype algorithm authoring and execution{\_}Journal of Biom.pdf:pdf},
isbn = {1532-0464},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {HL7 Fast Healthcare Interoperability Resources (FH,Metadata standards,Phenotype algorithms,Quality Data Model (QDM),Semantic Web technology,rank:85,relevancy:C,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {rank:85,type:research,relevancy:C,topic:EHR,topic:phenotyping},
pages = {232--242},
pmid = {27392645},
publisher = {Elsevier Inc.},
title = {{Developing a data element repository to support EHR-driven phenotype algorithm authoring and execution}},
url = {http://dx.doi.org/10.1016/j.jbi.2016.07.008},
volume = {62},
year = {2016}
}
@article{Yoo2011,
author = {Yoo, Seunghyun and Yoo, Changwon},
file = {:Users/na399/GitHub/thesis/references/papers/Yoo, Yoo{\_}2011{\_}A statistical model that calculates the life time risk of Alzheimer ' s disease using Bayesian Networks{\_}Unknown.pdf:pdf},
keywords = {alzheimer lifetime risk,bayesian networks,key genes of alzheimer,rank:n/a,relevancy:A,s disease},
mendeley-tags = {rank:n/a,relevancy:A},
number = {December},
pages = {12--16},
title = {{A statistical model that calculates the life time risk of Alzheimer ' s disease using Bayesian Networks}},
year = {2011}
}
@inproceedings{Sukkar2012,
abstract = {The development of novel treatments for many slowly progressing diseases, such as Alzheimer's disease (AD), is dependent on the ability to monitor and detect changes in disease progression. In some diseases the distinct clinical stages of the disease progress far too slowly to enable a quick evaluation of the efficacy of a given proposed treatment. To help improve the assessment of disease progression, we propose using Hidden Markov Models (HMM's) to model, in a more granular fashion, disease progression as compared to the clinical stages of the disease. Unlike many other applications of Hidden Markov Models, we train our HMM in an unsupervised way and then evaluate how effective the model is at uncovering underlying statistical patterns in disease progression by considering HMM states as disease stages. In this study, we focus on AD and show that our model, when evaluated on the cross validation data, can identify more granular disease stages than the three currently accepted clinical stages of "Normal", "MCI" (Mild Cognitive Impairment), and "AD".},
author = {Sukkar, Rafid and Katz, Elyse and {Yanwei Zhang} and Raunig, David and Wyman, Bradley T.},
booktitle = {2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society},
doi = {10.1109/EMBC.2012.6346556},
file = {:Users/na399/GitHub/thesis/references/papers/Sukkar et al.{\_}2012{\_}Disease progression modeling using Hidden Markov Models.{\_}Conference proceedings ... Annual International Conference.pdf:pdf},
isbn = {978-1-4577-1787-1},
issn = {1557-170X},
keywords = {Biomedical signal classification,Markov models in signal pattern classification,disease:dementia,model:Markov,rank:20,relevancy:A},
mendeley-tags = {rank:20,relevancy:A,disease:dementia,model:Markov},
month = {aug},
pages = {2845--2848},
pmid = {23366517},
publisher = {IEEE},
title = {{Disease progression modeling using Hidden Markov Models}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6346556{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/23366517 http://ieeexplore.ieee.org/document/6346556/},
volume = {2012},
year = {2012}
}
@inproceedings{Yan2014,
author = {Yan, Jingwen and Huang, Heng and Kim, Sungeun and Moore, Jason and Saykin, Andrew and Shen, Li},
booktitle = {2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)},
doi = {10.1109/ISBI.2014.6867958},
file = {:Users/na399/GitHub/thesis/references/papers/Yan et al.{\_}2014{\_}Joint identification of imaging and proteomics biomarkers of Alzheimer's disease using network-guided sparse learning{\_}20.pdf:pdf},
isbn = {978-1-4673-1961-4},
keywords = {Alzheimer{\"{i}}¿½s Disease,Brain imaging,Computer aided detection and diagnosis,rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
month = {apr},
number = {1},
pages = {665--668},
publisher = {IEEE},
title = {{Joint identification of imaging and proteomics biomarkers of Alzheimer's disease using network-guided sparse learning}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6867958 http://ieeexplore.ieee.org/document/6867958/},
year = {2014}
}
@article{Kagawa2017,
abstract = {Background:Phenotyping is an automated technique that can be used to distinguish patients based on electronic health records. To improve the quality of medical care and advance type 2 diabetes mellitus (T2DM) research, the demand for T2DM phenotyping has been increasing. Some existing phenotyping algorithms are not sufficiently accurate for screening or identifying clinical research subjects.Objective:We propose a practical phenotyping framework using both expert knowledge and a machine learning approach to develop 2 phenotyping algorithms: one is for screening; the other is for identifying research subjects.Methods:We employ expert knowledge as rules to exclude obvious control patients and machine learning to increase accuracy for complicated patients. We developed phenotyping algorithms on the basis of our framework and performed binary classification to determine whether a patient has T2DM. To facilitate development of practical phenotyping algorithms, this study introduces new evaluation metrics: area under the precision-sensitivity curve (AUPS) with a high sensitivity and AUPS with a high positive predictive value.Results:The proposed phenotyping algorithms based on our framework show higher performance than baseline algorithms. Our proposed framework can be used to develop 2 types of phenotyping algorithms depending on the tuning approach: one for screening, the other for identifying research subjects.Conclusions:We develop a novel phenotyping framework that can be easily implemented on the basis of proper evaluation metrics, which are in accordance with users' objectives. The phenotyping algorithms based on our framework are useful for extraction of T2DM patients in retrospective studies.},
author = {Kagawa, Rina and Kawazoe, Yoshimasa and Ida, Yusuke and Shinohara, Emiko and Tanaka, Katsuya and Imai, Takeshi and Ohe, Kazuhiko},
doi = {10.1177/1932296816681584},
file = {:Users/na399/GitHub/thesis/references/papers/Kagawa et al.{\_}2017{\_}Development of Type 2 Diabetes Mellitus Phenotyping Framework Using Expert Knowledge and Machine Learning Approach{\_}Jo.pdf:pdf},
isbn = {1932296816},
issn = {19322968},
journal = {Journal of Diabetes Science and Technology},
keywords = {phenotyping,positive predictive value (PPV),rank:65,relevancy:B,sensitivity,support vector machine (SVM),type 2 diabetes mellitus (T2DM)},
mendeley-tags = {rank:65,relevancy:B},
number = {4},
pages = {791--799},
pmid = {27932531},
title = {{Development of Type 2 Diabetes Mellitus Phenotyping Framework Using Expert Knowledge and Machine Learning Approach}},
volume = {11},
year = {2017}
}
@article{Brookmeyer2007,
abstract = {Background: Our goal was to forecast the global burden of Alzheimer's disease and evaluate the potential impact of interventions that delay disease onset or progression. Methods: A stochastic, multistate model was used in conjunction with United Nations worldwide population forecasts and data from epidemiological studies of the risks of Alzheimer's disease. Results: In 2006, the worldwide prevalence of Alzheimer's disease was 26.6 million. By 2050, the prevalence will quadruple, by which time 1 in 85 persons worldwide will be living with the disease. We estimate about 43{\%} of prevalent cases need a high level of care, equivalent to that of a nursing home. If interventions could delay both disease onset and progression by a modest 1 year, there would be nearly 9.2 million fewer cases of the disease in 2050, with nearly the entire decline attributable to decreases in persons needing a high level of care. Conclusions: We face a looming global epidemic of Alzheimer's disease as the world's population ages. Modest advances in therapeutic and preventive strategies that lead to even small delays in the onset and progression of Alzheimer's disease can significantly reduce the global burden of this disease. {\textcopyright} 2007 The Alzheimer's Association.},
author = {Brookmeyer, Ron and Johnson, Elizabeth and Ziegler-Graham, Kathryn and Arrighi, H. Michael},
doi = {10.1016/j.jalz.2007.04.381},
file = {:Users/na399/Downloads/Research Papers/Brookmeyer et al.{\_}2007{\_}Forecasting the global burden of Alzheimer's disease{\_}Alzheimer's and Dementia.pdf:pdf},
isbn = {1552-5260},
issn = {15525260},
journal = {Alzheimer's and Dementia},
keywords = {Alzheimer's,Forecast,Prediction,Statistics,disease:dementia,rank:99,relevancy:C,topic:impact,type:research},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:impact,type:research},
number = {3},
pages = {186--191},
pmid = {19595937},
title = {{Forecasting the global burden of Alzheimer's disease}},
volume = {3},
year = {2007}
}
@article{Agarwal2016,
abstract = {Objective Traditionally, patient groups with a phenotype are selected through rule-based definitions whose creation and validation are time-con-suming. Machine learning approaches to electronic phenotyping are limited by the paucity of labeled training datasets. We demonstrate the feasi-bility of utilizing semi-automatically labeled training sets to create phenotype models via machine learning, using a comprehensive representation of the patient medical record. Methods We use a list of keywords specific to the phenotype of interest to generate noisy labeled training data. We train L1 penalized logistic re-gression models for a chronic and an acute disease and evaluate the performance of the models against a gold standard. Results Our models for Type 2 diabetes mellitus and myocardial infarction achieve precision and accuracy of 0.90, 0.89, and 0.86, 0.89, respec-tively. Local implementations of the previously validated rule-based definitions for Type 2 diabetes mellitus and myocardial infarction achieve preci-sion and accuracy of 0.96, 0.92 and 0.84, 0.87, respectively. We have demonstrated feasibility of learning phenotype models using imperfectly labeled data for a chronic and acute phenotype. Further research in feature engineering and in specification of the keyword list can improve the performance of the models and the scalability of the approach. Conclusions Our method provides an alternative to manual labeling for creating training sets for statistical models of phenotypes. Such an ap-proach can accelerate research with large observational healthcare datasets and may also be used to create local phenotype models.},
author = {Agarwal, Vibhu and Podchiyska, Tanya and Banda, Juan M. and Goel, Veena and Leung, Tiffany I. and Minty, Evan P. and Sweeney, Timothy E. and Gyang, Elsie and Shah, Nigam H.},
doi = {10.1093/jamia/ocw028},
file = {:Users/na399/GitHub/thesis/references/papers/Agarwal et al.{\_}2016{\_}Learning statistical models of phenotypes using noisy labeled training data{\_}Journal of the American Medical Informat.pdf:pdf},
isbn = {6507231398},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Electronic health record,High throughput,Machine learning,Noisy labels,Phenotyping,disease:diabetes,model:logisticRegression,rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {disease:diabetes,model:logisticRegression,rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:research},
number = {6},
pages = {1166--1173},
pmid = {27174893},
title = {{Learning statistical models of phenotypes using noisy labeled training data}},
volume = {23},
year = {2016}
}
@article{Kho2011,
abstract = {Clinical data in electronic medical records (EMRs) are a potential source of longitudinal clinical data for research. The Electronic Medical Records and Genomics Network (eMERGE) investigates whether data captured through routine clinical care using EMRs can identify disease phenotypes with sufficient positive and negative predictive values for use in genome-wide association studies (GWAS). Using data from five different sets of EMRs, we have identified five disease phenotypes with positive predictive values of 73 to 98{\%} and negative predictive values of 98 to 100{\%}. Most EMRs captured key information (diagnoses, medications, laboratory tests) used to define phenotypes in a structured format. We identified natural language processing as an important tool to improve case identification rates. Efforts and incentives to increase the implementation of interoperable EMRs will markedly improve the availability of clinical data for genomics research.},
author = {Kho, A. N. and Pacheco, J. A. and Peissig, P. L. and Rasmussen, L. and Newton, K. M. and Weston, N. and Crane, P. K. and Pathak, J. and Chute, C. G. and Bielinski, S. J. and Kullo, I. J. and Li, R. and Manolio, T. A. and Chisholm, R. L. and Denny, J. C.},
doi = {10.1126/scitranslmed.3001807},
file = {:Users/na399/GitHub/thesis/references/papers/Kho et al.{\_}2011{\_}Electronic Medical Records for Genetic Research Results of the eMERGE Consortium{\_}Science Translational Medicine.pdf:pdf},
isbn = {1946-6242; 1946-6234},
issn = {1946-6234},
journal = {Science Translational Medicine},
keywords = {disease:general,rank:99,relevancy:C,topic:EHR,topic:GWAS,topic:bioinformatics,topic:phenotyping,topic:platform,type:research},
mendeley-tags = {disease:general,rank:99,relevancy:C,topic:EHR,topic:GWAS,topic:bioinformatics,topic:phenotyping,topic:platform,type:research},
number = {79},
pages = {79re1--79re1},
pmid = {21508311},
title = {{Electronic Medical Records for Genetic Research: Results of the eMERGE Consortium}},
url = {http://stm.sciencemag.org/cgi/doi/10.1126/scitranslmed.3001807},
volume = {3},
year = {2011}
}
@inproceedings{Schafer2017,
abstract = {{\textcopyright} 2017 Association for Computing Machinery. People increasingly use the Internet for obtaining information regarding diseases, diagnoses and available treatments. Currently, many online health portals already provide non-personalized health information in the form of articles. However, it can be challenging to find information relevant to one's condition, interpret this in context, and understand the medical terms and relationships. Recommender Systems (RS) already help these systems perform precise information filtering. In this short paper, we look one step ahead and show the progress made towards RS helping users find personalized, complex medical interventions or support them with preventive healthcare measures. We identify key challenges that need to be addressed for RS to offer the kind of decision support needed in high-risk domains like healthcare.},
address = {New York, New York, USA},
author = {Sch{\"{a}}fer, Hanna and Hors-Fraile, Santiago and Karumur, Raghav Pavan and {Calero Valdez}, Andr{\'{e}} and Said, Alan and Torkamaan, Helma and Ulmer, Tom and Trattner, Christoph},
booktitle = {Proceedings of the 2017 International Conference on Digital Health - DH '17},
doi = {10.1145/3079452.3079499},
file = {:Users/na399/GitHub/thesis/references/papers/Sch{\"{a}}fer et al.{\_}2017{\_}Towards Health (Aware) Recommender Systems{\_}Proceedings of the 2017 International Conference on Digital Health - DH.pdf:pdf},
isbn = {9781450352499},
keywords = {acm reference format,disease modeling,health informatics,health recommender systems,ing,online health interventions,patient model-,rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
pages = {157--161},
publisher = {ACM Press},
title = {{Towards Health (Aware) Recommender Systems}},
url = {http://dl.acm.org/citation.cfm?doid=3079452.3079499},
year = {2017}
}
@article{Zhao2017,
abstract = {Electronic health records contain large amounts of longitudinal data that are valuable for biomedical informatics research. The application of machine learning is a promising alternative to manual analysis of such data. However, the complex structure of the data, which includes clinical events that are unevenly distributed over time, poses a challenge for standard learning algorithms. Some approaches to modeling temporal data rely on extracting single values from time series; however, this leads to the loss of potentially valuable sequential information. How to better account for the temporality of clinical data, hence, remains an important research question. In this study, novel representations of temporal data in electronic health records are explored. These representations retain the sequential information, and are directly compatible with standard machine learning algorithms. The explored methods are based on symbolic sequence representations of time series data, which are utilized in a number of different ways. An empirical investigation, using 19 datasets comprising clinical measurements observed over time from a real database of electronic health records, shows that using a distance measure to random subsequences leads to substantial improvements in predictive performance compared to using the original sequences or clustering the sequences. Evidence is moreover provided on the quality of the symbolic sequence representation by comparing it to sequences that are generated using domain knowledge by clinical experts. The proposed method creates representations that better account for the temporality of clinical events, which is often key to prediction tasks in the biomedical domain.},
author = {Zhao, Jing and Papapetrou, Panagiotis and Asker, Lars and Bostr{\"{o}}m, Henrik},
doi = {10.1016/j.jbi.2016.11.006},
file = {:Users/na399/GitHub/thesis/references/papers/Zhao et al.{\_}2017{\_}Learning from heterogeneous temporal data in electronic health records{\_}Journal of Biomedical Informatics.pdf:pdf},
isbn = {1532-0480 (Electronic) 1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Data mining,Electronic health records,Machine learning,Random subsequence,Time series classification,rank:85,relevancy:A,topic:EHR,topic:prediction,topic:progression,type:research},
mendeley-tags = {rank:85,relevancy:A,topic:EHR,topic:progression,topic:prediction,type:research},
pages = {105--119},
pmid = {27919732},
publisher = {The Author(s)},
title = {{Learning from heterogeneous temporal data in electronic health records}},
url = {http://dx.doi.org/10.1016/j.jbi.2016.11.006},
volume = {65},
year = {2017}
}
@article{Cummings2016a,
abstract = {The global impact of Alzheimer's disease (AD) continues to increase, and focused efforts are needed to address this immense public health challenge. National leaders have set a goal to prevent or effectively treat AD by 2025. In this paper, we discuss the path to 2025, and what is feasible in this time frame given the realities and challenges of AD drug development, with a focus on disease-modifying therapies (DMTs). Under the current conditions, only drugs currently in late Phase 1 or later will have a chance of being approved by 2025. If pipeline attrition rates remain high, only a few compounds at best will meet this time frame. There is an opportunity to reduce the time and risk of AD drug development through an improvement in trial design; better trial infrastructure; disease registries of well-characterized participant cohorts to help with more rapid enrollment of appropriate study populations; validated biomarkers to better detect disease, determine risk and monitor disease progression as well as predict disease response; more sensitive clinical assessment tools; and faster regulatory review. To implement change requires efforts to build awareness, educate and foster engagement; increase funding for both basic and clinical research; reduce fragmented environments and systems; increase learning from successes and failures; promote data standardization and increase wider data sharing; understand AD at the basic biology level; and rapidly translate new knowledge into clinical development. Improved mechanistic understanding of disease onset and progression is central to more efficient AD drug development and will lead to improved therapeutic approaches and targets. The opportunity for more than a few new therapies by 2025 is small. Accelerating research and clinical development efforts and bringing DMTs to market sooner would have a significant impact on the future societal burden of AD. As these steps are put in place and plans come to fruition, e.g., approval of a DMT, it can be predicted that momentum will build, the process will be self-sustaining, and the path to 2025, and beyond, becomes clearer.},
author = {Cummings, Jeffrey and Aisen, Paul S. and DuBois, Bruno and Fr{\"{o}}lich, Lutz and Jack, Clifford R. and Jones, Roy W. and Morris, John C. and Raskin, Joel and Dowsett, Sherie A. and Scheltens, Philip},
doi = {10.1186/s13195-016-0207-9},
file = {:Users/na399/GitHub/thesis/references/papers/Cummings et al.{\_}2016{\_}Drug development in Alzheimer's disease the path to 2025{\_}Alzheimer's Research {\&} Therapy.pdf:pdf},
isbn = {1758-9193 (Electronic)},
issn = {1758-9193},
journal = {Alzheimer's Research {\&} Therapy},
keywords = {Alzheimer's disease,Disease-modifying therapy 2025,disease:dementia,rank:95,relevancy:C,topic:treatment,type:review},
mendeley-tags = {rank:95,type:review,disease:dementia,topic:treatment,relevancy:C},
month = {dec},
number = {1},
pages = {39},
pmid = {27646601},
publisher = {Alzheimer's Research {\&} Therapy},
title = {{Drug development in Alzheimer's disease: the path to 2025}},
url = {http://dx.doi.org/10.1186/s13195-016-0207-9 http://alzres.biomedcentral.com/articles/10.1186/s13195-016-0207-9},
volume = {8},
year = {2016}
}
@article{Carvalho2017,
abstract = {The worldwide aging phenomenon is a growing concern. Alzheimer's disease (AD) has a high prevalence in the elderly. In this paper, we present a clinical decision support system for aiding the diagnosis of AD and related disorders. We describe system's main components and architecture, which is based on a mobile web-based platform. Its predictive model is based on Bayesian networks designed considering AD diagnosis criteria, trained and tested with the patient database of the Center for Alzheimer's Disease and Related Disorder at the Institute of Psychiatry of the Federal University of Rio de Janeiro, Brazil. Patient database attributes are composed by predisposal factors, demographic data, assessment scales, symptoms and signs. When the system indicates a patient diagnosis, it provides: the most probable diagnosis, health data that lead to such diagnosis and, in case of low certainty factor, unobserved health data that should be collected to confirm or refuse the initial diagnostic hypothesis. Preliminary usability tests indicate potential use of the system in clinical practice.},
author = {Carvalho, Carolina Medeiros and Christina, Debora and Saade, Muchaluat and Conci, Aura and Seixas, Flavio Luiz and Laks, Jerson},
doi = {10.1109/ICC.2017.7996968},
file = {:Users/na399/GitHub/thesis/references/papers/Carvalho et al.{\_}2017{\_}A clinical decision support system for aiding diagnosis of Alzheimer's disease and related disorders in mobile devi.pdf:pdf},
isbn = {978-1-4673-8999-0},
journal = {2017 IEEE International Conference on Communications (ICC)},
keywords = {AD diagnosis criteria,Alzheimer's disease,Alzheimer's disease diagnosis,Bayes methods,Bayesian networks,Computer-aided diagnosis,Databases,Dementia,Engines,Internet,Predictive models,aging phenomenon,alzheimer,bayesian networks,belief networks,clinical decision support system,computer-aided diagnosis,decision support systems,diseases,health data collection,initial diagnostic hypothesis,medical diagnostic computing,mobile Web-based platform,mobile computing,mobile devices,mobile healthcare,patient database attributes,patient diagnosis,rank:99,relevancy:A,s disease},
mendeley-tags = {rank:99,relevancy:A},
pages = {1--6},
title = {{A clinical decision support system for aiding diagnosis of Alzheimer's disease and related disorders in mobile devices}},
url = {http://ieeexplore.ieee.org/document/7996968/},
year = {2017}
}
@article{Prince2017,
abstract = {http://dx.doi.org/10.1016/S0140-6736(17)31757-9 1 Progress on dementia—leaving no one behind The Lancet Commission Dementia Prevention, Intervention, and Care 1 makes a timely evidence-driven contribution to global efforts to improve the lives of people with dementia and their carers, and limit the future impact on societies. The Commission proposes ambitious prevention targets, treatment of cognitive symptoms in people with Alzheimer's disease or dementia with Lewy bodies, individualised dementia care, provision of care for carers, planning for the future for patients and families, risk protection balanced with respect for autonomy, management of neuropsychiatric symptoms, consideration of dementia in end of life care, and use of technological innovations to improve care but not replace social contact. It recommends a comprehensive package of evidence-based actions that will complement wider global efforts to respond to the challenge of dementia. On May 29, 2017, the World Health Assembly endorsed the WHO Global Action Plan on the Public Health Response to Dementia (2017–2025), 2 with member states committing to international collaboration, and national strategies with implementation plans. This plan signals an upswing in awareness of the need to address what WHO declared, in 2012, to be a global public health priority. 3 Concerted international and intersectoral collaborative action will be required to implement WHO's Plan. Equity and rights must be foregrounded to ensure that we " leave no one behind " . The Lancet Commission, through a systematic and judicious appraisal of the evidence, has helpfully indicated what works, what might work, and what should be avoided in drafting strategies and plans. The Commission provides the " what " , without necessarily specifying the " how " and the " where " . With endorsement of the WHO Global Action Plan, there is acknowledgment that dementia is a global problem that particularly impacts low-income and middle-income countries (LMICs). Alzheimer's Disease International (ADI) estimated that there were 46{\textperiodcentered}8 million people living with dementia worldwide in 2015, increasing to 131{\textperiodcentered}5 million by 2050. 4},
author = {Prince, Martin},
doi = {10.1016/S0140-6736(17)31757-9},
file = {:Users/na399/Downloads/Research Papers/Prince{\_}2017{\_}Progress on dementia-leaving no one behind{\_}The Lancet.pdf:pdf},
issn = {1474547X},
journal = {The Lancet},
keywords = {disease:dementia,rank:99,relevancy:C,topic:impact,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:impact,type:commentary},
number = {17},
pages = {51--53},
pmid = {28735856},
title = {{Progress on dementia-leaving no one behind}},
volume = {6736},
year = {2017}
}
@article{Exarchos2013,
abstract = {In this paper we propose a methodology for predicting the progression of atherosclerosis in coronary arteries using dynamic Bayesian networks. The methodology takes into account patient data collected at the baseline study and the same data collected in the follow-up study. Our aim is to analyze all the different sources of information (Demographic, Clinical, Biochemical profile, Inflammatory markers, Treatment characteristics) in order to predict possible manifestations of the disease; subsequently, our purpose is twofold: i) to identify the key factors that dictate the progression of atherosclerosis and ii) based on these factors to build a model which is able to predict the progression of atherosclerosis for a specific patient, providing at the same time information about the underlying mechanism of the disease.},
author = {Exarchos, Konstantinos P. and Exarchos, Themis P. and Bourantas, Christos V. and Papafaklis, Michail I. and Naka, Katerina K. and Michalis, Lampros K. and Parodi, Oberdan and Fotiadis, Dimitrios I.},
doi = {10.1109/EMBC.2013.6610394},
file = {:Users/na399/GitHub/thesis/references/papers/Exarchos et al.{\_}2013{\_}Prediction of coronary atherosclerosis progression using dynamic Bayesian networks{\_}2013 35th Annual International C.pdf:pdf},
isbn = {978-1-4577-0216-7},
journal = {2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
keywords = {Biomedical data-driven modeling,Mining clinical d,rank:n/a,relevancy:A},
mendeley-tags = {rank:n/a,relevancy:A},
pages = {3889--3892},
title = {{Prediction of coronary atherosclerosis progression using dynamic Bayesian networks}},
url = {http://ieeexplore.ieee.org/document/6610394/},
year = {2013}
}
@article{Darwiche2010,
abstract = {What are Bayesian networks and why are their applications growing across all fields?},
archivePrefix = {arXiv},
arxivId = {1401.0852},
author = {Darwiche, Adnan},
doi = {10.1145/1859204.1859227},
eprint = {1401.0852},
file = {:Users/na399/GitHub/thesis/references/papers/Darwiche{\_}2010{\_}Bayesian networks{\_}Communications of the ACM.pdf:pdf},
isbn = {0001-0782},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {model:Bayesian,rank:80,relevancy:A,type:education},
mendeley-tags = {rank:80,type:education,model:Bayesian,relevancy:A},
month = {dec},
number = {12},
pages = {80},
pmid = {21775236},
title = {{Bayesian networks}},
url = {http://portal.acm.org/citation.cfm?doid=1859204.1859227},
volume = {53},
year = {2010}
}
@article{Pedersen2016,
abstract = {As weight-loss surgery is an effective treatment for the glycaemic control of type 2 diabetes in obese patients, yet not all patients benefit, it is valuable to find predictive factors for this diabetic remission. This will help elucidating possible mechanistic insights and form the basis for prioritising obese patients with dysregulated diabetes for surgery where diabetes remission is of interest. In this study, we combine both clinical and genomic factors using heuristic methods, informed by prior biological knowledge in order to rank factors that would have a role in predicting diabetes remission, and indeed in identifying patients who may have low likelihood in responding to bariatric surgery for improved glycaemic control. Genetic variants from the Illumina CardioMetaboChip were prioritised through single-association tests and then seeded a larger selection from protein-protein interaction networks. Artificial neural networks allowing nonlinear correlations were trained to discriminate patients with and without surgery-induced diabetes remission, and the importance of each clinical and genetic parameter was evaluated. The approach highlighted insulin treatment, baseline HbA1c levels, use of insulin-sensitising agents and baseline serum insulin levels, as the most informative variables with a decent internal validation performance (74{\%} accuracy, area under the curve (AUC) 0.81). Adding information for the eight top-ranked single nucleotide polymorphisms (SNPs) significantly boosted classification performance to 84{\%} accuracy (AUC 0.92). The eight SNPs mapped to eight genes -ABCA1, ARHGEF12, CTNNBL1, GLI3, PROK2, RYBP, SMUG1andSTXBP5- three of which are known to have a role in insulin secretion, insulin sensitivity or obesity, but have not been indicated for diabetes remission after bariatric surgery before.},
author = {Pedersen, Helle Krogh and Gudmundsdottir, Valborg and Pedersen, Mette Krogh and Brorsson, Caroline and Brunak, S{\o}ren and Gupta, Ramneek},
doi = {10.1038/npjgenmed.2016.35},
file = {:Users/na399/GitHub/thesis/references/papers/Pedersen et al.{\_}2016{\_}Ranking factors involved in diabetes remission after bariatric surgery using machine-learning integrating clinical.pdf:pdf},
issn = {2056-7944},
journal = {NPJ genomic medicine},
keywords = {rank:n/a,relevancy:A},
mendeley-tags = {rank:n/a,relevancy:A},
month = {nov},
number = {1},
pages = {16035},
pmid = {29263820},
title = {{Ranking factors involved in diabetes remission after bariatric surgery using machine-learning integrating clinical and genomic biomarkers.}},
url = {http://www.nature.com/articles/npjgenmed201635 http://www.ncbi.nlm.nih.gov/pubmed/29263820 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5685313},
volume = {1},
year = {2016}
}
@article{Dartigues2009,
abstract = {The World Alzheimer Report, recently published under the auspices of Alzheimer Disease International (ADI), emphasises that, with global increases in population size and life expectancy, Alzheimer's disease (AD) has become a world health problem. According to the new report, the global prevalence of AD is set to rise to more than 35 million people by 2010, a 10{\%} increase on the previous estimate published in 2005 by ADI. Moreover, the ADI investigators predict that dementia prevalence will nearly double every 20 years, to 65{\textperiodcentered}7 million in 2030 and 115{\textperiodcentered}4 million in 2050, and that the increases in prevalence have been mainly driven by new data from low-income and middle-income countries. On the basis of the report's findings, the ADI team provides eight recommendations for health policies and the management of dementia. Knowledge of the prevalence and incidence of AD is essential to determine the extent to which specialists, memory clinics, respite care services, nursing homes, etc, are needed. Difficulty in the management of AD at a collective level is the high proportion of undiagnosed cases, even at the severe stage of the disease. The discovery of a disease-modifying drug would contribute greatly to solving the problem of AD, and major research efforts to identify such a drug are underway in many countries. In the meantime, a central aim for the management of patients with AD is to support caregivers and families. (PsycINFO Database Record (c) 2012 APA, all rights reserved)},
author = {Dartigues, Jean Fran{\c{c}}ois},
doi = {10.1016/S1474-4422(09)70298-4},
file = {:Users/na399/Downloads/Research Papers/Dartigues{\_}2009{\_}Alzheimer's disease a global challenge for the 21st century{\_}The Lancet Neurology.pdf:pdf},
isbn = {1474-4422},
issn = {14744422},
journal = {The Lancet Neurology},
keywords = {disease:dementia,rank:99,relevancy:B,topic:impact,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:B,topic:impact,type:commentary},
number = {12},
pages = {1082--1083},
pmid = {19909903},
publisher = {Elsevier Ltd},
title = {{Alzheimer's disease: a global challenge for the 21st century}},
url = {http://dx.doi.org/10.1016/S1474-4422(09)70298-4},
volume = {8},
year = {2009}
}
@article{Dagliati2017,
abstract = {One of the areas where Artificial Intelligence is having more impact is machine learning, which develops algorithms able to learn patterns and decision rules from data. Machine learning algorithms have been embedded into data mining pipelines, which can combine them with classical statistical strategies, to extract knowledge from data. Within the EU-funded MOSAIC project, a data mining pipeline has been used to derive a set of predictive models of type 2 diabetes mellitus (T2DM) complications based on electronic health record data of nearly one thousand patients. Such pipeline comprises clinical center profiling, predictive model targeting, predictive model construction and model validation. After having dealt with missing data by means of random forest (RF) and having applied suitable strategies to handle class imbalance, we have used Logistic Regression with stepwise feature selection to predict the onset of retinopathy, neuropathy, or nephropathy, at different time scenarios, at 3, 5, and 7 years from ...},
author = {Dagliati, Arianna and Marini, Simone and Sacchi, Lucia and Cogni, Giulia and Teliti, Marsida and Tibollo, Valentina and {De Cata}, Pasquale and Chiovato, Luca and Bellazzi, Riccardo},
doi = {10.1177/1932296817706375},
file = {:Users/na399/GitHub/thesis/references/papers/Dagliati et al.{\_}2017{\_}Machine Learning Methods to Predict Diabetes Complications{\_}Journal of Diabetes Science and Technology.pdf:pdf},
issn = {1932-2968},
journal = {Journal of Diabetes Science and Technology},
keywords = {40 years provided important,ai,artificial intelligence,contributions to computer sci-,data mining,is a discipline that,machine learning,microvascular complications,over the past,rank:65,relevancy:B,risk predictions,type 2 diabetes},
mendeley-tags = {rank:65,relevancy:B},
month = {mar},
number = {2},
pages = {295--302},
pmid = {28494618},
title = {{Machine Learning Methods to Predict Diabetes Complications}},
url = {http://journals.sagepub.com/doi/10.1177/1932296817706375},
volume = {12},
year = {2018}
}
@article{Goldstein2017b,
abstract = {OBJECTIVE Electronic health records (EHRs) are an increasingly common data source for clinical risk prediction, presenting both unique analytic opportunities and challenges. We sought to evaluate the current state of EHR based risk prediction modeling through a systematic review of clinical prediction studies using EHR data. METHODS We searched PubMed for articles that reported on the use of an EHR to develop a risk prediction model from 2009 to 2014. Articles were extracted by two reviewers, and we abstracted information on study design, use of EHR data, model building, and performance from each publication and supplementary documentation. RESULTS We identified 107 articles from 15 different countries. Studies were generally very large (median sample size = 26 100) and utilized a diverse array of predictors. Most used validation techniques (n = 94 of 107) and reported model coefficients for reproducibility (n = 83). However, studies did not fully leverage the breadth of EHR data, as they uncommonly used longitudinal information (n = 37) and employed relatively few predictor variables (median = 27 variables). Less than half of the studies were multicenter (n = 50) and only 26 performed validation across sites. Many studies did not fully address biases of EHR data such as missing data or loss to follow-up. Average c-statistics for different outcomes were: mortality (0.84), clinical prediction (0.83), hospitalization (0.71), and service utilization (0.71). CONCLUSIONS EHR data present both opportunities and challenges for clinical risk prediction. There is room for improvement in designing such studies.},
author = {Goldstein, Benjamin A and Navar, Ann Marie and Pencina, Michael J and Ioannidis, John P A},
doi = {10.1093/jamia/ocw042},
file = {:Users/na399/GitHub/thesis/references/papers/Goldstein et al.{\_}2017{\_}Opportunities and challenges in developing risk prediction models with electronic health records data a systematic.pdf:pdf},
isbn = {1067-5027},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
keywords = {electronic medical record,rank:90,relevancy:A,review,risk assessment,topic:EHR,topic:prediction,type:review},
mendeley-tags = {rank:90,relevancy:A,topic:EHR,topic:prediction,type:review},
number = {1},
pages = {198--208},
pmid = {27189013},
title = {{Opportunities and challenges in developing risk prediction models with electronic health records data: a systematic review}},
url = {https://academic.oup.com/jamia/article-lookup/doi/10.1093/jamia/ocw042},
volume = {24},
year = {2017}
}
@article{Fernald2011,
abstract = {MOTIVATION: Widespread availability of low-cost, full genome sequencing will introduce new challenges for bioinformatics. RESULTS: This review outlines recent developments in sequencing technologies and genome analysis methods for application in personalized medicine. New methods are needed in four areas to realize the potential of personalized medicine: (i) processing large-scale robust genomic data; (ii) interpreting the functional effect and the impact of genomic variation; (iii) integrating systems data to relate complex genetic interactions with phenotypes; and (iv) translating these discoveries into medical practice. CONTACT: russ.altman@stanford.edu},
author = {Fernald, Guy Haskin and Capriotti, Emidio and Daneshjou, Roxana and Karczewski, Konrad J. and Altman, Russ B.},
doi = {10.1093/bioinformatics/btr295},
file = {:Users/na399/GitHub/thesis/references/papers/Fernald et al.{\_}2011{\_}Bioinformatics challenges for personalized medicine{\_}Bioinformatics.pdf:pdf},
isbn = {1367-4811 (Electronic)$\backslash$n1367-4803 (Linking)},
issn = {13674803},
journal = {Bioinformatics},
keywords = {disease:general,rank:99,relevancy:C,topic:bioinformatics,topic:treatment,type:review},
mendeley-tags = {disease:general,rank:99,relevancy:C,topic:bioinformatics,topic:treatment,type:review},
number = {13},
pages = {1741--1748},
pmid = {21596790},
title = {{Bioinformatics challenges for personalized medicine}},
volume = {27},
year = {2011}
}
@article{Atkins2017,
abstract = {Computerized tests benefit from automated scoring procedures and standardized administration instructions. These methods can reduce the potential for rater error. However, especially in patients with severe mental illnesses, the equivalency of traditional and tablet-based tests cannot be assumed. The Brief Assessment of Cognition in Schizophrenia (BACS) is a pen-and-paper cognitive assessment tool that has been used in hundreds of research studies and clinical trials, and has normative data available for generating age- and gender-corrected standardized scores. A tablet-based version of the BACS called the BAC App has been developed. This study compared performance on the BACS and the BAC App in patients with schizophrenia and healthy controls. Test equivalency was assessed, and the applicability of paper-based normative data was evaluated. Results demonstrated the distributions of standardized composite scores for the tablet-based BAC App and the pen-and-paper BACS were indistinguishable, and the between-methods mean differences were not statistically significant. The discrimination between patients and controls was similarly robust. The between-methods correlations for individual measures in patients were r {\textgreater} 0.70 for most subtests. When data from the Token Motor Test was omitted, the between-methods correlation of composite scores was r = 0.88 (df = 48; p {\textless} 0.001) in healthy controls and r = 0.89 (df = 46; p {\textless} 0.001) in patients, consistent with the test-retest reliability of each measure. Taken together, results indicate that the tablet-based BAC App generates results consistent with the traditional pen-and-paper BACS, and support the notion that the BAC App is appropriate for use in clinical trials and clinical practice.},
author = {Atkins, Alexandra S. and Tseng, Tina and Vaughan, Adam and Twamley, Elizabeth W. and Harvey, Philip and Patterson, Thomas and Narasimhan, Meera and Keefe, Richard S.E.},
doi = {10.1016/j.schres.2016.10.010},
file = {:Users/na399/Downloads/Research Papers/Atkins et al.{\_}2017{\_}Validation of the tablet-administered Brief Assessment of Cognition (BAC App){\_}Schizophrenia Research.pdf:pdf},
isbn = {1573-2509 (Electronic)$\backslash$r0920-9964 (Linking)},
issn = {15732509},
journal = {Schizophrenia Research},
keywords = {App,BACS,Cognition,Cognitive test,Schizophrenia,Tablet assessment,disease:dementia,rank:90,relevancy:D,topic:diagnosis,type:research},
mendeley-tags = {disease:dementia,rank:90,relevancy:D,topic:diagnosis,type:research},
pages = {100--106},
pmid = {27771201},
publisher = {The Authors},
title = {{Validation of the tablet-administered Brief Assessment of Cognition (BAC App)}},
url = {http://dx.doi.org/10.1016/j.schres.2016.10.010},
volume = {181},
year = {2017}
}
@article{Perera2018,
abstract = {Introduction: The European Medical Information Framework consortium has assembled electronic health record (EHR) databases for dementia research. We calculated dementia prevalence and incidence in 25 million persons from 2004 to 2012. Methods: Six EHR databases (three primary care and three secondary care) from five countries were interrogated. Dementia was ascertained by consensus harmonization of clinical/diagnostic codes. Annual period prevalences and incidences by age and gender were calculated and meta-analyzed. Results: The six databases contained 138,625 dementia cases. Age-specific prevalences were around 30{\%} of published estimates from community samples and incidences were around 50{\%}. Pooled prevalences had increased from 2004 to 2012 in all age groups but pooled incidences only after age 75 years. Associations with age and gender were stable over time. Discussion: The European Medical Information Framework initiative supports EHR data on unprecedented number of people with dementia. Age-specific prevalences and incidences mirror estimates from community samples in pattern at levels that are lower but increasing over time.},
author = {Perera, Gayan and Pedersen, Lars and Ansel, David and Alexander, Myriam and Arrighi, H. Michael and Avillach, Paul and Foskett, Nadia and Gini, Rosa and Gordon, Mark F. and Gungabissoon, Usha and Mayer, Miguel Angel and Novak, Gerald and Rijnbeek, Peter and Trifir{\`{o}}, Gianluca and van der Lei, Johan and Visser, Pieter J. and Stewart, Robert},
doi = {10.1016/j.jalz.2017.06.2270},
file = {:Users/na399/GitHub/thesis/references/papers/Perera et al.{\_}2018{\_}Dementia prevalence and incidence in a federation of European Electronic Health Record databases The European Medical.pdf:pdf},
issn = {15525279},
journal = {Alzheimer's and Dementia},
keywords = {Dementia,Electronic Health Records,European Medical Informatics Framework,Incidence,Prevalence,disease:dementia,rank:99,relevancy:A,topic:impact,topic:prevalence,type:research},
mendeley-tags = {disease:dementia,rank:99,relevancy:A,topic:impact,topic:prevalence,type:research},
number = {2},
pages = {130--139},
pmid = {28734783},
title = {{Dementia prevalence and incidence in a federation of European Electronic Health Record databases: The European Medical Informatics Framework resource}},
volume = {14},
year = {2018}
}
@article{Nakamura2015,
author = {Nakamura, Antonio Eduardo and Opaleye, Davi and Tani, Giovanni and Ferri, Cleusa P.},
doi = {10.1016/S0140-6736(15)60153-2},
file = {:Users/na399/Downloads/Research Papers/Nakamura et al.{\_}2015{\_}Dementia underdiagnosis in Brazil{\_}The Lancet.pdf:pdf},
issn = {1474547X},
journal = {The Lancet},
keywords = {disease:dementia,rank:99,relevancy:C,topic:impact,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:impact,type:commentary},
number = {9966},
pages = {418--419},
pmid = {25706975},
publisher = {Elsevier Ltd},
title = {{Dementia underdiagnosis in Brazil}},
url = {http://dx.doi.org/10.1016/S0140-6736(15)60153-2},
volume = {385},
year = {2015}
}
@inproceedings{Arandjelovic2015a,
author = {Arandjelovic, Ognjen},
booktitle = {2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
doi = {10.1109/EMBC.2015.7318910},
file = {:Users/na399/GitHub/thesis/references/papers/Arandjelovic{\_}2015{\_}Prediction of Health Outcomes Using Big (Health) Data{\_}Engineering in Medicine and Biology Society (EMBC), 2015 37th An.pdf:pdf},
isbn = {978-1-4244-9271-8},
issn = {1557170X},
keywords = {Electronic health records,Knowledge discovery and,rank:20,relevancy:A},
mendeley-tags = {rank:20,relevancy:A},
month = {aug},
pages = {2543--2546},
pmid = {26736810},
publisher = {IEEE},
title = {{Prediction of health outcomes using big (health) data}},
url = {http://ieeexplore.ieee.org/document/7318910/},
year = {2015}
}
@article{Hurdle2013,
abstract = {Nature Reviews Genetics 14, 1 (2013). doi:10.1038/nrg3208-c1},
author = {Hurdle, John F. and Smith, Ken R. and Mineau, Geraldine P.},
doi = {10.1038/nrg3208-c1},
file = {:Users/na399/GitHub/thesis/references/papers/Hurdle, Smith, Mineau{\_}2013{\_}Mining electronic health records An additional perspective{\_}Nature Reviews Genetics.pdf:pdf},
isbn = {1471-0064},
issn = {14710056},
journal = {Nature Reviews Genetics},
keywords = {disease:general,rank:99,relevancy:A,topic:EHR,type:commentary},
mendeley-tags = {disease:general,rank:99,relevancy:A,topic:EHR,type:commentary},
number = {1},
pages = {75},
pmid = {23247438},
publisher = {Nature Publishing Group},
title = {{Mining electronic health records: An additional perspective}},
url = {http://dx.doi.org/10.1038/nrg3208-c1},
volume = {14},
year = {2013}
}
@article{Lafortune2017,
author = {Lafortune, Louise and Brayne, Carol},
doi = {10.1038/nrneurol.2017.136},
file = {:Users/na399/Downloads/Research Papers/Lafortune, Brayne{\_}2017{\_}Dementia Dementia prevention - A call for contextualized evidence{\_}Nature Reviews Neurology.pdf:pdf},
issn = {17594766},
journal = {Nature Reviews Neurology},
keywords = {disease:dementia,rank:99,relevancy:A,topic:impact,topic:prevention,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:A,topic:impact,topic:prevention,type:commentary},
number = {10},
pages = {579--580},
pmid = {28960208},
title = {{Dementia: Dementia prevention - A call for contextualized evidence}},
volume = {13},
year = {2017}
}
@article{Denaxas2016,
abstract = {Modern cohort studies include self-reported measures on disease, behavior and lifestyle, sensor-based observations from mobile phones and wearables, and rich -omics data. Follow-up is often achieved through electronic health record (EHR) linkages across primary and secondary healthcare providers. Historically however, researchers typically only get to see the tip of the iceberg: coded administrative data relating to healthcare claims which mainly record billable diagnoses and procedures. The rich data generated during the clinical pathway remain submerged and inaccessible. While some institutions and initiatives have made good progress in unlocking such deep phenotypic data within their institutional realms, access at scale still remains challenging. Here we outline and discuss the main technical and social challenges associated with accessing these data for data mining and hauling the entire iceberg.},
author = {Denaxas, Spiros C. and Asselbergs, Folkert W. and Moore, Jason H.},
doi = {10.1186/s13040-016-0109-1},
file = {:Users/na399/GitHub/thesis/references/papers/Denaxas, Asselbergs, Moore{\_}2016{\_}The tip of the iceberg challenges of accessing hospital electronic health record data for biological dat.pdf:pdf},
isbn = {1304001601},
issn = {17560381},
journal = {BioData Mining},
keywords = {rank:70,relevancy:B},
mendeley-tags = {rank:70,relevancy:B},
number = {1},
pages = {1--4},
pmid = {27688810},
publisher = {BioData Mining},
title = {{The tip of the iceberg: challenges of accessing hospital electronic health record data for biological data mining}},
url = {http://dx.doi.org/10.1186/s13040-016-0109-1},
volume = {9},
year = {2016}
}
@book{Weaver2016,
address = {New York, NY},
author = {Weaver, Charlotte A and Ball, Marion J and Kim, George R and Editors, Joan M Kiel},
doi = {10.1007/978-1-4757-4043-1},
editor = {Ball, Marion J. and O'Desky, Robert I. and Douglas, Judith V. and Albright, James W.},
file = {:Users/na399/GitHub/thesis/references/papers/Weaver et al.{\_}1991{\_}Healthcare Information Management Systems{\_}Unknown.pdf:pdf},
isbn = {978-1-4757-4045-5},
keywords = {rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
publisher = {Springer New York},
title = {{Healthcare Information Management Systems}},
url = {http://link.springer.com/10.1007/978-1-4757-4043-1},
year = {2016}
}
@article{Weiner2017a,
abstract = {Introduction The Alzheimer's Disease Neuroimaging Initiative (ADNI) has continued development and standardization of methodologies for biomarkers and has provided an increased depth and breadth of data available to qualified researchers. This review summarizes the over 400 publications using ADNI data during 2014 and 2015. Methods We used standard searches to find publications using ADNI data. Results (1) Structural and functional changes, including subtle changes to hippocampal shape and texture, atrophy in areas outside of hippocampus, and disruption to functional networks, are detectable in presymptomatic subjects before hippocampal atrophy; (2) In subjects with abnormal $\beta$-amyloid deposition (A$\beta$+), biomarkers become abnormal in the order predicted by the amyloid cascade hypothesis; (3) Cognitive decline is more closely linked to tau than A$\beta$ deposition; (4) Cerebrovascular risk factors may interact with A$\beta$ to increase white-matter (WM) abnormalities which may accelerate Alzheimer's disease (AD) progression in conjunction with tau abnormalities; (5) Different patterns of atrophy are associated with impairment of memory and executive function and may underlie psychiatric symptoms; (6) Structural, functional, and metabolic network connectivities are disrupted as AD progresses. Models of prion-like spreading of A$\beta$ pathology along WM tracts predict known patterns of cortical A$\beta$ deposition and declines in glucose metabolism; (7) New AD risk and protective gene loci have been identified using biologically informed approaches; (8) Cognitively normal and mild cognitive impairment (MCI) subjects are heterogeneous and include groups typified not only by “classic” AD pathology but also by normal biomarkers, accelerated decline, and suspected non-Alzheimer's pathology; (9) Selection of subjects at risk of imminent decline on the basis of one or more pathologies improves the power of clinical trials; (10) Sensitivity of cognitive outcome measures to early changes in cognition has been improved and surrogate outcome measures using longitudinal structural magnetic resonance imaging may further reduce clinical trial cost and duration; (11) Advances in machine learning techniques such as neural networks have improved diagnostic and prognostic accuracy especially in challenges involving MCI subjects; and (12) Network connectivity measures and genetic variants show promise in multimodal classification and some classifiers using single modalities are rivaling multimodal classifiers. Discussion Taken together, these studies fundamentally deepen our understanding of AD progression and its underlying genetic basis, which in turn informs and improves clinical trial design.},
author = {Weiner, Michael W. and Veitch, Dallas P. and Aisen, Paul S. and Beckett, Laurel A. and Cairns, Nigel J. and Green, Robert C. and Harvey, Danielle and Jack, Clifford R. and Jagust, William and Morris, John C. and Petersen, Ronald C. and Saykin, Andrew J. and Shaw, Leslie M. and Toga, Arthur W. and Trojanowski, John Q.},
doi = {10.1016/j.jalz.2016.11.007},
file = {:Users/na399/OneDrive/Documents/NN/Alz/Papers/RDRF/Weiner et al.{\_}2017{\_}Recent publications from the Alzheimer's Disease Neuroimaging Initiative Reviewing progress toward improved AD clinic.pdf:pdf},
isbn = {1552-5260},
issn = {15525279},
journal = {Alzheimer's and Dementia},
keywords = {Alzheimer's disease,Amyloid,Biomarker,Disease progression,Mild cognitive impairment,Tau,disease:dementia,rank:99,relevancy:C,topic:neuroimaging,type:review},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:neuroimaging,type:review},
number = {4},
pages = {e1--e85},
pmid = {28342697},
publisher = {Elsevier},
title = {{Recent publications from the Alzheimer's Disease Neuroimaging Initiative: Reviewing progress toward improved AD clinical trials}},
url = {http://dx.doi.org/10.1016/j.jalz.2016.11.007},
volume = {13},
year = {2017}
}
@article{Halpern2016,
abstract = {BACKGROUND Electronic medical records (EMRs) hold a tremendous amount of information about patients that is relevant to determining the optimal approach to patient care. As medicine becomes increasingly precise, a patient's electronic medical record phenotype will play an important role in triggering clinical decision support systems that can deliver personalized recommendations in real time. Learning with anchors presents a method of efficiently learning statistically driven phenotypes with minimal manual intervention. MATERIALS AND METHODS We developed a phenotype library that uses both structured and unstructured data from the EMR to represent patients for real-time clinical decision support. Eight of the phenotypes were evaluated using retrospective EMR data on emergency department patients using a set of prospectively gathered gold standard labels. RESULTS We built a phenotype library with 42 publicly available phenotype definitions. Using information from triage time, the phenotype classifiers have an area under the ROC curve (AUC) of infection 0.89, cancer 0.88, immunosuppressed 0.85, septic shock 0.93, nursing home 0.87, anticoagulated 0.83, cardiac etiology 0.89, and pneumonia 0.90. Using information available at the time of disposition from the emergency department, the AUC values are infection 0.91, cancer 0.95, immunosuppressed 0.90, septic shock 0.97, nursing home 0.91, anticoagulated 0.94, cardiac etiology 0.92, and pneumonia 0.97. DISCUSSION The resulting phenotypes are interpretable and fast to build, and perform comparably to statistically learned phenotypes developed with 5000 manually labeled patients. CONCLUSION Learning with anchors is an attractive option for building a large public repository of phenotype definitions that can be used for a range of health IT applications, including real-time decision support.},
author = {Halpern, Yoni and Horng, Steven and Choi, Youngduck and Sontag, David},
doi = {10.1093/jamia/ocw011},
file = {:Users/na399/GitHub/thesis/references/papers/Halpern et al.{\_}2016{\_}Electronic medical record phenotyping using the anchor and learn framework{\_}Journal of the American Medical Informati.pdf:pdf},
isbn = {1527-974X (Electronic) 1067-5027 (Linking)},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Clinical decision support systems,Electronic health records,Knowledge representation,Machine learning,Natural language processing,disease:general,rank:90,relevancy:A,topic:CDSS,topic:EHR,type:research},
mendeley-tags = {disease:general,rank:90,relevancy:A,topic:CDSS,topic:EHR,type:research},
number = {4},
pages = {731--740},
pmid = {27107443},
title = {{Electronic medical record phenotyping using the anchor and learn framework}},
volume = {23},
year = {2016}
}
@inproceedings{Zhang2017c,
abstract = {{\textcopyright} 2017 IEEE. The increasing adoption of electronic health record (EHR) systems has brought tremendous opportunities in medicine enabling more personalized prognostic models. However, most work to date has investigated the binary classification problem for predicting the onset of one chronic disease, but little attention has been given to assessing risk of developing comorbidities that are major causes of morbidity and mortality. For example, type 2 diabetes and chronic kidney disease frequently accompany congestive heart failure. This paper is motivated by the problem of predicting comorbid diseases and aims to answer the following question: Can we predict the comorbid risk using a patient's medical history? We propose a new predictive learning framework, Heterogeneous Convolutional Neural Network (HCNN), that represents EHRs as graphs with heterogeneous attributes (e.g. diagnoses, procedures, and medication), and then develop a novel deep learning methodology for risk prediction of multiple comorbid diseases. The main innovation of the framework is that it defines the distance between the heterogeneous attributes of the graph representation extracted from the EHR and develops an appropriate learning infrastructure that is a composition of sparse convolutional layers and local pooling steps that match with the local structure of the space of the heterogeneous attributes. As a result, the new method is capable of capturing features about the relationships between heterogeneous attributes of the graphs. Through a comparative study on patient EHR data, HCNN achieves better performance than traditional convolutional neural networks on the risk prediction of comorbid diseases.},
author = {Zhang, Jinghe and Gong, Jiaqi and Barnes, Laura},
booktitle = {2017 IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies (CHASE)},
doi = {10.1109/CHASE.2017.80},
file = {:Users/na399/GitHub/thesis/references/papers/Zhang, Gong, Barnes{\_}2017{\_}HCNN Heterogeneous Convolutional Neural Networks for Comorbid Risk Prediction with Electronic Health Records{\_}Pr.pdf:pdf},
isbn = {978-1-5090-4722-2},
keywords = {Electronic Health Records,Heterogeneous Convolution,Neural Networks,Risk Prediction,rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
month = {jul},
pages = {214--221},
publisher = {IEEE},
title = {{HCNN: Heterogeneous Convolutional Neural Networks for Comorbid Risk Prediction with Electronic Health Records}},
url = {http://ieeexplore.ieee.org/document/8010635/},
year = {2017}
}
@article{Society1988,
abstract = {A causal network is used in a number of areas as a depiction of patterns of `influence' among sets of variables. In expert systems it is common to perform `inference' by means of local computations on such large but sparse networks. In general, non-probabilistic methods are used to handle uncertainty when propagating the effects of evidence, and it has appeared that exact probabilistic methods are not computationally feasible. Motivated by an application in electromyography, we counter this claim by exploiting a range of local representations for the joint probability distribution, combined with topological changes to the original network termed `marrying' and `filling-in'. The resulting structure allows efficient algorithms for transfer between representations, providing rapid absorption and propagation of evidence. The scheme is first illustrated on a small, fictitious but challenging example, and the underlying theory and computational aspects are then discussed.},
author = {Society, Royal Statistical},
doi = {10.2307/2345762},
file = {:Users/na399/GitHub/thesis/references/papers/Society{\_}1988{\_}Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems{\_}Journal of the Royal.pdf:pdf},
isbn = {00359246},
issn = {0035-9246},
journal = {Journal of the Royal Statistical Society},
keywords = {model:Bayesian,rank:99,relevancy:A,type:education},
mendeley-tags = {model:Bayesian,rank:99,relevancy:A,type:education},
number = {2},
pages = {157--224},
title = {{Local Computations with Probabilities on Graphical Structures and Their Application to Expert Systems}},
volume = {50},
year = {1988}
}
@article{Han2015,
abstract = {Biomedical Informatics is a growing interdisciplinary field in which research topics and citation trends have been evolving rapidly in recent years. To analyze these data in a fast, reproducible manner, automation of certain processes is needed. JAMIA is a "generalist" journal for biomedical informatics. Its articles reflect the wide range of topics in informatics. In this study, we retrieved Medical Subject Headings (MeSH) terms and citations of JAMIA articles published between 2009 and 2014. We use tensors (i.e., multidimensional arrays) to represent the interaction among topics, time and citations, and applied tensor decomposition to automate the analysis. The trends represented by tensors were then carefully interpreted and the results were compared with previous findings based on manual topic analysis. A list of most cited JAMIA articles, their topics, and publication trends over recent years is presented. The analyses confirmed previous studies and showed that, from 2012 to 2014, the number of articles related to MeSH terms Methods, Organization {\&} Administration, and Algorithms increased significantly both in number of publications and citations. Citation trends varied widely by topic, with Natural Language Processing having a large number of citations in particular years, and Medical Record Systems, Computerized remaining a very popular topic in all years.},
author = {Han, Dong and Wang, Shuang and Jiang, Chao and Jiang, Xiaoqian and Kim, Hyeon Eui and Sun, Jimeng and Ohno-Machado, Lucila},
doi = {10.1093/jamia/ocv157},
file = {:Users/na399/GitHub/thesis/references/papers/Han et al.{\_}2015{\_}Trends in biomedical informatics Automated topic analysis of JAMIA articles{\_}Journal of the American Medical Informatics.pdf:pdf},
isbn = {1527-974X (Electronic) 1067-5027 (Linking)},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Bioinformatics,Biomedical informatics,Citation analysis,Medical subject headings,Tensor factorization,rank:90,relevancy:C,topic:trend,type:analysis},
mendeley-tags = {rank:90,relevancy:C,topic:trend,type:analysis},
number = {6},
pages = {1153--1163},
pmid = {26555018},
title = {{Trends in biomedical informatics: Automated topic analysis of JAMIA articles}},
volume = {22},
year = {2015}
}
@article{Bagley2016,
abstract = {Patterns of disease co-occurrence that deviate from statistical independence may represent important constraints on biological mechanism, which sometimes can be explained by shared genetics. In this work we study the relationship between disease co-occurrence and commonly shared genetic architecture of disease. Records of pairs of diseases were combined from two different electronic medical systems (Columbia, Stanford), and compared to a large database of published disease-associated genetic variants (VARIMED); data on 35 disorders were available across all three sources, which include medical records for over 1.2 million patients and variants from over 17,000 publications. Based on the sources in which they appeared, disease pairs were categorized as having predominant clinical, genetic, or both kinds of manifestations. Confounding effects of age on disease incidence were controlled for by only comparing diseases when they fall in the same cluster of similarly shaped incidence patterns. We find that disease pairs that are overrepresented in both electronic medical record systems and in VARIMED come from two main disease classes, autoimmune and neuropsychiatric. We furthermore identify specific genes that are shared within these disease groups.},
author = {Bagley, Steven C. and Sirota, Marina and Chen, Richard and Butte, Atul J. and Altman, Russ B.},
doi = {10.1371/journal.pcbi.1004885},
editor = {Kann, Maricel},
file = {:Users/na399/GitHub/thesis/references/papers/Bagley et al.{\_}2016{\_}Constraints on Biological Mechanism from Disease Comorbidity Using Electronic Medical Records and Database of Genetic.PDF:PDF},
issn = {1553-7358},
journal = {PLOS Computational Biology},
keywords = {disease:general,model:network,rank:99,relevancy:C,topic:comorbidity,type:research},
mendeley-tags = {disease:general,model:network,rank:99,topic:comorbidity,type:research,relevancy:C},
month = {apr},
number = {4},
pages = {e1004885},
pmid = {27115429},
title = {{Constraints on Biological Mechanism from Disease Comorbidity Using Electronic Medical Records and Database of Genetic Variants}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1004885},
volume = {12},
year = {2016}
}
@article{Nguyen2017,
abstract = {Feature engineering remains a major bottleneck when creating predictive systems from electronic medical records. At present, an important missing element is detecting predictive regular clinical motifs from irregular episodic records. We present Deepr (short for Deep record), a new end-to-end deep learning system that learns to extract features from medical records and predicts future risk automatically. Deepr transforms a record into a sequence of discrete elements separated by coded time gaps and hospital transfers. On top of the sequence is a convolutional neural net that detects and combines predictive local clinical motifs to stratify the risk. Deepr permits transparent inspection and visualization of its inner working. We validate Deepr on hospital data to predict unplanned readmission after discharge. Deepr achieves superior accuracy compared to traditional techniques, detects meaningful clinical motifs, and uncovers the underlying structure of the disease and intervention space.},
archivePrefix = {arXiv},
arxivId = {1607.07519},
author = {Nguyen, Phuoc and Tran, Truyen and Wickramasinghe, Nilmini and Venkatesh, Svetha},
doi = {10.1109/JBHI.2016.2633963},
eprint = {1607.07519},
file = {:Users/na399/GitHub/thesis/references/papers/Nguyen et al.{\_}2017{\_}Deepr A Convolutional Net for Medical Records{\_}IEEE Journal of Biomedical and Health Informatics.pdf:pdf},
isbn = {2168-2194 VO - 21},
issn = {21682194},
journal = {IEEE Journal of Biomedical and Health Informatics},
keywords = {Convolutional neural networks,deep learning,medical records,model:DeepLearning,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
mendeley-tags = {model:DeepLearning,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
number = {1},
pages = {22--30},
pmid = {27913366},
title = {{Deepr: A Convolutional Net for Medical Records}},
volume = {21},
year = {2017}
}
@article{Ho2014,
abstract = {The rapidly increasing availability of electronic health records (EHRs) from multiple heterogeneous sources has spearheaded the adoption of data-driven approaches for improved clinical research, decision making, prognosis, and patient management. Unfortunately, EHR data do not always directly and reliably map to medical concepts that clinical researchers need or use. Some recent studies have focused on EHR-derived phenotyping, which aims at mapping the EHR data to specific medical concepts; however, most of these approaches require labor intensive supervision from experienced clinical professionals. Furthermore, existing approaches are often disease-centric and specialized to the idiosyncrasies of the information technology and/or business practices of a single healthcare organization. In this paper, we propose Limestone, a nonnegative tensor factorization method to derive phenotype candidates with virtually no human supervision. Limestone represents the data source interactions naturally using tensors (a generalization of matrices). In particular, we investigate the interaction of diagnoses and medications among patients. The resulting tensor factors are reported as phenotype candidates that automatically reveal patient clusters on specific diagnoses and medications. Using the proposed method, multiple phenotypes can be identified simultaneously from data. We demonstrate the capability of Limestone on a cohort of 31,815 patient records from the Geisinger Health System. The dataset spans 7. years of longitudinal patient records and was initially constructed for a heart failure onset prediction study. Our experiments demonstrate the robustness, stability, and the conciseness of Limestone-derived phenotypes. Our results show that using only 40 phenotypes, we can outperform the original 640 features (169 diagnosis categories and 471 medication types) to achieve an area under the receiver operator characteristic curve (AUC) of 0.720 (95{\%} CI 0.715 to 0.725). Moreover, in consultation with a medical expert, we confirmed 82{\%} of the top 50 candidates automatically extracted by Limestone are clinically meaningful.},
author = {Ho, Joyce C. and Ghosh, Joydeep and Steinhubl, Steve R. and Stewart, Walter F. and Denny, Joshua C. and Malin, Bradley A. and Sun, Jimeng},
doi = {10.1016/j.jbi.2014.07.001},
file = {:Users/na399/GitHub/thesis/references/papers/Ho et al.{\_}2014{\_}Limestone High-throughput candidate phenotype generation via tensor factorization{\_}Journal of Biomedical Informatics.pdf:pdf},
isbn = {1532-0480 (Electronic)$\backslash$r1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Dimensionality reduction,EHR phenotyping,Nonnegative tensor factorization,rank:85,relevancy:B,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {rank:85,type:research,relevancy:B,topic:EHR,topic:phenotyping},
pages = {199--211},
pmid = {25038555},
publisher = {Elsevier Inc.},
title = {{Limestone: High-throughput candidate phenotype generation via tensor factorization}},
url = {http://dx.doi.org/10.1016/j.jbi.2014.07.001},
volume = {52},
year = {2014}
}
@article{Mohammadhassanzadeh2017,
abstract = {Capturing complete medical knowledge is challenging-often due to incomplete patient Electronic Health Records (EHR), but also because of valuable, tacit medical knowledge hidden away in physicians' experiences. To extend the coverage of incomplete medical knowledge-based systems beyond their deductive closure, and thus enhance their decision-support capabilities, we argue that innovative, multi-strategy reasoning approaches should be applied. In particular, plausible reasoning mechanisms apply patterns from human thought processes, such as generalization, similarity and interpolation, based on attributional, hierarchical, and relational knowledge. Plausible reasoning mechanisms include inductive reasoning, which generalizes the commonalities among the data to induce new rules, and analogical reasoning, which is guided by data similarities to infer new facts. By further leveraging rich, biomedical Semantic Web ontologies to represent medical knowledge, both known and tentative, we increase the accuracy and expressivity of plausible reasoning, and cope with issues such as data heterogeneity, inconsistency and interoperability. In this paper, we present a Semantic Web-based, multi-strategy reasoning approach, which integrates deductive and plausible reasoning and exploits Semantic Web technology to solve complex clinical decision support queries. We evaluated our system using a real-world medical dataset of patients with hepatitis, from which we randomly removed different percentages of data (5{\%}, 10{\%}, 15{\%}, and 20{\%}) to reflect scenarios with increasing amounts of incomplete medical knowledge. To increase the reliability of the results, we generated 5 independent datasets for each percentage of missing values, which resulted in 20 experimental datasets (in addition to the original dataset). The results show that plausibly inferred knowledge extends the coverage of the knowledge base by, on average, 2{\%}, 7{\%}, 12{\%}, and 16{\%} for datasets with, respectively, 5{\%}, 10{\%}, 15{\%}, and 20{\%} of missing values. This expansion in the KB coverage allowed solving complex disease diagnostic queries that were previously unresolvable, without losing the correctness of the answers. However, compared to deductive reasoning, data-intensive plausible reasoning mechanisms yield a significant performance overhead. We observed that plausible reasoning approaches, by generating tentative inferences and leveraging domain knowledge of experts, allow us to extend the coverage of medical knowledge bases, resulting in improved clinical decision support. Second, by leveraging OWL ontological knowledge, we are able to increase the expressivity and accuracy of plausible reasoning methods. Third, our approach is applicable to clinical decision support systems for a range of chronic diseases.},
author = {Mohammadhassanzadeh, Hossein and {Van Woensel}, William and Abidi, Samina Raza and Abidi, Syed Sibte Raza},
doi = {10.1186/s13040-017-0123-y},
file = {:Users/na399/GitHub/thesis/references/papers/Mohammadhassanzadeh et al.{\_}2017{\_}Semantics-based plausible reasoning to extend the knowledge coverage of medical knowledge bases for impr.pdf:pdf},
issn = {17560381},
journal = {BioData Mining},
keywords = {Analogical reasoning,Inductive generalization,Medical knowledge bases,Plausible reasoning,Semantic Web reasoning,rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
number = {1},
pages = {1--31},
pmid = {28203277},
publisher = {BioData Mining},
title = {{Semantics-based plausible reasoning to extend the knowledge coverage of medical knowledge bases for improved clinical decision support}},
volume = {10},
year = {2017}
}
@article{Thornton-Wells2008,
abstract = {Common diseases with a genetic basis are likely to have a very complex etiology, in which the mapping between genotype and phenotype is far from straightforward. A new comprehensive statistical and computational strategy for identifying the missing link between genotype and phenotype has been proposed, which emphasizes the need to address heterogeneity in the first stage of any analysis and gene-gene interactions in the second stage. We applied this two-stage analysis strategy to late-onset Alzheimer disease (LOAD) data, which included functional and positional candidate genes and markers in a region of interest on chromosome 10. Bayesian classification found statistically significant clusterings for independent family-based and case-control datasets, which used the same five markers in leucine-rich repeat transmembrane neuronal 3 (LRRTM3) as the most influential in determining cluster assignment. In subsequent analyses to detect main effects and gene-gene interactions, markers in three genes--urokinase-type plasminogen activator (PLAU), angiotensin 1 converting enzyme (ACE) and cell division cycle 2 (CDC2)--were found to be associated with LOAD in particular subsets of the data based on their LRRTM3 multilocus genotype. All of these genes are viable candidates for LOAD based on their known biological function, even though PLAU, CDC2 and LRRTM3 were initially identified as positional candidates. Further studies are needed to replicate these statistical findings and to elucidate possible biological interaction mechanisms between LRRTM3 and these genes.},
author = {Thornton-Wells, Tricia A. and Moore, Jason H. and Martin, Eden R. and Pericak-Vance, Margaret A. and Haines, Jonathan L.},
doi = {10.1002/gepi.20294},
file = {:Users/na399/GitHub/thesis/references/papers/Thornton-Wells et al.{\_}2008{\_}Confronting complexity in late-onset Alzheimer disease Application of two-stage analysis approach addressing.pdf:pdf},
isbn = {0741-0395 (Print)$\backslash$n0741-0395 (Linking)},
issn = {07410395},
journal = {Genetic Epidemiology},
keywords = {Alzheimer disease,Association,Bayesian classification,Clustering,Complex disease,Epistasis,Gene-gene interaction,Heterogeneity,Linkage,Logistic regression,Multifactor dimensionality reduction,Statistical genetics,rank:60,relevancy:C},
mendeley-tags = {rank:60,relevancy:C},
number = {3},
pages = {187--203},
pmid = {18076107},
title = {{Confronting complexity in late-onset Alzheimer disease: Application of two-stage analysis approach addressing heterogeneity and epistasis}},
volume = {32},
year = {2008}
}
@article{Sposato2015,
abstract = {Discussion | To our knowledge, this is the first study showing a decline in dementia incidence over time. This report may also be unique in showing a corresponding decline in stroke inci- dence in the same population. Previous evidence suggests that diet, exercise, cognitive training, and vascular risk monitor- ing may improve or maintain cognitive functioning in at-risk elderly people.4 Hence, primary prevention strategies result- ing in improved risk-factor control may have concurrently re- duced dementia risk.5 In addition, given that cerebrovascular disease is an important cause of dementia and that 60 to 80{\%} of all major dementias have a vascular component, the falling incidence of stroke may have further contributed to the de- cline in dementia incidence.},
author = {Sposato, Luciano A. and Kapral, Moira K. and Fang, Jiming and Gill, Sudeep S. and Hackam, Daniel G. and Cipriano, Lauren E. and Hachinski, Vladimir},
doi = {10.1001/jamaneurol.2015.2816},
file = {:Users/na399/Downloads/Research Papers/Sposato et al.{\_}2015{\_}Declining incidence of stroke and dementia Coincidence or prevention opportunity{\_}JAMA Neurology.pdf:pdf},
issn = {21686149},
journal = {JAMA Neurology},
keywords = {disease:dementia,rank:95,relevancy:B,topic:impact,type:commentary},
mendeley-tags = {disease:dementia,rank:95,relevancy:B,topic:impact,type:commentary},
number = {12},
pages = {1529--1531},
pmid = {26658969},
title = {{Declining incidence of stroke and dementia: Coincidence or prevention opportunity?}},
volume = {72},
year = {2015}
}
@article{Dyagilev2016,
abstract = {A large and diverse set of measurements are regularly collected during a patient's hospital stay to monitor their health status. Tools for integrating these measurements into severity scores, that accurately track changes in illness severity, can improve clinicians ability to provide timely interventions. Existing approaches for creating such scores either 1) rely on experts to fully specify the severity score, or 2) train a predictive score, using supervised learning, by regressing against a surrogate marker of severity such as the presence of downstream adverse events. The first approach does not extend to diseases where an accurate score cannot be elicited from experts. The second approach often produces scores that suffer from bias due to treatment-related censoring (Paxton, 2013). We propose a novel ranking based framework for disease severity score learning (DSSL). DSSL exploits the following key observation: while it is challenging for experts to quantify the disease severity at any given time, it is often easy to compare the disease severity at two different times. Extending existing ranking algorithms, DSSL learns a function that maps a vector of patient's measurements to a scalar severity score such that the resulting score is temporally smooth and consistent with the expert's ranking of pairs of disease states. We apply DSSL to the problem of learning a sepsis severity score using a large, real-world dataset. The learned scores significantly outperform state-of-the-art clinical scores in ranking patient states by severity and in early detection of future adverse events. We also show that the learned disease severity trajectories are consistent with clinical expectations of disease evolution. Further, using simulated datasets, we show that DSSL exhibits better generalization performance to changes in treatment patterns compared to the above approaches.},
archivePrefix = {arXiv},
arxivId = {1507.07295},
author = {Dyagilev, Kirill and Saria, Suchi},
doi = {10.1007/s10994-015-5527-7},
eprint = {1507.07295},
file = {:Users/na399/GitHub/thesis/references/papers/Dyagilev, Saria{\_}2016{\_}Learning (predictive) risk scores in the presence of censoring due to interventions{\_}Machine Learning.pdf:pdf},
issn = {15730565},
journal = {Machine Learning},
keywords = {Gradient boosted regression trees,MIMIC,Ranking,Sepsis,Severity score,rank:80,relevancy:C},
mendeley-tags = {rank:80,relevancy:C},
number = {3},
pages = {323--348},
publisher = {Springer US},
title = {{Learning (predictive) risk scores in the presence of censoring due to interventions}},
volume = {102},
year = {2016}
}
@article{Choi2017,
abstract = {Objective: We explored whether use of deep learning to model temporal relations among events in electronic health records (EHRs) would improve model performance in predicting initial diagnosis of heart failure (HF) compared to conventional methods that ignore temporality. Materials and Methods: Data were from a health system's EHR on 3884 incident HF cases and 28 903 controls, identified as primary care patients, between May 16, 2000, and May 23, 2013. Recurrent neural network (RNN) models using gated recurrent units (GRUs) were adapted to detect relations among time-stamped events (eg, disease diagnosis, medication orders, procedure orders, etc.) with a 12-to 18-month observation window of cases and controls. Model performance metrics were compared to regularized logistic regression, neural net-work, support vector machine, and K-nearest neighbor classifier approaches. Results: Using a 12-month observation window, the area under the curve (AUC) for the RNN model was 0.777, compared to AUCs for logistic regression (0.747), multilayer perceptron (MLP) with 1 hidden layer (0.765), sup-port vector machine (SVM) (0.743), and K-nearest neighbor (KNN) (0.730). When using an 18-month observation window, the AUC for the RNN model increased to 0.883 and was significantly higher than the 0.834 AUC for the best of the baseline methods (MLP). Conclusion: Deep learning models adapted to leverage temporal relations appear to improve performance of models for detection of incident heart failure with a short observation window of 12–18 months. OBJECTIVE Before diagnosis of a disease, an individual's progression mediated by pathophysiologic changes distinguishes those who will eventually get the disease from those who will not. Detection of temporal event sequences that reliably distinguish disease cases from controls may be particularly useful in improving predictive model performance. We investigated whether recurrent neural network (RNN) models could be adapted for this purpose, converting clinical event se-quences and related time-stamped data into pathways relevant to early detection of disease. Electronic health record (EHR) data capture rich clinical and re-lated temporal information. Patient health care encounters are well documented (eg, diagnoses, medications, and procedures) and time-stamped. However, EHR data are highly complex, given the struc-ture and breadth of information captured (spanning provider behav-ior, care utilization, treatment pathways, and patient disease state) and irregular sampling frequency. To date, most predictive modeling work using EHR data rely on aggregate features (eg, event count and event average). Temporal relations among disaggregated fea-tures (eg, medication ordered at one time and procedure performed at another) are not captured using these methods. We applied RNN models to heart failure (HF) cases and controls using longitudinal EHR data, and compared the model performance to traditional machine learning approaches. HF is one of the leading causes of morbidity and mortality among elderly individuals in de-veloped economies and accounts for significant and growing health care expenditures. 1,2 Improved early detection could open new op-portunities for delaying or preventing progression to diagnosis of HF and reduce cost.},
author = {Choi, Edward and Schuetz, Andy and Stewart, Walter F. and Sun, Jimeng},
doi = {10.1093/jamia/ocw112},
file = {:Users/na399/GitHub/thesis/references/papers/Choi et al.{\_}2017{\_}Using recurrent neural network models for early detection of heart failure onset{\_}Journal of the American Medical Inform.pdf:pdf},
isbn = {1527-974X (Electronic) 1067-5027 (Linking)},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Deep learning,Electronic health records,Heart failure prediction,Patient progression model,Recurrent neural network,disease:CVD,model:DeepLearning,model:SVM,rank:90,relevancy:B,topic:EHR,topic:diagnosis,topic:progression,type:research},
mendeley-tags = {disease:CVD,model:DeepLearning,model:SVM,rank:90,relevancy:B,topic:EHR,topic:diagnosis,topic:progression,type:research},
number = {2},
pages = {361--370},
pmid = {27521897},
title = {{Using recurrent neural network models for early detection of heart failure onset}},
volume = {24},
year = {2017}
}
@inproceedings{Henderson2017a,
abstract = {One of the most formidable challenges electronic health records (EHRs) pose for traditional analytics is the inability to map directly (or reliably) to medical concepts or phenotypes. Among other things, EHR-based phenotyping can help identify and target patients for interventions and improve real-time clinical decisions. Existing phenotyping approaches often require labor-intensive supervision from medical experts or do not focus on generating concise and diverse phenotypes. Sparsity in phenotypes is key to making them interpretable and useful to clinicians, while diversity allows clinicians to grasp the main features of a patient population quickly.In this paper, we introduce Granite, a diversified, sparse nonnegative tensor factorization method to derive phenotypes with limited human supervision. Compared to existing high-throughput phenotyping techniques, Granite yields phenotypes with much more distinct (non-overlapping) elements that can, as an artifact, capture rare phenotypes. Moreover, the resulting concise phenotypes retain predictive powers comparable to or surpassing existing dimensionality reduction techniques. We evaluate Granite by comparing its resulting phenotypes with those generated using state-of-the-art, high-throughput methods on simulated as well as real EHR data. Our algorithm offers a promising and novel data-driven solution to rapidly characterize, predict, and manage a wide range of diseases. {\textcopyright} 2017 IEEE.},
author = {Henderson, Jette and Ho, Joyce C. and Kho, Abel N. and Denny, Joshua C. and Malin, Bradley A. and Sun, Jimeng and Ghosh, Joydeep},
booktitle = {2017 IEEE International Conference on Healthcare Informatics (ICHI)},
doi = {10.1109/ICHI.2017.61},
file = {:Users/na399/GitHub/thesis/references/papers/Henderson et al.{\_}2017{\_}Granite Diversified, Sparse Tensor Factorization for Electronic Health Record-Based Phenotyping{\_}Proceedings - 2017.pdf:pdf},
isbn = {978-1-5090-4881-6},
keywords = {Computational phenotyping,Data mining,Electronic health records,Feature extraction,Health information management,Tensor factorization,rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
month = {aug},
pages = {214--223},
publisher = {IEEE},
title = {{Granite: Diversified, Sparse Tensor Factorization for Electronic Health Record-Based Phenotyping}},
url = {http://ieeexplore.ieee.org/document/8031150/},
year = {2017}
}
@article{Hopper2008,
author = {Hopper, Louise and Hughes, Suzanne and Burke, Teresa and Irving, Kate},
file = {:Users/na399/Downloads/Research Papers/Hopper et al.{\_}2008{\_}a National Dementia Registry for Ireland{\_}Unknown.pdf:pdf},
keywords = {rank:n/a,relevancy:D},
mendeley-tags = {rank:n/a,relevancy:D},
title = {{a National Dementia Registry for Ireland}},
year = {2008}
}
@article{Beck2016,
abstract = {Sepsis affects millions of people every year, many of whom will die. In contrast to current survival prediction models for sepsis patients that primarily are based on data from within-admission clinical measurements (e.g. vital parameters and blood values), we aim for using the full disease history to predict sepsis mortality. We benefit from data in electronic medical records covering all hospital encounters in Denmark from 1996 to 2014. This data set included 6.6 million patients of whom almost 120,000 were diagnosed with the ICD-10 code: A41 'Other sepsis'. Interestingly, patients following recurrent trajectories of time-ordered co-morbidities had significantly increased sepsis mortality compared to those who did not follow a trajectory. We identified trajectories which significantly altered sepsis mortality, and found three major starting points in a combined temporal sepsis network: Alcohol abuse, Diabetes and Cardio-vascular diagnoses. Many cancers also increased sepsis mortality. Using the trajectory based stratification model we explain contradictory reports in relation to diabetes that recently have appeared in the literature. Finally, we compared the predictive power using 18.5 years of disease history to scoring based on within-admission clinical measurements emphasizing the value of long term data in novel patient scores that combine the two types of data.},
author = {Beck, Mette K. and Jensen, Anders Boeck and Nielsen, Annelaura Bach and Perner, Anders and Moseley, Pope L. and Brunak, S{\o}ren},
doi = {10.1038/srep36624},
file = {:Users/na399/GitHub/thesis/references/papers/Beck et al.{\_}2016{\_}Diagnosis trajectories of prior multi-morbidity predict sepsis mortality{\_}Scientific Reports.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
keywords = {disease:sepsis,rank:95,relevancy:A,topic:EHR,topic:trajectory,type:research},
mendeley-tags = {disease:sepsis,rank:95,relevancy:A,topic:EHR,topic:trajectory,type:research},
number = {July},
pages = {1--9},
pmid = {27812043},
publisher = {Nature Publishing Group},
title = {{Diagnosis trajectories of prior multi-morbidity predict sepsis mortality}},
url = {http://dx.doi.org/10.1038/srep36624},
volume = {6},
year = {2016}
}
@article{Possin2017,
abstract = {Katherine Possin and colleagues report on the implementation, development, and early findings of the Care Ecosystem, an adaptive, personalized, and scalable dementia care program.},
author = {Possin, Katherine L. and Merrilees, Jennifer and Bonasera, Stephen J. and Bernstein, Alissa and Chiong, Winston and Lee, Kirby and Wilson, Leslie and Hooper, Sarah M. and Dulaney, Sarah and Braley, Tamara and Laohavanich, Sutep and Feuer, Julie E. and Clark, Amy M. and Schaffer, Michael W. and Schenk, A. Katrin and Heunis, Julia and Ong, Paulina and Cook, Kristen M. and Bowhay, Angela D. and Gearhart, Rosalie and Chodos, Anna and Naasan, Georges and Bindman, Andrew B. and Dohan, Daniel and Ritchie, Christine and Miller, Bruce L.},
doi = {10.1371/journal.pmed.1002260},
file = {:Users/na399/Downloads/Research Papers/Possin et al.{\_}2017{\_}Development of an adaptive, personalized, and scalable dementia care program Early findings from the Care Ecosystem{\_}P.pdf:pdf},
isbn = {1111111111},
issn = {1549-1676},
journal = {PLOS Medicine},
keywords = {disease:dementia,rank:99,relevancy:D,topic:treatment,type:research},
mendeley-tags = {disease:dementia,rank:99,relevancy:D,topic:treatment,type:research},
month = {mar},
number = {3},
pages = {e1002260},
pmid = {28323819},
title = {{Development of an adaptive, personalized, and scalable dementia care program: Early findings from the Care Ecosystem}},
url = {http://dx.plos.org/10.1371/journal.pmed.1002260},
volume = {14},
year = {2017}
}
@article{Peissig2014,
abstract = {Objective: Electronic health records (EHR) offer medical and pharmacogenomics research unprecedented opportunities to identify and classify patients at risk. EHRs are collections of highly inter-dependent records that include biological, anatomical, physiological, and behavioral observations. They comprise a patient's clinical phenome, where each patient has thousands of date-stamped records distributed across many relational tables. Development of EHR computer-based phenotyping algorithms require time and medical insight from clinical experts, who most often can only review a small patient subset representative of the total EHR records, to identify phenotype features. In this research we evaluate whether relational machine learning (ML) using inductive logic programming (ILP) can contribute to addressing these issues as a viable approach for EHR-based phenotyping. Methods: Two relational learning ILP approaches and three well-known WEKA (Waikato Environment for Knowledge Analysis) implementations of non-relational approaches (PART, J48, and JRIP) were used to develop models for nine phenotypes. International Classification of Diseases, Ninth Revision (ICD-9) coded EHR data were used to select training cohorts for the development of each phenotypic model. Accuracy, precision, recall, F-Measure, and Area Under the Receiver Operating Characteristic (AUROC) curve statistics were measured for each phenotypic model based on independent manually verified test cohorts. A two-sided binomial distribution test (sign test) compared the five ML approaches across phenotypes for statistical significance. Results: We developed an approach to automatically label training examples using ICD-9 diagnosis codes for the ML approaches being evaluated. Nine phenotypic models for each ML approach were evaluated, resulting in better overall model performance in AUROC using ILP when compared to PART (p= 0.039), J48 (p= 0.003) and JRIP (p= 0.003). Discussion: ILP has the potential to improve phenotyping by independently delivering clinically expert interpretable rules for phenotype definitions, or intuitive phenotypes to assist experts. Conclusion: Relational learning using ILP offers a viable approach to EHR-driven phenotyping.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Peissig, Peggy L. and {Santos Costa}, Vitor and Caldwell, Michael D. and Rottscheit, Carla and Berg, Richard L. and Mendonca, Eneida A. and Page, David},
doi = {10.1016/j.jbi.2014.07.007},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/Peissig et al.{\_}2014{\_}Relational machine learning for electronic health record-driven phenotyping{\_}Journal of Biomedical Informatics.pdf:pdf},
isbn = {6176321972},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Electronic health record,Inductive logic programming,Machine learning,Phenotyping,Relational machine learning,disease:dementia,disease:general,rank:85,relevancy:A,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {rank:85,type:research,relevancy:A,topic:EHR,topic:phenotyping,disease:general,disease:dementia},
pages = {260--270},
pmid = {25048351},
publisher = {Elsevier Inc.},
title = {{Relational machine learning for electronic health record-driven phenotyping}},
url = {http://dx.doi.org/10.1016/j.jbi.2014.07.007},
volume = {52},
year = {2014}
}
@article{Weiss2015,
abstract = {BACKGROUND: Biological data mining is a powerful tool that can provide a wealth of information about patterns of genetic and genomic biomarkers of health and disease. A potential disadvantage of data mining is volume and complexity of the results that can often be overwhelming. It is our working hypothesis that visualization methods can greatly enhance our ability to make sense of data mining results. More specifically, we propose that 3-D printing has an important role to play as a visualization technology in biological data mining. We provide here a brief review of 3-D printing along with a case study to illustrate how it might be used in a research setting.$\backslash$n$\backslash$nRESULTS: We present as a case study a genetic interaction network associated with grey matter density, an endophenotype for late onset Alzheimer's disease, as a physical model constructed with a 3-D printer. The synergy or interaction effects of multiple genetic variants were represented through a color gradient of the physical connections between nodes. The digital gene-gene interaction network was then 3-D printed to generate a physical network model.$\backslash$n$\backslash$nCONCLUSIONS: The physical 3-D gene-gene interaction network provided an easily manipulated, intuitive and creative way to visualize the synergistic relationships between the genetic variants and grey matter density in patients with late onset Alzheimer's disease. We discuss the advantages and disadvantages of this novel method of biological data mining visualization.},
author = {Weiss, Talia L. and Zieselman, Amanda and Hill, Douglas P. and Diamond, Solomon G. and Shen, Li and Saykin, Andrew J. and Moore, Jason H.},
doi = {10.1186/s13040-015-0056-2},
file = {:Users/na399/OneDrive - K{\o}benhavns Universitet/Project/report/Paper/241017/Weiss et al.{\_}2015{\_}The role of visualization and 3-D printing in biological data mining{\_}BioData Mining.pdf:pdf},
issn = {1756-0381},
journal = {BioData Mining},
keywords = {rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
number = {1},
pages = {22},
pmid = {26246856},
publisher = {BioData Mining},
title = {{The role of visualization and 3-D printing in biological data mining}},
url = {http://biodatamining.biomedcentral.com/articles/10.1186/s13040-015-0056-2},
volume = {8},
year = {2015}
}
@article{Thathiah2011,
abstract = {G protein-coupled receptors (GPCRs) are involved in numerous key neurotransmitter systems in the brain that are disrupted in Alzheimer's disease (AD). GPCRs also directly influence the amyloid cascade through modulation of the $\alpha$-, $\beta$- and $\gamma$-secretases, proteolysis of the amyloid precursor protein (APP), and regulation of amyloid-$\beta$ degradation. Additionally, amyloid-$\beta$ has been shown to perturb GPCR function. Emerging insights into the mechanistic link between GPCRs and AD highlight the potential of this class of receptors as a therapeutic target for AD.},
author = {Thathiah, Amantha and {De Strooper}, Bart},
doi = {10.1038/nrn2977},
file = {:Users/na399/Downloads/Research Papers/Thathiah, De Strooper{\_}2011{\_}The role of G protein-coupled receptors in the pathology of Alzheimer's disease{\_}Nature Reviews Neuroscience.pdf:pdf},
isbn = {1471-0048 (Electronic)$\backslash$n1471-003X (Linking)},
issn = {1471003X},
journal = {Nature Reviews Neuroscience},
keywords = {disease:dementia,rank:99,relevancy:C,topic:molecular,type:review},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:molecular,type:review},
number = {2},
pages = {73--87},
pmid = {21248787},
publisher = {Nature Publishing Group},
title = {{The role of G protein-coupled receptors in the pathology of Alzheimer's disease}},
url = {http://dx.doi.org/10.1038/nrn2977},
volume = {12},
year = {2011}
}
@article{Castro2011,
author = {de Castro, Ana Karoline Ara{\'{u}}jo and Pinheiro, Pl{\'{a}}cido Rog{\'{e}}rio and {Dantas Pinheiro}, Mirian Cal$\backslash$'$\backslash$iope and Tamanini, Isabelle},
doi = {10.1080/18756891.2011.9727766},
file = {:Users/na399/GitHub/thesis/references/papers/Castro et al.{\_}2011{\_}Towards the Applied Hybrid Model in Decision Making A Neuropsychological Diagnosis of Alzheimer's Disease Study Case{\_}.pdf:pdf},
journal = {International Journal of Computational Intelligence Systems},
keywords = {alzheimer,bayesian network,diagnosis,disease:dementia,influence diagram,multicriteria method,rank:75,relevancy:B,s disease},
mendeley-tags = {rank:75,relevancy:B,disease:dementia},
number = {1},
pages = {89--99},
title = {{Towards the Applied Hybrid Model in Decision Making: A Neuropsychological Diagnosis of Alzheimer's Disease Study Case}},
volume = {4},
year = {2011}
}
@article{Ellaway2013,
abstract = {This paper reflects on the extent to which we are preparing learners for practice in an electronic health record (EHR)-mediated world. We are currently training the last generation to remember a world without the Internet and the first who will practice in a largely EHR-mediated practice environment. We undertook a thematic review of the literature connecting medical education with e-health using the concepts of 'electronic health record' or 'electronic medical record' as a proxy for the broader notion of e-health. Our findings are more equivocal and cautious than earlier commentators might have expected and while there are examples of good practice and successful integration, the majority of articles we reviewed raised issues and problems with the current links between EHRs and medical education. Medical professionals in particular are quite ambivalent about many of the changes brought about by EHRs, and in the absence of changes in perception and practice it is likely that the connections between medical education and e-health will continue to be problematic. We hope that this paper will lead to an improved understanding of these problems and will serve to advance the discourse on how medical education should engage with the world of e-health and the world of e-health with medical education.},
author = {Ellaway, Rachel H. and Graves, Lisa and Greene, Peter S.},
doi = {10.3109/0142159X.2013.773396},
file = {:Users/na399/GitHub/thesis/references/papers/Ellaway, Graves, Greene{\_}2013{\_}Medical education in an electronic health record-mediated world{\_}Medical Teacher.pdf:pdf},
isbn = {1466-187X (Electronic)$\backslash$r0142-159X (Linking)},
issn = {0142159X},
journal = {Medical Teacher},
keywords = {rank:85,relevancy:D,topic:EHR,type:commentary},
mendeley-tags = {rank:85,type:commentary,relevancy:D,topic:EHR},
number = {4},
pages = {282--286},
pmid = {23464893},
title = {{Medical education in an electronic health record-mediated world}},
volume = {35},
year = {2013}
}
@article{Elibol2016,
abstract = {Patients with developmental disorders, such as autism spectrum disorder (ASD), present with symptoms that change with time even if the named diagnosis remains fixed. For exam-ple, language impairments may present as delayed speech in a toddler and difficulty reading in a school-age child. Characterizing these trajectories is important for early treatment. However, deriving these trajectories from observational sources is challenging: electronic health records only reflect observations of patients at irregular intervals and only record what factors are clinically relevant at the time of observation. Meanwhile, caretakers discuss daily developments and concerns on social media. In this work, we present a fully unsupervised approach for learning disease trajectories from incomplete medical records and social media posts, including cases in which we have only a single observation of each patient. In particular, we use a dynamic topic model approach which embeds each disease trajectory as a path in R D . A P{\'{o}}lya-gamma aug-mentation scheme is used to efficiently perform inference as well as incorporate multiple data sources. We learn disease trajectories from the electronic health records of 13,435 patients with ASD and the forum posts of 13,743 caretakers of children with ASD, deriving interesting clinical insights as well as good predictions.},
author = {Elibol, Huseyin Melih and Nguyen, Vincent and Linderman, Scott and Johnson, Matthew and Hashmi, Amna and Doshi-Velez, Finale},
file = {:Users/na399/GitHub/thesis/references/papers/Elibol et al.{\_}2016{\_}Cross-Corpora Unsupervised Learning of Trajectories in Autism Spectrum Disorders{\_}Journal of Machine Learning Research.pdf:pdf},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Disease progression model,Dynamic topic model,disease:psychiatry,model:dynamicTopic,rank:95,relevancy:B,topic:EHR,topic:prediction,topic:trajectory,type:research},
mendeley-tags = {disease:psychiatry,model:dynamicTopic,rank:95,relevancy:B,topic:EHR,topic:prediction,topic:trajectory,type:research},
pages = {1--38},
title = {{Cross-Corpora Unsupervised Learning of Trajectories in Autism Spectrum Disorders}},
volume = {17},
year = {2016}
}
@article{Brunson2017,
author = {Brunson, Jason Cory and Laubenbacher, Reinhard C},
doi = {10.1093/jamia/ocx052},
file = {:Users/na399/GitHub/thesis/references/papers/Brunson, Laubenbacher{\_}2017{\_}Applications of network analysis to routinely collected health care data a systematic review{\_}Journal of the A.pdf:pdf},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
keywords = {administrative data,and accessibility,as electronic information systems,background and significance,digitized clinical recordkeeping has,efficiency,ehr,graph theory,have increased in capacity,made routinely col-,network analysis,rank:90,relevancy:C,secondary use,topic:EHR,type:review},
mendeley-tags = {rank:90,relevancy:C,topic:EHR,type:review},
number = {March},
pages = {210--221},
title = {{Applications of network analysis to routinely collected health care data: a systematic review}},
url = {http://academic.oup.com/jamia/article/doi/10.1093/jamia/ocx052/4157164/Applications-of-network-analysis-to-routinely},
volume = {25},
year = {2017}
}
@inproceedings{Henderson2017,
author = {Henderson, Jette and Ho, Joyce and Ghosh, Joydeep},
booktitle = {2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)},
doi = {10.1109/EMBC.2017.8037647},
file = {:Users/na399/GitHub/thesis/references/papers/Henderson, Ho, Ghosh{\_}2017{\_}GamAID Greedy CP tensor decomposition for supervised EHR-based disease trajectory differentiation{\_}Proceedings.pdf:pdf},
isbn = {978-1-5090-2809-2},
issn = {1557170X},
keywords = {General and theoretical informatics - Computationa,rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
month = {jul},
pages = {3644--3647},
publisher = {IEEE},
title = {{gamAID: Greedy CP tensor decomposition for supervised EHR-based disease trajectory differentiation}},
url = {http://ieeexplore.ieee.org/document/8037647/},
year = {2017}
}
@article{Religa2015,
abstract = {BACKGROUND: The Swedish Dementia Registry (SveDem) was developed with the aim to improve the quality of diagnostic work-up, treatment and care of patients with dementia disorders in Sweden.$\backslash$n$\backslash$nMETHODS: SveDem is an internet based quality registry where several indicators can be followed over time. It includes information about the diagnostic work-up, medical treatment and community support (www.svedem.se). The patients are diagnosed and followed-up yearly in specialist units, primary care centres or in nursing homes.$\backslash$n$\backslash$nRESULTS: The database was initiated in May 2007 and covers almost all of Sweden. There were 28 722 patients registered with a mean age of 79.3 years during 2007-2012. Each participating unit obtains continuous online statistics from its own registrations and they can be compared with regional and national data. A report from SveDem is published yearly to inform medical and care professionals as well as political and administrative decision-makers about the current quality of diagnostics, treatment and care of patients with dementia disorders in Sweden.$\backslash$n$\backslash$nCONCLUSION: SveDem provides knowledge about current dementia care in Sweden and serves as a framework for ensuring the quality of diagnostics, treatment and care across the country. It also reflects changes in quality dementia care over time. Data from SveDem can be used to further develop the national guidelines for dementia and to generate new research hypotheses.},
author = {Religa, Dorota and Fereshtehnejad, Seyed-Mohammad and Cermakova, Pavla and Edlund, Ann-Katrin and Garcia-Ptacek, Sara and Granqvist, Nicklas and Hallb{\"{a}}ck, Anne and K{\aa}we, Kerstin and Farahmand, Bahman and Kilander, Lena and Mattsson, Ulla-Britt and N{\"{a}}gga, Katarina and Nordstr{\"{o}}m, Peter and Wijk, Helle and Wimo, Anders and Winblad, Bengt and Eriksdotter, Maria},
doi = {10.1371/journal.pone.0116538},
editor = {Quinn, Terence J},
file = {:Users/na399/Downloads/Research Papers/Religa et al.{\_}2015{\_}SveDem, the Swedish Dementia Registry – A Tool for Improving the Quality of Diagnostics, Treatment and Care of Deme.PDF:PDF},
isbn = {1932-6203},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {disease:dementia,rank:90,relevancy:C,topic:EHR,type:method},
mendeley-tags = {disease:dementia,rank:90,relevancy:C,topic:EHR,type:method},
month = {feb},
number = {2},
pages = {e0116538},
pmid = {25695768},
title = {{SveDem, the Swedish Dementia Registry – A Tool for Improving the Quality of Diagnostics, Treatment and Care of Dementia Patients in Clinical Practice}},
url = {http://dx.plos.org/10.1371/journal.pone.0116538},
volume = {10},
year = {2015}
}
@article{Singanamalli2017,
abstract = {{\textcopyright} 2017 The Author(s). The introduction of mild cognitive impairment (MCI) as a diagnostic category adds to the challenges of diagnosing Alzheimer's Disease (AD). No single marker has been proven to accurately categorize patients into their respective diagnostic groups. Thus, previous studies have attempted to develop fused predictors of AD and MCI. These studies have two main limitations. Most do not simultaneously consider all diagnostic categories and provide suboptimal fused representations using the same set of modalities for prediction of all classes. In this work, we present a combined framework, cascaded multiview canonical correlation (CaMCCo), for fusion and cascaded classification that incorporates all diagnostic categories and optimizes classification by selectively combining a subset of modalities at each level of the cascade. CaMCCo is evaluated on a data cohort comprising 149 patients for whom neurophysiological, neuroimaging, proteomic and genomic data were available. Results suggest that fusion of select modalities for each classification task outperforms (mean AUC = 0.92) fusion of all modalities (mean AUC = 0.54) and individual modalities (mean AUC = 0.90, 0.53, 0.71, 0.73, 0.62, 0.68). In addition, CaMCCo outperforms all other multi-class classification methods for MCI prediction (PPV: 0.80 vs. 0.67, 0.63).},
author = {Singanamalli, Asha and Wang, Haibo and Madabhushi, Anant and Weiner, Michael and Aisen, Paul and Petersen, Ronald and Jack, Clifford and Jagust, William and Trojanowki, John and Toga, Arthur and Beckett, Laurel and Green, Robert and Saykin, Andrew and Morris, John and Shaw, Leslie and Kaye, Jeffrey and Quinn, Joseph and Silbert, Lisa and Lind, Betty and Carter, Raina and Dolen, Sara and Schneider, Lon and Pawluczyk, Sonia and Beccera, Mauricio and Teodoro, Liberty and Spann, Bryan and Brewer, James and Vanderswag, Helen and Fleisher, Adam and Heidebrink, Judith and Lord, Joanne and Mason, Sara and Albers, Colleen and Knopman, David and Johnson, Kris and Doody, Rachelle and Villanueva-Meyer, Javier and Chowdhury, Munir and Rountree, Susan and Dang, Mimi and Stern, Yaakov and Honig, Lawrence and Bell, Karen and Ances, Beau and Carroll, Maria and Creech, Mary and Franklin, Erin and Mintun, Mark and Schneider, Stacy and Oliver, Angela and Marson, Daniel and Griffith, Randall and Clark, David and Geldmacher, David and Brockington, John and Roberson, Erik and {Natelson Love}, Marissa and Grossman, Hillel and Mitsis, Effie and Shah, Raj and Detoledo-Morrell, Leyla and Duara, Ranjan and Varon, Daniel and Greig, Maria and Roberts, Peggy and Albert, Marilyn and Onyike, Chiadi and D'Agostino, Daniel and Kielb, Stephanie and Galvin, James and Cerbone, Brittany and Michel, Christina and Pogorelec, Dana and Rusinek, Henry and {De Leon}, Mony and Glodzik, Lidia and {De Santi}, Susan and Doraiswamy, P. and Petrella, Jeffrey and Borges-Neto, Salvador and Wong, Terence and Coleman, Edward and Smith, Charles and Jicha, Greg and Hardy, Peter and Sinha, Partha and Oates, Elizabeth and Conrad, Gary and Porsteinsson, Anton and Goldstein, Bonnie and Martin, Kim and Makino, Kelly and Ismail, M. and Brand, Connie and Mulnard, Ruth and Thai, Gaby and Mc-Adams-Ortiz, Catherine and Womack, Kyle and Mathews, Dana and Quiceno, Mary and Levey, Allan and Lah, James and Cellar, Janet and Burns, Jeffrey and Swerdlow, Russell and Brooks, William and Apostolova, Liana and Tingus, Kathleen and Woo, Ellen and Silverman, Daniel and Lu, Po and Bartzokis, George and Graff-Radford, Neill and Parfitt, Francine and Kendall, Tracy and Johnson, Heather and Farlow, Martin and {Marie Hake}, Ann and Matthews, Brandy and Brosch, Jared and Herring, Scott and Hunt, Cynthia and Dyck, Christopher and Carson, Richard and MacAvoy, Martha and Varma, Pradeep and Chertkow, Howard and Bergman, Howard and Hosein, Chris and Black, Sandra and Stefanovic, Bojana and Caldwell, Curtis and {Robin Hsiung}, Ging Yuek and Feldman, Howard and Mudge, Benita and Assaly, Michele and Finger, Elizabeth and Pasternack, Stephen and Rachisky, Irina and Trost, Dick and Kertesz, Andrew and Bernick, Charles and Munic, Donna and Mesulam, Marek Marsel and Lipowski, Kristine and Weintraub, Sandra and Bonakdarpour, Borna and Kerwin, Diana and Wu, Chuang Kuo and Johnson, Nancy and Sadowsky, Carl and Villena, Teresa and {Scott Turner}, Raymond and Johnson, Kathleen and Reynolds, Brigid and Sperling, Reisa and Johnson, Keith and Marshall, Gad and Yesavage, Jerome and Taylor, Joy and Lane, Barton and Rosen, Allyson and Tinklenberg, Jared and Sabbagh, Marwan and Belden, Christine and Jacobson, Sandra and Sirrel, Sherye and Kowall, Neil and Killiany, Ronald and Budson, Andrew and Norbash, Alexander and {Lynn Johnson}, Patricia and Obisesan, Thomas and Wolday, Saba and Allard, Joanne and Lerner, Alan and Ogrocki, Paula and Tatsuoka, Curtis and Fatica, Parianne and Fletcher, Evan and Maillard, Pauline and Olichney, John and Decarli, Charles and Carmichael, Owen and Kittur, Smita and Borrie, Michael and Lee, T. Y. and Robbartha and Johnson, Sterling and Asthana, Sanjay and Carlsson, Cynthia and Potkin, Steven and Preda, Adrian and Nguyen, Dana and Tariot, Pierre and Burke, Anna and Trncic, Nadira and Reeder, Stephanie and Bates, Vernice and Capote, Horacio and Rainka, Michelle and Scharre, Douglas and Kataki, Maria and Adeli, Anahita and Zimmerman, Earl and Celmins, Dzintra and Brown, Alice and Pearlson, Godfrey and Blank, Karen and Anderson, Karen and Flashman, Laura and Seltzer, Marc and Hynes, Mary and Santulli, Robert and Sink, Kaycee and Gordineer, Leslie and Williamson, Jeff and Garg, Pradeep and Watkins, Franklin and Ott, Brian and Querfurth, Henry and Tremont, Geoffrey and Salloway, Stephen and Malloy, Paul and Correia, Stephen and Rosen, Howard and Miller, Bruce and Perry, David and Mintzer, Jacobo and Spicer, Kenneth and Bachman, David and Pomara, Nunzio and Hernando, Raymundo and Sarrael, Antero and Relkin, Norman and Chaing, Gloria and Lin, Michael and Ravdin, Lisa and Smith, Amanda and {Ashok Raj}, Balebail and Fargher, Kristin},
doi = {10.1038/s41598-017-03925-0},
file = {:Users/na399/GitHub/thesis/references/papers/Singanamalli et al.{\_}2017{\_}Cascaded Multi-view Canonical Correlation (CaMCCo) for Early Diagnosis of Alzheimer's Disease via Fusion of Cli.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
keywords = {disease:dementia,model:correlation,rank:95,relevancy:A,topic:diagnosis,type:research},
mendeley-tags = {disease:dementia,model:correlation,rank:95,relevancy:A,topic:diagnosis,type:research},
number = {1},
pages = {1--14},
title = {{Cascaded Multi-view Canonical Correlation (CaMCCo) for Early Diagnosis of Alzheimer's Disease via Fusion of Clinical, Imaging and Omic Features}},
volume = {7},
year = {2017}
}
@article{Ford2016,
abstract = {Background Electronic medical records (EMRs) are revolutionizing health-related research. One key issue for study quality is the accurate identifi-cation of patients with the condition of interest. Information in EMRs can be entered as structured codes or unstructured free text. The majority of research studies have used only coded parts of EMRs for case-detection, which may bias findings, miss cases, and reduce study quality. This re-view examines whether incorporating information from text into case-detection algorithms can improve research quality. Methods A systematic search returned 9659 papers, 67 of which reported on the extraction of information from free text of EMRs with the stated purpose of detecting cases of a named clinical condition. Methods for extracting information from text and the technical accuracy of case-detection algorithms were reviewed. Results Studies mainly used US hospital-based EMRs, and extracted information from text for 41 conditions using keyword searches, rule-based algorithms, and machine learning methods. There was no clear difference in case-detection algorithm accuracy between rule-based and machine learning methods of extraction. Inclusion of information from text resulted in a significant improvement in algorithm sensitivity and area under the receiver operating characteristic in comparison to codes alone (median sensitivity 78{\%} (codes þ text) vs 62{\%} (codes), P ¼ .03; median area under the receiver operating characteristic 95{\%} (codes þ text) vs 88{\%} (codes), P ¼ .025). Conclusions Text in EMRs is accessible, especially with open source information extraction algorithms, and significantly improves case detection when combined with codes. More harmonization of reporting within EMR studies is needed, particularly standardized reporting of algorithm accu-racy metrics like positive predictive value (precision) and sensitivity (recall).},
author = {Ford, Elizabeth and Carroll, John A. and Smith, Helen E. and Scott, Donia and Cassell, Jackie A.},
doi = {10.1093/jamia/ocv180},
file = {:Users/na399/GitHub/thesis/references/papers/Ford et al.{\_}2016{\_}Extracting information from the text of electronic medical records to improve case detection A systematic review{\_}Journa.pdf:pdf},
isbn = {1067-5027},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Case detection,Data quality,Electronic health records,Review,Text mining,model:NLP,rank:90,relevancy:B,topic:EHR,topic:diagnosis,type:review},
mendeley-tags = {model:NLP,rank:90,relevancy:B,topic:EHR,topic:diagnosis,type:review},
number = {5},
pages = {1007--1015},
pmid = {26911811},
title = {{Extracting information from the text of electronic medical records to improve case detection: A systematic review}},
volume = {23},
year = {2016}
}
@article{Casey2016,
abstract = {The use and functionality of electronic health records (EHRs) have increased rapidly in the past decade. Although the primary purpose of EHRs is clinical, researchers have used them to conduct epidemiologic investigations, ranging from cross-sectional studies within a given hospital to longitudinal studies on geographically distributed patients. Herein, we describe EHRs, examine their use in population health research, and compare them with traditional epidemiologic methods. We describe diverse research applications that benefit from the large sample sizes and generalizable patient populations afforded by EHRs. These have included reevaluation of prior findings, a range of diseases and subgroups, environmental and social epidemiology, stigmatized conditions, predictive modeling, and evaluation of natural experiments. Although studies using primary data collection methods may have more reliable data and better population retention, EHR-based studies are less expensive and require less time to complete. Fut...},
author = {Casey, Joan A. and Schwartz, Brian S. and Stewart, Walter F. and Adler, Nancy E.},
doi = {10.1146/annurev-publhealth-032315-021353},
file = {:Users/na399/GitHub/thesis/references/papers/Casey et al.{\_}2016{\_}Using Electronic Health Records for Population Health Research A Review of Methods and Applications{\_}Annual Review of P.pdf:pdf},
isbn = {1545-2093},
issn = {0163-7525},
journal = {Annual Review of Public Health},
keywords = {disease:general,ehr,electronic health records,environmental epidemiology,epidemiology,geographic information systems,health determinants,rank:99,relevancy:A,social,topic:EHR,type:review},
mendeley-tags = {disease:general,rank:99,relevancy:A,topic:EHR,type:review},
number = {1},
pages = {61--81},
pmid = {26667605},
title = {{Using Electronic Health Records for Population Health Research: A Review of Methods and Applications}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-publhealth-032315-021353},
volume = {37},
year = {2016}
}
@article{Pham2017,
abstract = {Personalized predictive medicine necessitates the modeling of patient illness and care processes, which inherently have long-term temporal dependencies. Healthcare observations, stored in electronic medical records are episodic and irregular in time. We introduce DeepCare, an end-to-end deep dynamic neural network that reads medical records, stores previous illness history, infers current illness states and predicts future medical outcomes. At the data level, DeepCare represents care episodes as vectors and models patient health state trajectories by the memory of historical records. Built on Long Short-Term Memory (LSTM), DeepCare introduces methods to handle irregularly timed events by moderating the forgetting and consolidation of memory. DeepCare also explicitly models medical interventions that change the course of illness and shape future medical risk. Moving up to the health state level, historical and present health states are then aggregated through multiscale temporal pooling, before passing through a neural network that estimates future outcomes. We demonstrate the efficacy of DeepCare for disease progression modeling, intervention recommendation, and future risk prediction. On two important cohorts with heavy social and economic burden – diabetes and mental health – the results show improved prediction accuracy.},
author = {Pham, Trang and Tran, Truyen and Phung, Dinh and Venkatesh, Svetha},
doi = {10.1016/j.jbi.2017.04.001},
file = {:Users/na399/GitHub/thesis/references/papers/Pham et al.{\_}2017{\_}Predicting healthcare trajectories from medical records A deep learning approach{\_}Journal of Biomedical Informatics.pdf:pdf},
isbn = {1532-0480 (Electronic) 1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Electronic medical records,Healthcare processes,Irregular timing,Long-Short Term Memory,Predictive medicine,disease:diabetes,disease:psychiatry,model:DeepLearning,rank:85,relevancy:A,topic:EHR,topic:prediction,topic:trajectory,type:research},
mendeley-tags = {rank:85,type:research,relevancy:A,topic:trajectory,topic:prediction,disease:diabetes,disease:psychiatry,model:DeepLearning,topic:EHR},
pages = {218--229},
pmid = {28410981},
publisher = {Elsevier Inc.},
title = {{Predicting healthcare trajectories from medical records: A deep learning approach}},
url = {http://dx.doi.org/10.1016/j.jbi.2017.04.001},
volume = {69},
year = {2017}
}
@article{Roque2011,
abstract = {Electronic patient records remain a rather unexplored, but potentially rich data source for discovering correlations between diseases. We describe a general approach for gathering phenotypic descriptions of patients from medical records in a systematic and non-cohort dependent manner. By extracting phenotype information from the free-text in such records we demonstrate that we can extend the information contained in the structured record data, and use it for producing fine-grained patient stratification and disease co-occurrence statistics. The approach uses a dictionary based on the International Classification of Disease ontology and is therefore in principle language independent. As a use case we show how records from a Danish psychiatric hospital lead to the identification of disease correlations, which subsequently can be mapped to systems biology frameworks.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Roque, Francisco S. and Jensen, Peter B. and Schmock, Henriette and Dalgaard, Marlene and Andreatta, Massimo and Hansen, Thomas and S{\o}eby, Karen and Bredkj{\ae}r, S{\o}ren and Juul, Anders and Werge, Thomas and Jensen, Lars J. and Brunak, S{\o}ren},
doi = {10.1371/journal.pcbi.1002141},
editor = {Ritchie, Marylyn D.},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/Roque et al.{\_}2011{\_}Using electronic patient records to discover disease correlations and stratify patient cohorts{\_}PLoS Computational Biol.PDF:PDF},
isbn = {1553-734x},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {disease:psychiatry,model:network,rank:99,relevancy:A,topic:EHR,topic:comorbidity,type:research},
mendeley-tags = {disease:psychiatry,model:network,rank:99,relevancy:A,topic:EHR,topic:comorbidity,type:research},
month = {aug},
number = {8},
pages = {e1002141},
pmid = {21901084},
title = {{Using Electronic Patient Records to Discover Disease Correlations and Stratify Patient Cohorts}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1002141},
volume = {7},
year = {2011}
}
@article{Anderson2016a,
abstract = {Objectives: An estimated 25{\%} of type two diabetes mellitus (DM2) patients in the United States are undiagnosed due to inadequate screening, because it is prohibitive to administer laboratory tests to everyone. We assess whether electronic health record (EHR) phenotyping could improve DM2 screening compared to conventional models, even when records are incomplete and not recorded systematically across patients and practice locations, as is typically seen in practice. Methods: In this cross-sectional, retrospective study, EHR data from 9948 US patients were used to develop a pre-screening tool to predict current DM2, using multivariate logistic regression and a random-forests probabilistic model for out-of-sample validation. We compared (1) a full EHR model containing commonly prescribed medications, diagnoses (as ICD9 categories), and conventional predictors, (2) a restricted EHR DX model which excluded medications, and (3) a conventional model containing basic predictors and their interactions (BMI, age, sex, smoking status, hypertension). Results: Using a patient's full EHR or restricted EHR was superior to using basic covariates alone for detecting individuals with diabetes (hierarchical X2 test, p {\textless} 0.001). Migraines, depot medroxyprogesterone acetate, and cardiac dysrhythmias were associated negatively with DM2, while sexual and gender identity disorder diagnosis, viral and chlamydial infections, and herpes zoster were associated positively. Adding EHR phenotypes improved classification; the AUC for the full EHR Model, EHR DX model, and conventional model using logistic regression, were 84.9{\%}, 83.2{\%}, and 75.0{\%} respectively. For random forest machine learning out-of-sample prediction, accuracy also was improved when using EHR phenotypes; the AUC values were 81.3{\%}, 79.6{\%}, and 74.8{\%}, respectively. Improved AUCs reflect better performance for most thresholds that balance sensitivity and specificity. Conclusions: EHR phenotyping resulted in markedly superior detection of DM2, even in the face of missing and unsystematically recorded data, based on the ROC curves. EHR phenotypes could more efficiently identify which patients do require, and don't require, further laboratory screening. When applied to the current number of undiagnosed individuals in the United States, we predict that incorporating EHR phenotype screening would identify an additional 400,000 patients with active, untreated diabetes compared to the conventional pre-screening models.},
archivePrefix = {arXiv},
arxivId = {1501.02402},
author = {Anderson, Ariana E. and Kerr, Wesley T. and Thames, April and Li, Tong and Xiao, Jiayang and Cohen, Mark S.},
doi = {10.1016/j.jbi.2015.12.006},
eprint = {1501.02402},
file = {:Users/na399/GitHub/thesis/references/papers/Anderson et al.{\_}2016{\_}Electronic health record phenotyping improves detection and screening of type 2 diabetes in the general United Stat.pdf:pdf},
isbn = {1532-0464},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Electronic health records,Evidence-based medicine,Phenotype,Population screening,Type 2 diabetes,disease:diabetes,rank:85,relevancy:A,topic:EHR,topic:diagnosis,topic:phenotyping,type:research},
mendeley-tags = {rank:85,type:research,disease:diabetes,relevancy:A,topic:EHR,topic:phenotyping,topic:diagnosis},
pages = {162--168},
pmid = {26707455},
publisher = {Elsevier Inc.},
title = {{Electronic health record phenotyping improves detection and screening of type 2 diabetes in the general United States population: A cross-sectional, unselected, retrospective study}},
url = {http://dx.doi.org/10.1016/j.jbi.2015.12.006},
volume = {60},
year = {2016}
}
@article{Shen2014a,
abstract = {The Genetics Core of the Alzheimer's Disease Neuroimaging Initiative (ADNI), formally established in 2009, aims to provide resources and facilitate research related to genetic predictors of multidimensional Alzheimer's disease (AD)-related phenotypes. Here, we provide a systematic review of genetic studies published between 2009 and 2012 where either ADNI APOE genotype or genome-wide association study (GWAS) data were used. We review and synthesize ADNI genetic associations with disease status or quantitative disease endophenotypes including structural and functional neuroimaging, fluid biomarker assays, and cognitive performance. We also discuss the diverse analytical strategies used in these studies, including univariate and multivariate analysis, meta-analysis, pathway analysis, and interaction and network analysis. Finally, we perform pathway and network enrichment analyses of these ADNI genetic associations to highlight key mechanisms that may drive disease onset and trajectory. Major ADNI findings included all the top 10 AD genes and several of these (e.g., APOE, BIN1, CLU, CR1, and PICALM) were corroborated by ADNI imaging, fluid and cognitive phenotypes. ADNI imaging genetics studies discovered novel findings (e.g., FRMD6) that were later replicated on different data sets. Several other genes (e.g., APOC1, FTO, GRIN2B, MAGI2, and TOMM40) were associated with multiple ADNI phenotypes, warranting further investigation on other data sets. The broad availability and wide scope of ADNI genetic and phenotypic data has advanced our understanding of the genetic basis of AD and has nominated novel targets for future studies employing next-generation sequencing and convergent multi-omics approaches, and for clinical drug and biomarker development.},
author = {Shen, Li and Thompson, Paul M. and Potkin, Steven G. and Bertram, Lars and Farrer, Lindsay A. and Foroud, Tatiana M. and Green, Robert C. and Hu, Xiaolan and Huentelman, Matthew J. and Kim, Sungeun and Kauwe, John S.K. and Li, Qingqin and Liu, Enchi and Macciardi, Fabio and Moore, Jason H. and Munsie, Leanne and Nho, Kwangsik and Ramanan, Vijay K. and Risacher, Shannon L. and Stone, David J. and Swaminathan, Shanker and Toga, Arthur W. and Weiner, Michael W. and Saykin, Andrew J.},
doi = {10.1007/s11682-013-9262-z},
file = {:Users/na399/GitHub/thesis/references/papers/Shen et al.{\_}2014{\_}Genetic analysis of quantitative phenotypes in AD and MCI Imaging, cognition and biomarkers{\_}Brain Imaging and Behavior.pdf:pdf},
isbn = {1931-7565 (Electronic)$\backslash$r1931-7557 (Linking)},
issn = {19317565},
journal = {Brain Imaging and Behavior},
keywords = {Alzheimer's disease,Biomarker,Cognition,Genetic association study,Neuroimaging,Quantitative traits,disease:dementia,rank:90,relevancy:C,topic:GWAS,topic:bioinformatics,type:research},
mendeley-tags = {disease:dementia,rank:90,relevancy:C,topic:GWAS,topic:bioinformatics,type:research},
number = {2},
pages = {183--207},
pmid = {24092460},
title = {{Genetic analysis of quantitative phenotypes in AD and MCI: Imaging, cognition and biomarkers}},
volume = {8},
year = {2014}
}
@article{Iliffe2011,
abstract = {To describe the development of a dementia research registry, outlining the conceptual, practical and ethical challenges, and to report initial experiences of recruiting people with dementia to it from primary and secondary care.},
author = {Iliffe, Steve and Curry, Lisa and Kharicha, Kalpa and Rait, Greta and Wilcock, Jane and Lowery, David and Tapuria, Archana and Kalra, Dipak and Ritchie, Craig},
doi = {10.1186/1471-2288-11-9},
file = {:Users/na399/Downloads/Research Papers/Iliffe et al.{\_}2011{\_}Developing a dementia research registry A descriptive case study from North Thames DeNDRoN and the EVIDEM programme{\_}B.pdf:pdf},
isbn = {1471-2288 (Electronic)$\backslash$n1471-2288 (Linking)},
issn = {14712288},
journal = {BMC Medical Research Methodology},
keywords = {disease:dementia,rank:90,relevancy:D,topic:registry,type:commentary},
mendeley-tags = {disease:dementia,rank:90,relevancy:D,topic:registry,type:commentary},
pmid = {21272296},
title = {{Developing a dementia research registry: A descriptive case study from North Thames DeNDRoN and the EVIDEM programme}},
volume = {11},
year = {2011}
}
@article{Cespedes2017,
abstract = {OBJECTIVES In recent years, large-scale longitudinal neuroimaging studies have improved our understanding of healthy ageing and pathologies including Alzheimer's disease (AD). A particular focus of these studies is group differences and identification of participants at risk of deteriorating to a worse diagnosis. For this, statistical analysis using linear mixed-effects (LME) models are used to account for correlated observations from individuals measured over time. A Bayesian framework for LME models in AD is introduced in this paper to provide additional insight often not found in current LME volumetric analyses. SETTING AND PARTICIPANTS Longitudinal neuroimaging case study of ageing was analysed in this research on 260 participants diagnosed as either healthy controls (HC), mild cognitive impaired (MCI) or AD. Bayesian LME models for the ventricle and hippocampus regions were used to: (1) estimate how the volumes of these regions change over time by diagnosis, (2) identify high-risk non-AD individuals with AD like degeneration and (3) determine probabilistic trajectories of diagnosis groups over age. RESULTS We observed (1) large differences in the average rate of change of volume for the ventricle and hippocampus regions between diagnosis groups, (2) high-risk individuals who had progressed from HC to MCI and displayed similar rates of deterioration as AD counterparts, and (3) critical time points which indicate where deterioration of regions begins to diverge between the diagnosis groups. CONCLUSIONS To the best of our knowledge, this is the first application of Bayesian LME models to neuroimaging data which provides inference on a population and individual level in the AD field. The application of a Bayesian LME framework allows for additional information to be extracted from longitudinal studies. This provides health professionals with valuable information of neurodegeneration stages, and a potential to provide a better understanding of disease pathology.},
author = {Cespedes, Marcela I. and Fripp, Jurgen and McGree, James M. and Drovandi, Christopher C. and Mengersen, Kerrie and Doecke, James D.},
doi = {10.1136/bmjopen-2016-012174},
file = {:Users/na399/GitHub/thesis/references/papers/Cespedes et al.{\_}2017{\_}Comparisons of neurodegeneration over time between healthy ageing and Alzheimer's disease cohorts via Bayesian infe.pdf:pdf},
issn = {20446055},
journal = {BMJ Open},
keywords = {disease:dementia,model:Bayesian,rank:90,relevancy:A,topic:progression,type:research},
mendeley-tags = {disease:dementia,model:Bayesian,rank:90,relevancy:A,topic:progression,type:research},
number = {2},
pages = {1--16},
pmid = {28174220},
title = {{Comparisons of neurodegeneration over time between healthy ageing and Alzheimer's disease cohorts via Bayesian inference}},
volume = {7},
year = {2017}
}
@article{Razavian2015,
abstract = {Early diagnosis of treatable diseases is essential for improving healthcare, and many diseases' onsets are predictable from annual lab tests and their temporal trends. We introduce a multi-resolution convolutional neural network for early detection of multiple diseases from irregularly measured sparse lab values. Our novel architecture takes as input both an imputed version of the data and a binary observation matrix. For imputing the temporal sparse observations, we develop a flexible, fast to train method for differentiable multivariate kernel regression. Our experiments on data from 298K individuals over 8 years, 18 common lab measurements, and 171 diseases show that the temporal signatures learned via convolution are significantly more predictive than baselines commonly used for early disease diagnosis.},
archivePrefix = {arXiv},
arxivId = {1511.07938},
author = {Razavian, Narges and Sontag, David},
eprint = {1511.07938},
file = {:Users/na399/GitHub/thesis/references/papers/Razavian, Sontag{\_}2015{\_}Temporal Convolutional Neural Networks for Diagnosis from Lab Tests{\_}Unknown.pdf:pdf},
isbn = {9781611970685},
issn = {0004-6361},
keywords = {rank:n/a,relevancy:D},
mendeley-tags = {rank:n/a,relevancy:D},
month = {nov},
pmid = {23459267},
title = {{Temporal Convolutional Neural Networks for Diagnosis from Lab Tests}},
url = {http://arxiv.org/abs/1511.07938 http://www.aanda.org/10.1051/0004-6361/201527329},
year = {2015}
}
@article{Xu2015e,
abstract = {Objective To review and evaluate available software tools for electronic health record–driven phenotype authoring in order to identify gaps and needs for future development.Materials and Methods Candidate phenotype authoring tools were identified through (1) literature search in four publication databases (PubMed, Embase, Web of Science, and Scopus) and (2) a web search. A collection of tools was compiled and reviewed after the searches. A survey was designed and distributed to the developers of the reviewed tools to discover their functionalities and features.Results Twenty-four different phenotype authoring tools were identified and reviewed. Developers of 16 of these identified tools completed the evaluation survey (67{\%} response rate). The surveyed tools showed commonalities but also varied in their capabilities in algorithm representation, logic functions, data support and software extensibility, search functions, user interface, and data outputs.Discussion Positive trends identified in the evaluation included: algorithms can be represented in both computable and human readable formats; and most tools offer a web interface for easy access. However, issues were also identified: many tools were lacking advanced logic functions for authoring complex algorithms; the ability to construct queries that leveraged un-structured data was not widely implemented; and many tools had limited support for plug-ins or external analytic software.Conclusions Existing phenotype authoring tools could enable clinical researchers to work with electronic health record data more efficiently, but gaps still exist in terms of the functionalities of such tools. The present work can serve as a reference point for the future development of similar tools.},
author = {Xu, Jie and Rasmussen, Luke V. and Shaw, Pamela L. and Jiang, Guoqian and Kiefer, Richard C. and Mo, Huan and Pacheco, Jennifer A. and Speltz, Peter and Zhu, Qian and Denny, Joshua C. and Pathak, Jyotishman and Thompson, William K. and Montague, Enid},
doi = {10.1093/jamia/ocv070},
file = {:Users/na399/GitHub/thesis/references/papers/Xu et al.{\_}2015{\_}Review and evaluation of electronic health records-driven phenotype algorithm authoring tools for clinical and translatio.pdf:pdf},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Clinical research,Electronic health records,Phenotype algorithm authoring tool,Phenotyping,Review,rank:90,relevancy:B,topic:EHR,topic:phenotyping,topic:platform,type:review},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,topic:phenotyping,topic:platform,type:review},
number = {6},
pages = {1251--1260},
pmid = {26224336},
title = {{Review and evaluation of electronic health records-driven phenotype algorithm authoring tools for clinical and translational research}},
volume = {22},
year = {2015}
}
@article{Ghosh2017,
abstract = {Background and objective Critical care patient events like sepsis or septic shock in intensive care units (ICUs) are dangerous complications which can cause multiple organ failures and eventual death. Preventive prediction of such events will allow clinicians to stage effective interventions for averting these critical complications. Methods It is widely understood that physiological conditions of patients on variables such as blood pressure and heart rate are suggestive to gradual changes over a certain period of time, prior to the occurrence of a septic shock. This work investigates the performance of a novel machine learning approach for the early prediction of septic shock. The approach combines highly informative sequential patterns extracted from multiple physiological variables and captures the interactions among these patterns via coupled hidden Markov models (CHMM). In particular, the patterns are extracted from three non-invasive waveform measurements: the mean arterial pressure levels, the heart rates and respiratory rates of septic shock patients from a large clinical ICU dataset called MIMIC-II. Evaluation and results For baseline estimations, SVM and HMM models on the continuous time series data for the given patients, using MAP (mean arterial pressure), HR (heart rate), and RR (respiratory rate) are employed. Single channel patterns based HMM (SCP-HMM) and multi-channel patterns based coupled HMM (MCP-HMM) are compared against baseline models using 5-fold cross validation accuracies over multiple rounds. Particularly, the results of MCP-HMM are statistically significant having a p-value of 0.0014, in comparison to baseline models. Our experiments demonstrate a strong competitive accuracy in the prediction of septic shock, especially when the interactions between the multiple variables are coupled by the learning model. Conclusions It can be concluded that the novelty of the approach, stems from the integration of sequence-based physiological pattern markers with the sequential CHMM model to learn dynamic physiological behavior, as well as from the coupling of such patterns to build powerful risk stratification models for septic shock patients.},
author = {Ghosh, Shameek and Li, Jinyan and Cao, Longbing and Ramamohanarao, Kotagiri},
doi = {10.1016/j.jbi.2016.12.010},
file = {:Users/na399/GitHub/thesis/references/papers/Ghosh et al.{\_}2017{\_}Septic shock prediction for ICU patients via coupled HMM walking on sequential contrast patterns{\_}Journal of Biomedical.pdf:pdf},
isbn = {1532-0480 (Electronic) 1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Coupled hidden Markov models,Septic shock,Sequential pattern mining,Symbolic sequences,disease:sepsis,model:Markov,model:SVM,rank:85,relevancy:A,topic:EHR,type:research},
mendeley-tags = {rank:85,type:research,relevancy:A,model:Markov,model:SVM,topic:EHR,disease:sepsis},
pages = {19--31},
pmid = {28011233},
title = {{Septic shock prediction for ICU patients via coupled HMM walking on sequential contrast patterns}},
url = {http://dx.doi.org/10.1016/j.jbi.2016.12.010},
volume = {66},
year = {2017}
}
@article{Jones2016,
abstract = {The potential decline of dementia, seen in light of the rise and fall of other major diseases, raises a tantalizing prospect: Can we control our burden of disease? The history of the debate on CAD decline carries important lessons for emerging reports of dementia's decline.},
author = {Jones, David S and Greene, Jeremy A},
doi = {10.1056/NEJMp1514434},
file = {:Users/na399/Downloads/Research Papers/Jones, Greene{\_}2016{\_}Is Dementia in Decline Historical Trends and Future Trajectories{\_}New England Journal of Medicine.pdf:pdf},
isbn = {1533-4406 (Electronic)$\backslash$r0028-4793 (Linking)},
issn = {0028-4793},
journal = {New England Journal of Medicine},
keywords = {disease:dementia,rank:99,relevancy:B,topic:impact,type:commentary},
mendeley-tags = {rank:99},
number = {6},
pages = {507--509},
pmid = {26863352},
title = {{Is Dementia in Decline? Historical Trends and Future Trajectories}},
url = {http://www.nejm.org/doi/10.1056/NEJMp1514434},
volume = {374},
year = {2016}
}
@article{Billis2015,
abstract = {Artificial intelligence and decision support systems offer a plethora of health monitoring capabilities in ambient assisted living environment. Continuous assessment of health indicators for elderly people living on their own is of utmost importance, so as to prolong their independence and quality of life. Slow varying, long-term deteriorating health trends are not easily identifiable in seniors. Thus, early sign detection of a specific condition, as well as, any likely transition from a healthy state to a pathological one are key problems that the herein proposed framework aims at resolving. Statistical process control concepts offer a personalized approach toward identification of trends that are away from the atypical behavior or state of the seniors, while fuzzy cognitive maps knowledge representation and inference schema have proved to be efficient in terms of disease classification. Geriatric depression is used as a case study throughout the paper, so to prove the validity of the framework, which is planned to be pilot tested with a series of lone-living seniors in their own homes.},
author = {Billis, Antonis S. and Papageorgiou, Elpiniki I. and Frantzidis, Christos A. and Tsatali, Marianna S. and Tsolaki, Anthoula C. and Bamidis, Panagiotis D.},
doi = {10.1109/JBHI.2014.2336757},
file = {:Users/na399/GitHub/thesis/references/papers/Billis et al.{\_}2015{\_}A decision-support framework for promoting independent living and ageing well{\_}IEEE Journal of Biomedical and Health I.pdf:pdf},
isbn = {2168-2194 VO - 19},
issn = {21682194},
journal = {IEEE Journal of Biomedical and Health Informatics},
keywords = {Data-driven Hebbian learning (DD-NHL),decision support systems (DSSs),disease:psychiatry,fuzzy cognitive maps (FCMs),personalized health,rank:90,relevancy:B,statistical process control,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:psychiatry,rank:90,relevancy:B,topic:EHR,topic:prediction,type:research},
number = {1},
pages = {199--209},
pmid = {25073180},
title = {{A decision-support framework for promoting independent living and ageing well}},
volume = {19},
year = {2015}
}
@article{Wu2010,
abstract = {Background: Electronic health record (EHR) databases contain vast amounts of information about patients. Machine learning techniques such as Boosting and support vector machine (SVM) can potentially identify patients at high risk for serious conditions, such as heart disease, from EHR data. However, these techniques have not yet been widely tested. Objective: To model detection of heart failure more than 6 months before the actual date of clinical diagnosis using machine learning techniques applied to EHR data. To compare the performance of logistic regression, SVM, and Boosting, along with various variable selection methods in heart failure prediction. Research Design: Geisinger Clinic primary care patients with data in the EHR data from 2001 to 2006 diagnosed with heart failure between 2003 and 2006 were identified. Controls were randomly selected matched on sex, age, and clinic for this nested case-control study. Measures: Area under the curve (AUC) of receiver operator char- acteristic curve was computed for each method using 10-fold cross- validation. The number of variables selected by each method was compared. Results: Logistic regression with model selection based on Bayes- ian information criterion provided the most parsimonious model, with about 10 variables selected on average, while maintaining a high AUC (0.77 in 10-fold cross-validation). Boosting with strict variable importance threshold provided similar performance. Conclusions: Heart failure was predicted more than 6 months before clinical diagnosis, with AUC of about 0.76, using logistic regression and Boosting. These results were achieved even with strict model selection criteria. SVM had the poorest performance, possibly because of imbalanced data.},
author = {Wu, Jionglin and Roy, Jason and Stewart, Walter F.},
doi = {10.1097/MLR.0b013e3181de9e17},
file = {:Users/na399/GitHub/thesis/references/papers/Wu, Roy, Stewart{\_}2010{\_}Prediction Modeling Using EHR Data{\_}Medical Care.pdf:pdf},
isbn = {1537-1948 (Electronic)$\backslash$r0025-7079 (Linking)},
issn = {0025-7079},
journal = {Medical Care},
keywords = {48,comparative effectiveness,disease:CVD,electronic health record,machine learning,med care 2010,model:SVM,model:logisticRegression,prediction model,rank:90,relevancy:A,s106,s113,topic:EHR,topic:prediction,type:research,variable selection},
mendeley-tags = {disease:CVD,model:SVM,model:logisticRegression,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
number = {6},
pages = {S106--S113},
pmid = {20473190},
title = {{Prediction Modeling Using EHR Data}},
url = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage{\&}an=00005650-201006001-00017},
volume = {48},
year = {2010}
}
@article{Dumitrescu2015,
abstract = {BACKGROUND: Biorepositories linked to de-identified electronic medical records (EMRs) have the potential to complement traditional epidemiologic studies in genotype-phenotype studies of complex human diseases and traits. A major challenge in meeting this potential is the use of EMR-derived data to extract phenotypes and covariates for genetic association studies. Unlike traditional epidemiologic data, EMR-derived data are collected for clinical care and are therefore highly variable across patients. The variability of clinical data coupled with the challenges associated with searching unstructured clinical notes requires the development of algorithms to extract phenotypes for analysis. Given the number of possible algorithms that could be developed for any one EMR-derived phenotype, we explored here the impact algorithm decision logic has on genetic association study results for a single quantitative trait, high density lipoprotein cholesterol (HDL-C).$\backslash$n$\backslash$nRESULTS: We used five different algorithms to extract HDL-C from African American subjects genotyped on the Illumina Metabochip (n = 11,519) as part of Epidemiologic Architecture for Genes Linked to Environment (EAGLE). Tests of association between HDL-C and genetic risk scores for HDL-C associated variants suggest that the genetic effect size does not vary substantially across the five HDL-C definitions.$\backslash$n$\backslash$nCONCLUSIONS: These data collectively suggest that, at least for this quantitative trait, algorithm decision logic and phenotyping details do not appreciably impact genetic association study test statistics.},
author = {Dumitrescu, Logan and Goodloe, Robert and Bradford, Yukiko and Farber-Eger, Eric and Boston, Jonathan and Crawford, Dana C.},
doi = {10.1186/s13040-015-0048-2},
file = {:Users/na399/GitHub/thesis/references/papers/Dumitrescu et al.{\_}2015{\_}The effects of electronic medical record phenotyping details on genetic association studies HDL-C as a case study.pdf:pdf},
issn = {17560381},
journal = {BioData Mining},
keywords = {Electronic medical record,Genetic risk score,HDL-C,PAGE I study,eMERGE network,rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
number = {1},
pages = {1--8},
pmid = {25969697},
publisher = {???},
title = {{The effects of electronic medical record phenotyping details on genetic association studies: HDL-C as a case study}},
url = {???},
volume = {8},
year = {2015}
}
@article{Liu2014,
abstract = {The DiseaseConnect (http://disease-connect.org) is a web server for analysis and visualization of a comprehensive knowledge on mechanism-based disease connectivity. The traditional disease classification system groups diseases with similar clinical symptoms and phenotypic traits. Thus, diseases with entirely different pathologies could be grouped together, leading to a similar treatment design. Such problems could be avoided if diseases were classified based on their molecular mechanisms. Connecting diseases with similar pathological mechanisms could inspire novel strategies on the effective repositioning of existing drugs and therapies. Although there have been several studies attempting to generate disease connectivity networks, they have not yet utilized the enormous and rapidly growing public repositories of disease-related omics data and literature, two primary resources capable of providing insights into disease connections at an unprecedented level of detail. Our DiseaseConnect, the first public web server, integrates comprehensive omics and literature data, including a large amount of gene expression data, Genome-Wide Association Studies catalog, and text-mined knowledge, to discover disease-disease connectivity via common molecular mechanisms. Moreover, the clinical comorbidity data and a comprehensive compilation of known drug-disease relationships are additionally utilized for advancing the understanding of the disease landscape and for facilitating the mechanism-based development of new drug treatments.},
author = {Liu, Chun Chi and Tseng, Yu Ting and Li, Wenyuan and Wu, Chia Yu and Mayzus, Ilya and Rzhetsky, Andrey and Sun, Fengzhu and Waterman, Michael and Chen, Jeremy J.W. and Chaudhary, Preet M. and Loscalzo, Joseph and Crandall, Edward and Zhou, Xianghong Jasmine},
doi = {10.1093/nar/gku412},
file = {:Users/na399/GitHub/thesis/references/papers/Liu et al.{\_}2014{\_}DiseaseConnect A comprehensive web server for mechanism-based disease-disease connections{\_}Nucleic Acids Research.pdf:pdf},
isbn = {1362-4962 (Electronic)},
issn = {13624962},
journal = {Nucleic Acids Research},
keywords = {disease:general,model:network,rank:99,relevancy:C,topic:comorbidity,topic:platform,type:research},
mendeley-tags = {disease:general,model:network,rank:99,relevancy:C,topic:comorbidity,topic:platform,type:research},
number = {W1},
pages = {1--10},
pmid = {24895436},
title = {{DiseaseConnect: A comprehensive web server for mechanism-based disease-disease connections}},
volume = {42},
year = {2014}
}
@article{Jackson2003,
abstract = {Many chronic diseases have a natural interpretation in terms of staged progression. Multistate models based on Markov processes are a well-established method of estimating rates of transition between stages of disease. However, diagnoses of disease stages are some-times subject to error. The paper presents a general hidden Markov model for simultaneously estimating transition rates and probabilities of stage misclassification. Covariates can be fitted to both the transition rates and the misclassification probabilities. For example, in the study of abdominal aortic aneurysms by ultrasonography, the disease is staged by severity, according to successive ranges of aortic diameter. The model is illustrated on data from a trial of aortic aneurysm screening, in which the screening measurements are subject to error. General pur-pose software for model implementation has been developed in the form of an R package and is made freely available.},
author = {Jackson, Christopher H and Sharples, Linda D and Thompson, Simon G and Duffy, Stephen W and Couto, Elisabeth},
doi = {10.1111/1467-9884.00351},
file = {:Users/na399/GitHub/thesis/references/papers/Jackson et al.{\_}2003{\_}Multistate Markov models for disease progression with classification error{\_}The Statistician.pdf:pdf},
isbn = {1467-9884},
issn = {00390526},
journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
keywords = {Abdominal aortic aneurysm,Disease progression,Hidden Markov models,Multistate models,rank:80,relevancy:A},
mendeley-tags = {rank:80,relevancy:A},
month = {jul},
number = {2},
pages = {193--209},
title = {{Multistate Markov models for disease progression with classification error}},
url = {http://doi.wiley.com/10.1111/1467-9884.00351},
volume = {52},
year = {2003}
}
@article{Ruiz2014,
abstract = {The analysis of comorbidity is an open and complex research Field in the branch of psychiatry, where clinical experience and several studies suggest that the relation among the psychiatric disorders may have etiological and treatment implications. In this paper, we are interested in applying latent feature modeling to Find the latent structure behind the psychiatric disorders that can help to examine and explain the relationships among them. To this end, we use the large amount of information collected in the National Epidemiologic Survey on Alcohol and Related Conditions (NESARC) database and propose to model these data using a nonparametric latent model based on the Indian BuFiet Process (IBP). Due to the discrete nature of the data, we First need to adapt the observation model for discrete random variables. We propose a generative model in which the observations are drawn from a multinomial-logit distribution given the IBP matrix. The implementation of an eFicient Gibbs sampler is accomplished using the Laplace approximation, which allows integrating out the weighting factors of the multinomial-logit likelihood model. We also provide a variational inference algorithm for this model, which provides a complementary (and less expensive in terms of computational complexity) alternative to the Gibbs sampler allowing us to deal with a larger number of data. Finally, we use the model to analyze comorbidity among the psychiatric disorders diagnosed by experts from the NESARC database. {\textcopyright} 2014 Francisco J. R. Ruiz, Isabel Valera, Carlos Blanco and Fernando Perez-Cruz.},
archivePrefix = {arXiv},
arxivId = {1401.7620},
author = {Ruiz, Francisco J. R. and Valera, Isabel and Blanco, Carlos and Perez-Cruz, Fernando},
eprint = {1401.7620},
file = {:Users/na399/GitHub/thesis/references/papers/Ruiz et al.{\_}2014{\_}Bayesian nonparametric comorbidity analysis of psychiatric disorders{\_}Journal of Machine Learning Research.pdf:pdf},
isbn = {1532-4435},
issn = {15337928},
journal = {Journal of Machine Learning Research},
keywords = {Bayesian nonparametrics,Categorical observations,Indian buffet process,Laplace approximation,Multinomial-logit function,Variational inference,disease:psychiatry,model:Bayesian,rank:95,relevancy:A,topic:comorbidity,type:research},
mendeley-tags = {disease:psychiatry,model:Bayesian,rank:95,relevancy:A,topic:comorbidity,type:research},
pages = {1215--1247},
title = {{Bayesian nonparametric comorbidity analysis of psychiatric disorders}},
url = {http://arxiv.org/abs/1401.7620{\%}5Cnhttp://www.arxiv.org/pdf/1401.7620.pdf{\%}5Cnhttp://www.scopus.com/inward/record.url?eid=2-s2.0-84901596842{\&}partnerID=tZOtx3y1},
volume = {15},
year = {2014}
}
@article{Amra2017a,
abstract = {Purpose Long-term cognitive impairment is a common and important problem in survivors of critical illness. We developed electronic search algorithms to identify cognitive impairment and dementia from the electronic medical records (EMRs) that provide opportunity for big data analysis. Materials and methods Eligible patients met 2 criteria. First, they had a formal cognitive evaluation by The Mayo Clinic Study of Aging. Second, they were hospitalized in intensive care unit at our institution between 2006 and 2014. The “criterion standard” for diagnosis was formal cognitive evaluation supplemented by input from an expert neurologist. Using all available EMR data, we developed and improved our algorithms in the derivation cohort and validated them in the independent validation cohort. Results Of 993 participants who underwent formal cognitive testing and were hospitalized in intensive care unit, we selected 151 participants at random to form the derivation and validation cohorts. The automated electronic search algorithm for cognitive impairment was 94.3{\%} sensitive and 93.0{\%} specific. The search algorithms for dementia achieved respective sensitivity and specificity of 97{\%} and 99{\%}. EMR search algorithms significantly outperformed International Classification of Diseases codes. Conclusions Automated EMR data extractions for cognitive impairment and dementia are reliable and accurate and can serve as acceptable and efficient alternatives to time-consuming manual data review.},
author = {Amra, Sakusic and O'Horo, John C. and Singh, Tarun D. and Wilson, Gregory A. and Kashyap, Rahul and Petersen, Ronald and Roberts, Rosebud O. and Fryer, John D. and Rabinstein, Alejandro A. and Gajic, Ognjen},
doi = {10.1016/j.jcrc.2016.09.026},
file = {:Users/na399/GitHub/thesis/references/papers/Amra et al.{\_}2017{\_}Derivation and validation of the automated search algorithms to identify cognitive impairment and dementia in electr(2).pdf:pdf},
issn = {15578615},
journal = {Journal of Critical Care},
keywords = {Cognitive decline,Cognitive impairment,Critical illness,Dementia,Electronic medical records,Electronic search strategy,disease:dementia,rank:80,relevancy:A},
mendeley-tags = {rank:80,relevancy:A,disease:dementia},
number = {2017},
pages = {202--205},
pmid = {27969571},
publisher = {Elsevier Inc.},
title = {{Derivation and validation of the automated search algorithms to identify cognitive impairment and dementia in electronic health records}},
url = {http://dx.doi.org/10.1016/j.jcrc.2016.09.026},
volume = {37},
year = {2017}
}
@article{Cai2016a,
abstract = {Objective To develop a predictive model for real-time predictions of length of stay, mortality, and readmission for hospitalized patients using elec-tronic health records (EHRs). Materials and Methods A Bayesian Network model was built to estimate the probability of a hospitalized patient being " at home, " in the hospital, or dead for each of the next 7 days. The network utilizes patient-specific administrative and laboratory data and is updated each time a new pa-thology test result becomes available. Electronic health records from 32 634 patients admitted to a Sydney metropolitan hospital via the emergency department from July 2008 through December 2011 were used. The model was tested on 2011 data and trained on the data of earlier years. Results The model achieved an average daily accuracy of 80{\%} and area under the receiving operating characteristic curve (AUROC) of 0.82. The model's predictive ability was highest within 24 hours from prediction (AUROC ¼ 0.83) and decreased slightly with time. Death was the most pre-dictable outcome with a daily average accuracy of 93{\%} and AUROC of 0.84. Discussion We developed the first non–disease-specific model that simultaneously predicts remaining days of hospitalization, death, and readmis-sion as part of the same outcome. By providing a future daily probability for each outcome class, we enable the visualization of future patient tra-jectories. Among these, it is possible to identify trajectories indicating expected discharge, expected continuing hospitalization, expected death, and possible readmission. Conclusions Bayesian Networks can model EHRs to provide real-time forecasts for patient outcomes, which provide richer information than tradi-tional independent point predictions of length of stay, death, or readmission, and can thus better support decision making.},
author = {Cai, Xiongcai and Perez-Concha, Oscar and Coiera, Enrico and Martin-Sanchez, Fernando and Day, Richard and Roffe, David and Gallego, Blanca},
doi = {10.1093/jamia/ocv110},
file = {:Users/na399/GitHub/thesis/references/papers/Cai et al.{\_}2016{\_}Real-time prediction of mortality, readmission, and length of stay using electronic health record data{\_}Journal of the(2).pdf:pdf},
isbn = {1527-974X$\backslash$r1067-5027},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Length of stay,Mortality,Patient outcome,Prediction,Readmission,rank:90,relevancy:C,topic:EHR,topic:prediction,type:research},
mendeley-tags = {rank:90,relevancy:C,topic:EHR,topic:prediction,type:research},
number = {3},
pages = {553--561},
pmid = {26374704},
title = {{Real-time prediction of mortality, readmission, and length of stay using electronic health record data}},
volume = {23},
year = {2016}
}
@article{Zakim2016,
abstract = {The article discusses the development of automated history-taking software for clinical medicine, clinical research and basic medical science and highlights the evidence for the validity and superiority of this method for collecting clinical data and its significance for quality care. Topics covered include automation of history taking and medical diagnosis, patient experience of self-reported computerized history taking and physician perception of clinical value from computerized histories.},
author = {Zakim, D.},
doi = {10.1111/joim.12509},
file = {:Users/na399/GitHub/thesis/references/papers/Zakim{\_}2016{\_}Development and significance of automated history-taking software for clinical medicine, clinical research and basic medical.pdf:pdf},
issn = {13652796},
journal = {Journal of Internal Medicine},
keywords = {computing,medical history,rank:95,relevancy:D,self-reported clinical data,topic:EHR,type:analysis},
mendeley-tags = {rank:95,relevancy:D,topic:EHR,type:analysis},
number = {3},
pages = {287--299},
title = {{Development and significance of automated history-taking software for clinical medicine, clinical research and basic medical science}},
volume = {280},
year = {2016}
}
@article{Xie2017,
author = {Xie, Jiang and Liu, Yan and Zeng, Xu and Zhang, Wu and Mei, Zhen},
doi = {10.1142/S0217984917400553},
file = {:Users/na399/GitHub/thesis/references/papers/Xie et al.{\_}2017{\_}A Bayesian network model for predicting type 2 diabetes risk based on electronic health records{\_}Modern Physics Letters B.pdf:pdf},
issn = {0217-9849},
journal = {Modern Physics Letters B},
keywords = {bayesian network,electronic health records,model:Bayesian,rank:20,relevancy:B,risk prediction,type 2 diabetes},
mendeley-tags = {rank:20,relevancy:B,model:Bayesian},
month = {jul},
number = {19-21},
pages = {1740055},
title = {{A Bayesian network model for predicting type 2 diabetes risk based on electronic health records}},
url = {http://www.worldscientific.com/doi/abs/10.1142/S0217984917400553},
volume = {31},
year = {2017}
}
@article{Ito2010,
abstract = {Background: Various authors have evaluated disease progression in Alzheimer's disease (AD), using patient data from individual clinical studies or pooled data across various trials. We conducted a systematic review of public data sources from 1990 to 2008 for all available AChE inhibitor studies, as well as clinical studies that evaluated the rate of deterioration in AD patients. Unique to this analysis, we developed a model based on literature data to describe the longitudinal response in the Alzheimer's Disease Assessment Scale-Cognitive (ADAS-cog) (change from baseline) in mild to moderate severity AD patients. The model was used to estimate disease progression for both placebo-treated patients and acetylcholinesterase (AChE)-inhibitor treated patients, and factors that affected disease progression. Methods: We collected 576 mean ADAS-cog changes from baseline data points of 52 trials, representing data from approximately 19,972 patients and more than 84,000 individual observations. The model described the rate of disease progression, the evident placebo effect, and the symptomatic effect of AChE-inhibitors. Baseline ADAS-cog, Mini-Mental State Examination score, age, and year of publication were tested as covariates. Results: The disease progression in mild to moderate AD patients across all available and relevant literature sources was estimated as 5.5 points per year. An Emax-type model best described the symptomatic drug effect of AChE inhibitors. The rate of disease progression (underlying disease progression) was no different between placebo and AChE-inhibitors groups. Baseline ADAS-cog is a significant covariate in disease progression. Baseline age was also tested as a covariate in the rate of disease progression, but the model was unable to describe any effects of age, likely because of the narrow distribution of mean age (literature-level analysis). There was no significant impact of publication year in the model. Conclusions: Baseline ADAS-cog is a significant covariate affecting the rate of disease progression, and it describes or at least explains the different rates of deterioration evident in early or late stages of the disease. There was no significant impact of publication year in the model, suggesting that disease progression has not slowed in more recent trials. {\textcopyright} 2010 The Alzheimer's Association.},
author = {Ito, Kaori and Ahadieh, Sima and Corrigan, Brian and French, Jonathan and Fullerton, Terence and Tensfeldt, Thomas},
doi = {10.1016/j.jalz.2009.05.665},
file = {:Users/na399/GitHub/thesis/references/papers/Ito et al.{\_}2010{\_}Disease progression meta-analysis model in Alzheimer's disease{\_}Alzheimer's and Dementia.pdf:pdf},
issn = {15525260},
journal = {Alzheimer's and Dementia},
keywords = {ADAS-cog,Alzheimer's disease,Disease progression,Literature data,Model-based analysis,disease:dementia,model:frequentist,rank:99,relevancy:A,topic:progression,type:research},
mendeley-tags = {disease:dementia,model:frequentist,rank:99,relevancy:A,topic:progression,type:research},
number = {1},
pages = {39--53},
pmid = {19592311},
publisher = {Elsevier Ltd},
title = {{Disease progression meta-analysis model in Alzheimer's disease}},
url = {http://dx.doi.org/10.1016/j.jalz.2009.05.665},
volume = {6},
year = {2010}
}
@article{Baytas2016,
abstract = {Electronic health records (EHRs) capture comprehensive patient information in digital form from a variety of sources. Increasing availability of EHRs has facilitated development of data and visual analytic tools for healthcare analytics, such as clinical decision support and patient care management systems. Many healthcare analytic tools are used to investigate fundamental problems, such as study of patient population, exploring complicated interactions among patients and their medical histories, and extracting structured phenotypes characterizing the patient population. In this paper, we propose PHENOTREE, a novel data-driven, hierarchical, and interactive phenotyping tool, that enables physicians and medical researchers to participate in the phenotyping process of large-scale EHR cohorts. The proposed visual analytic tool allows users to interactively explore EHR cohorts, and generate, interpret, evaluate, and refine phenotypes by building and navigating a phenotype hierarchy. Specifically, given a cohort or subcohort, PHENOTREE employs sparse principal component analysis (SPCA) to identify key clinical features that characterize the population. The clinical features provide a natural way to generate deeper phenotypes at finer granularities by expanding the phenotype hierarchy. To facilitate the intensive computation required for interactive analytics, we design an efficient SPCA solver based on a variance reduced stochastic gradient technique. The benefits of our method are demonstrated by analyzing two different EHR patient cohorts, a public and a private dataset containing EHRs of 101 767 and 223 076 patients, respectively. Our evaluations show that PHENOTREE can detect clinically meaningful hierarchical phenotypes.},
author = {Baytas, Inci M. and Lin, Kaixiang and Wang, Fei and Jain, Anil K. and Zhou, Jiayu},
doi = {10.1109/TMM.2016.2614225},
file = {:Users/na399/GitHub/thesis/references/papers/Baytas et al.{\_}2016{\_}PhenoTree Interactive Visual Analytics for Hierarchical Phenotyping From Large-Scale Electronic Health Records{\_}IEEE T.pdf:pdf},
issn = {15209210},
journal = {IEEE Transactions on Multimedia},
keywords = {Data-driven phenotyping,disease:general,electronic health records (EHRs),hierarchical phenotyping,interactive visual analytics,rank:95,relevancy:B,sparse principal component analysis (SPCA),topic:EHR,topic:phenotyping,topic:visualisation,type:method},
mendeley-tags = {disease:general,rank:95,relevancy:B,topic:EHR,topic:phenotyping,topic:visualisation,type:method},
number = {11},
pages = {2257--2270},
title = {{PhenoTree: Interactive Visual Analytics for Hierarchical Phenotyping From Large-Scale Electronic Health Records}},
volume = {18},
year = {2016}
}
@article{Jensen2012a,
author = {Jensen, Peter B. and Jensen, Lars J. and Brunak, S{\o}ren},
doi = {10.1038/nrg3208-c2},
file = {:Users/na399/GitHub/thesis/references/papers/Jensen, Jensen, Brunak{\_}2012{\_}Reply to 'Mining electronic health records an additional perspective'{\_}Nature Reviews Genetics.pdf:pdf},
issn = {1471-0056},
journal = {Nature Reviews Genetics},
keywords = {disease:general,rank:99,relevancy:A,topic:EHR,type:commentary},
mendeley-tags = {disease:general,rank:99,relevancy:A,topic:EHR,type:commentary},
number = {1},
pages = {75--75},
publisher = {Nature Publishing Group},
title = {{Reply to 'Mining electronic health records: an additional perspective'}},
url = {http://www.nature.com/doifinder/10.1038/nrg3208-c2},
volume = {14},
year = {2012}
}
@article{Bynum2017,
author = {Bynum, W and Carrillo, Maria and Davis, Randall and Gustafson, Deborah and Karlawish, Jason and King, Jonathan W and Li, Rose Maria and Nicholas, Lauren and Obermeyer, Ziad and Peng, Lily and Possin, Katherine and Rentz, Dorene and Rice, J Jeremy and Shafran, Izhak and Smider, Nancy and Sperling, Reisa and Weiner, Michael},
file = {:Users/na399/GitHub/thesis/references/papers/Bynum et al.{\_}2017{\_}Cost-Effective Early Detection of Cognitive Decline{\_}Unknown.pdf:pdf},
keywords = {rank:n/a,relevancy:D},
mendeley-tags = {rank:n/a,relevancy:D},
title = {{Cost-Effective Early Detection of Cognitive Decline}},
year = {2017}
}
@article{Zhang2015e,
abstract = {The rise of data-intensive biology, advances in informatics technology, and changes in the way health care is delivered has created an compelling opportunity to allow us investigate biomedical questions in the context of "big data" and develop knowledge systems to support precision medicine. To promote such data mining and informatics technology development in precision medicine, we hosted two international informatics workshops in 2014: 1) the first workshop on Data Mining in Biomedical informatics and Healthcare, in conjunction with the 18th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2014), and 2) the first workshop on Translational biomedical and clinical informatics, in conjunction with the 8th International Conference on Systems Biology and the 4th Translational Bioinformatics Conference (ISB/TBC 2014). This thematic issue of BioData Mining presents a series of selected papers from these two international workshops, aiming to address the data mining needs in the informatics field due to the deluge of "big data" generated by next generation biotechnologies such as next generation sequencing, metabolomics, and proteomics, as well as the structured and unstructured biomedical and healthcare data from electronic health records. We are grateful for the BioData Mining's willingness to produce this forward-looking thematic issue.},
author = {Zhang, Yuji and Zhu, Qian and Liu, Hongfang},
doi = {10.1186/s13040-015-0064-2},
file = {:Users/na399/GitHub/thesis/references/papers/Zhang, Zhu, Liu{\_}2015{\_}Next generation informatics for big data in precision medicine era{\_}BioData Mining.pdf:pdf},
isbn = {1756-0381},
issn = {17560381},
journal = {BioData Mining},
keywords = {rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
number = {1},
pages = {10--12},
pmid = {26539249},
publisher = {BioData Mining},
title = {{Next generation informatics for big data in precision medicine era}},
volume = {8},
year = {2015}
}
@inproceedings{Zhou2011,
abstract = {Alzheimer's Disease (AD), the most common type of dementia, is a severe neurodegenerative disorder. Identifying markers that can track the progress of the disease has recently received increasing attentions in AD research. A definitive diagnosis of AD requires autopsy confirmation, thus many clinical/cognitive measures including Mini Mental State Examination (MMSE) and Alzheimer's Disease Assessment Scale cognitive subscale (ADAS-Cog) have been designed to evaluate the cognitive status of the patients and used as important criteria for clinical diagnosis of probable AD. In this paper, we propose a multi-task learning formulation for predicting the disease progression measured by the cognitive scores and selecting markers predictive of the progression. Specifically, we formulate the prediction problem as a multi-task regression problem by considering the prediction at each time point as a task. We capture the intrinsic relatedness among different tasks by a temporal group Lasso regularizer. The regularizer consists of two components including an ℓ 2,1-norm penalty on the regression weight vectors, which ensures that a small subset of features will be selected for the regression models at all time points, and a temporal smoothness term which ensures a small deviation between two regression models at successive time points. We have performed extensive evaluations using various types of data at the baseline from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database for predicting the future MMSE and ADAS-Cog scores. Our experimental studies demonstrate the effectiveness of the proposed algorithm for capturing the progression trend and the cross-sectional group differences of AD severity. Results also show that most markers selected by the proposed algorithm are consistent with findings from existing cross-sectional studies. Copyright 2011 ACM.},
address = {New York, New York, USA},
author = {Zhou, Jiayu and Yuan, Lei and Liu, Jun and Ye, Jieping},
booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '11},
doi = {10.1145/2020408.2020549},
file = {:Users/na399/GitHub/thesis/references/papers/Zhou et al.{\_}2011{\_}A multi-task learning formulation for predicting disease progression{\_}Proceedings of the 17th ACM SIGKDD international c.pdf:pdf},
isbn = {9781450308137},
keywords = {alzheimer,cognitive score,disease:dementia,group,lasso,model:Lasso,multi-task learning,rank:90,regression,relevancy:A,s disease,stability selection,topic:prediction,topic:progression,type:research},
mendeley-tags = {rank:90,type:research,disease:dementia,topic:prediction,topic:progression,model:Lasso,relevancy:A},
pages = {814},
publisher = {ACM Press},
title = {{A multi-task learning formulation for predicting disease progression}},
url = {http://dl.acm.org/citation.cfm?doid=2020408.2020549},
year = {2011}
}
@article{Farrell,
author = {Farrell, Lindsay},
file = {:Users/na399/GitHub/thesis/references/papers/Farrell{\_}Unknown{\_}Evaluation of a Computerized Clinical Decision Support System and EHR-Linked Registry to Improve the Management of Hyper.pdf:pdf},
keywords = {Clinical Decision Support,Hypertension,Implementation,Quality Improvement,rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
title = {{Evaluation of a Computerized Clinical Decision Support System and EHR-Linked Registry to Improve the Management of Hypertension in a Community Health Center}}
}
@article{Baker2017,
abstract = {Background Modeling trajectories of decline can help describe the variability in progression of cognitive impairment in dementia. Better characterisation of these trajectories has significant implica- tions for understanding disease progression, trial design and care planning. Methods Patients with at least three Mini-mental State Examination (MMSE) scores recorded in the South London and Maudsley NHS Foundation Trust Electronic Health Records, UK were selected (N = 3441) to form a retrospective cohort. Trajectories of cognitive decline were identified through latent class growth analysis of longitudinal MMSEscores. Demographics, Health of Nation Outcome Scales and medications were compared across trajectories identified. Results Four of the six trajectories showed increased rate of decline with lower baseline MMSE. Two trajectories had similar initialMMSEscores but different rates of decline. In the faster declining trajectory of the two, a higher incidence of both behavioral problems and sertraline prescription were present. Conclusions Wefind suggestive evidence for association of behavioral problems and sertraline prescrip- tion with rate of decline. Further work is needed to determine whether trajectories replicate in other datasets. Introduction},
author = {Baker, Elizabeth and Iqbal, Ehtesham and Johnston, Caroline and Broadbent, Matthew and Shetty, Hitesh and Stewart, Robert and Howard, Robert and Newhouse, Stephen and Khondoker, Mizanur and Dobson, Richard J. B.},
doi = {10.1371/journal.pone.0178562},
editor = {Laks, Jerson},
file = {:Users/na399/GitHub/thesis/references/papers/Baker et al.{\_}2017{\_}Trajectories of dementia-related cognitive decline in a large mental health records derived patient cohort{\_}PLoS ONE.pdf:pdf},
isbn = {1111111111},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {disease:dementia,model:SVM,rank:90,relevancy:A,topic:EHR,topic:progression,type:research},
mendeley-tags = {disease:dementia,model:SVM,rank:90,relevancy:A,topic:EHR,topic:progression,type:research},
month = {jun},
number = {6},
pages = {e0178562},
title = {{Trajectories of dementia-related cognitive decline in a large mental health records derived patient cohort}},
url = {http://dx.plos.org/10.1371/journal.pone.0178562},
volume = {12},
year = {2017}
}
@article{Horng2017,
abstract = {OBJECTIVE To demonstrate the incremental benefit of using free text data in addition to vital sign and demographic data to identify patients with suspected infection in the emergency department. METHODS This was a retrospective, observational cohort study performed at a tertiary academic teaching hospital. All consecutive ED patient visits between 12/17/08 and 2/17/13 were included. No patients were excluded. The primary outcome measure was infection diagnosed in the emergency department defined as a patient having an infection related ED ICD-9-CM discharge diagnosis. Patients were randomly allocated to train (64{\%}), validate (20{\%}), and test (16{\%}) data sets. After preprocessing the free text using bigram and negation detection, we built four models to predict infection, incrementally adding vital signs, chief complaint, and free text nursing assessment. We used two different methods to represent free text: a bag of words model and a topic model. We then used a support vector machine to build the prediction model. We calculated the area under the receiver operating characteristic curve to compare the discriminatory power of each model. RESULTS A total of 230,936 patient visits were included in the study. Approximately 14{\%} of patients had the primary outcome of diagnosed infection. The area under the ROC curve (AUC) for the vitals model, which used only vital signs and demographic data, was 0.67 for the training data set, 0.67 for the validation data set, and 0.67 (95{\%} CI 0.65-0.69) for the test data set. The AUC for the chief complaint model which also included demographic and vital sign data was 0.84 for the training data set, 0.83 for the validation data set, and 0.83 (95{\%} CI 0.81-0.84) for the test data set. The best performing methods made use of all of the free text. In particular, the AUC for the bag-of-words model was 0.89 for training data set, 0.86 for the validation data set, and 0.86 (95{\%} CI 0.85-0.87) for the test data set. The AUC for the topic model was 0.86 for the training data set, 0.86 for the validation data set, and 0.85 (95{\%} CI 0.84-0.86) for the test data set. CONCLUSION Compared to previous work that only used structured data such as vital signs and demographic information, utilizing free text drastically improves the discriminatory ability (increase in AUC from 0.67 to 0.86) of identifying infection.},
author = {Horng, Steven and Sontag, David A. and Halpern, Yoni and Jernite, Yacine and Shapiro, Nathan I. and Nathanson, Larry A.},
doi = {10.1371/journal.pone.0174708},
editor = {Groza, Tudor},
file = {:Users/na399/GitHub/thesis/references/papers/Horng et al.{\_}2017{\_}Creating an automated trigger for sepsis clinical decision support at emergency department triage using machine learni.pdf:pdf},
isbn = {1111111111},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {disease:sepsis,model:NLP,model:SVM,rank:90,relevancy:B,topic:CDSS,topic:diagnosis,type:research},
mendeley-tags = {disease:sepsis,model:NLP,model:SVM,rank:90,relevancy:B,topic:CDSS,topic:diagnosis,type:research},
month = {apr},
number = {4},
pages = {e0174708},
pmid = {28384212},
title = {{Creating an automated trigger for sepsis clinical decision support at emergency department triage using machine learning}},
url = {http://dx.plos.org/10.1371/journal.pone.0174708},
volume = {12},
year = {2017}
}
@article{Cortes2017,
abstract = {Gil McVean and colleagues present a new Bayesian analysis framework that exploits the hierarchical structure of diagnosis classifications to analyze genetic variants against UK Biobank disease phenotypes derived from self-reporting and hospital episode statistics. Their method displays increased power to detect genetic effects over other approaches and identifies novel associations between classical HLA alleles and common immune-mediated diseases.},
author = {Cortes, Adrian and Dendrou, Calliope A. and Motyer, Allan and Jostins, Luke and Vukcevic, Damjan and Dilthey, Alexander and Donnelly, Peter and Leslie, Stephen and Fugger, Lars and McVean, Gil},
doi = {10.1038/ng.3926},
file = {:Users/na399/Downloads/Research Papers/Cortes et al.{\_}2017{\_}Bayesian analysis of genetic association across tree-structured routine healthcare data in the UK Biobank{\_}Nature Gene.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {disease:general,model:Bayesian,rank:99,relevancy:C,topic:bioinformatics,type:research},
mendeley-tags = {disease:general,model:Bayesian,rank:99,relevancy:C,topic:bioinformatics,type:research},
number = {9},
pages = {1311--1318},
pmid = {28759005},
publisher = {Nature Publishing Group},
title = {{Bayesian analysis of genetic association across tree-structured routine healthcare data in the UK Biobank}},
url = {http://dx.doi.org/10.1038/ng.3926},
volume = {49},
year = {2017}
}
@article{Demiris2015,
abstract = {INTRODUCTION There is a growing international focus on patient- centered care. A model designed to facilitate this type of care in the primary care setting is the patient-centered medical home. This model of care strives to be patient-focused, comprehensive, team-based, coordinated, accessible, and focused on quality and safety of care. OBJECTIVE The objective of this paper is to identify the current status and future trends of patient-centered care and the role of informatics systems and tools in facilitating this model of care. METHODS In this paper we review recent scientific literature of the past four years to identify trends and state of current evidence when it comes to patient-centered care overall, and more specifically medical homes. RESULTS There are several studies that indicate growth and development in seven informatics areas within patient-centered care, namely clinical decision support, registries, team care, care transitions, personal health records, telehealth, and measurement. In some cases we are still lacking large randomized clinical trials and the evidence base is not always solid, but findings strongly indicate the potential of informatics to support patient-centered care. CONCLUSION Current evidence indicates that advancements have been made in implementing and evaluating patient-centered care models. Technical, legal, and practical challenges still remain. Further examination of the impact of patient-centered informatics tools and systems on clinical outcomes is needed.},
author = {Demiris, G. and Kneale, L.},
doi = {10.15265/IY-2015-003},
file = {:Users/na399/Downloads/Research Papers/Demiris, Kneale{\_}2015{\_}Informatics Systems and Tools to Facilitate Patient-centered Care Coordination{\_}Yearbook of medical informatics.pdf:pdf},
issn = {0943-4747},
journal = {IMIA Yearbook},
keywords = {Patient-centered care,clinical,decision support systems,personal health records,rank:n/a,registries,relevancy:C,telehealth},
mendeley-tags = {rank:n/a,relevancy:C},
number = {1},
pages = {15--21},
pmid = {26293847},
title = {{Informatics Systems and Tools to Facilitate Patient-centered Care Coordination}},
url = {http://www.schattauer.de/index.php?id=1214{\&}doi=10.15265/IY-2015-003},
volume = {10},
year = {2015}
}
@article{Khachaturian2013,
abstract = {This editorial discusses the pathways for international harmonization on data sharing in the field of aging and dementia research. The special issue of Alzheimer's {\&} Dementia aims to provide a set of seminal articles on the array of challenges confronted by various groups in their efforts to establish a multi-site collaborative research network, harmonize data sharing rules, and manage big databases as shared global resources. In order to usher in the era of big data for aging and dementia research, three key mission parameters need to be addressed: (1) Magnitude and multiple domains of data, (2) Harmonization, and (3) Funding. Alzheimer's {\&} Dementia solicits suggestions from the wider scientific community of any additional databases, cohorts, or ongoing studies that should be included in the proposed comprehensive inventory. The specific goals of the issue will be to survey and review all major data series that can be combined in standardized formats, codified and made accessible for truly international comparative purposes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
author = {Khachaturian, Ara S. and Meranus, Dana H. and Kukull, Walter A. and Khachaturian, Zaven S.},
doi = {10.1016/j.jalz.2013.09.001},
file = {:Users/na399/GitHub/thesis/references/papers/Khachaturian et al.{\_}2013{\_}Big data, aging, and dementia Pathways for international harmonization on data sharing{\_}Alzheimer's {\&} Dementia.pdf:pdf},
isbn = {1552-5279(Electronic);1552-5260(Print)},
issn = {15525260},
journal = {Alzheimer's {\&} Dementia},
keywords = {disease:dementia,rank:99,relevancy:C,topic:dataMining,type:commentary},
mendeley-tags = {rank:99,type:commentary,disease:dementia,relevancy:C,topic:dataMining},
month = {oct},
number = {5},
pages = {S61--S62},
pmid = {24125464},
publisher = {The Alzheimer's Association},
title = {{Big data, aging, and dementia: Pathways for international harmonization on data sharing}},
url = {http://dx.doi.org/10.1016/j.jalz.2013.09.001 http://linkinghub.elsevier.com/retrieve/pii/S1552526013028215},
volume = {9},
year = {2013}
}
@article{Vinters2015,
abstract = {Alzheimer's disease/senile dementia of the Alzheimer type (AD/SDAT) is the most common neuropathologic substrate of dementia. It is characterized by synapse loss (predominantly within neocortex) as well as deposition of certain distinctive lesions (the result of protein misfolding) throughout the brain. The latter include senile plaques, composed mainly of an amyloid (A$\beta$) core and a neuritic component; neurofibrillary tangles, composed predominantly of hyperphosphorylated tau; and cerebral amyloid angiopathy, a microangiopathy affecting both cerebral cortical capillaries and arterioles and resulting from A$\beta$ deposition within their walls or (in the case of capillaries) immediately adjacent brain parenchyma. In this article, I discuss the hypothesized role these lesions play in causing cerebral dysfunction, as well as CSF and neuroimaging biomarkers (for dementia) that are especially relevant as immunotherapeutic approaches are being developed to remove A$\beta$ from the brain parenchyma. In addition, I address the role of neuropathology in characterizing the sequelae of new AD/SDAT therapies and helping to validate CSF and neuroimaging biomarkers of disease. Comorbidity of AD/SDAT and various types of cerebrovascular disease is a major theme in dementia research, especially as cognitive impairment develops in the oldest old, who are especially vulnerable to ischemic and hemorrhagic brain lesions. Expected final online publication date for the Annual Review of Pathology: Mechanisms of Disease Volume 10 is January 24, 2015. Please see http://www.annualreviews.org/catalog/pubdates.aspx for revised estimates.},
archivePrefix = {arXiv},
arxivId = {cs/9605103},
author = {Vinters, Harry V.},
doi = {10.1146/annurev-pathol-020712-163927},
eprint = {9605103},
file = {:Users/na399/GitHub/thesis/references/papers/Vinters{\_}2015{\_}Emerging Concepts in Alzheimer's Disease{\_}Annual Review of Pathology Mechanisms of Disease.pdf:pdf},
isbn = {0-7803-3213-X},
issn = {1553-4006},
journal = {Annual Review of Pathology: Mechanisms of Disease},
keywords = {alzheimer,biomarkers,dementia,disease:dementia,immunotherapy,ischemic,mixed dementia,neuropathology,rank:99,relevancy:C,s disease,topic:pathology,type:review,vascular dementia},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:pathology,type:review},
number = {1},
pages = {291--319},
pmid = {25387055},
primaryClass = {cs},
title = {{Emerging Concepts in Alzheimer's Disease}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-pathol-020712-163927},
volume = {10},
year = {2015}
}
@article{Maroco2011,
abstract = {BACKGROUND: Dementia and cognitive impairment associated with aging are a major medical and social concern. Neuropsychological testing is a key element in the diagnostic procedures of Mild Cognitive Impairment (MCI), but has presently a limited value in the prediction of progression to dementia. We advance the hypothesis that newer statistical classification methods derived from data mining and machine learning methods like Neural Networks, Support Vector Machines and Random Forests can improve accuracy, sensitivity and specificity of predictions obtained from neuropsychological testing. Seven non parametric classifiers derived from data mining methods (Multilayer Perceptrons Neural Networks, Radial Basis Function Neural Networks, Support Vector Machines, CART, CHAID and QUEST Classification Trees and Random Forests) were compared to three traditional classifiers (Linear Discriminant Analysis, Quadratic Discriminant Analysis and Logistic Regression) in terms of overall classification accuracy, specificity, sensitivity, Area under the ROC curve and Press'Q. Model predictors were 10 neuropsychological tests currently used in the diagnosis of dementia. Statistical distributions of classification parameters obtained from a 5-fold cross-validation were compared using the Friedman's nonparametric test.$\backslash$n$\backslash$nRESULTS: Press' Q test showed that all classifiers performed better than chance alone (p {\textless} 0.05). Support Vector Machines showed the larger overall classification accuracy (Median (Me) = 0.76) an area under the ROC (Me = 0.90). However this method showed high specificity (Me = 1.0) but low sensitivity (Me = 0.3). Random Forest ranked second in overall accuracy (Me = 0.73) with high area under the ROC (Me = 0.73) specificity (Me = 0.73) and sensitivity (Me = 0.64). Linear Discriminant Analysis also showed acceptable overall accuracy (Me = 0.66), with acceptable area under the ROC (Me = 0.72) specificity (Me = 0.66) and sensitivity (Me = 0.64). The remaining classifiers showed overall classification accuracy above a median value of 0.63, but for most sensitivity was around or even lower than a median value of 0.5.$\backslash$n$\backslash$nCONCLUSIONS: When taking into account sensitivity, specificity and overall classification accuracy Random Forests and Linear Discriminant analysis rank first among all the classifiers tested in prediction of dementia using several neuropsychological tests. These methods may be used to improve accuracy, sensitivity and specificity of Dementia predictions from neuropsychological testing.},
author = {Maroco, Jo{\~{a}}o and Silva, Dina and Rodrigues, Ana and Guerreiro, Manuela and Santana, Isabel and de Mendon{\c{c}}a, Alexandre},
doi = {10.1186/1756-0500-4-299},
file = {:Users/na399/GitHub/thesis/references/papers/Maroco et al.{\_}2011{\_}Data mining methods in the prediction of Dementia A real-data comparison of the accuracy, sensitivity and specificity.pdf:pdf},
isbn = {10.1186/1756-0500-4-299},
issn = {1756-0500},
journal = {BMC Research Notes},
keywords = {disease:dementia,model:DeepLearning,model:SVM,rank:60,relevancy:A,topic:prediction,type:research},
mendeley-tags = {rank:60,type:research,topic:prediction,disease:dementia,model:SVM,model:DeepLearning,relevancy:A},
number = {1},
pages = {299},
pmid = {21849043},
title = {{Data mining methods in the prediction of Dementia: A real-data comparison of the accuracy, sensitivity and specificity of linear discriminant analysis, logistic regression, neural networks, support vector machines, classification trees and random forests}},
url = {http://bmcresnotes.biomedcentral.com/articles/10.1186/1756-0500-4-299},
volume = {4},
year = {2011}
}
@article{Ernecoff2017,
abstract = {CONTEXT Investigators need novel methods for timely identification of patients with serious illness to test or implement new palliative care models. OBJECTIVE The study aim was to develop an electronic health record (EHR) phenotype to identify patients with late-stage dementia for a clinical trial of palliative care consultation. METHODS We developed a computerized method to identify patients with dementia on hospital admission. Within a data warehouse derived from the hospital's EHR, we used search terms of age, admission date, and ICD-9 and ICD-10 diagnosis codes to create a EHR dementia phenotype, followed by brief medical record review to confirm late-stage dementia. We calculated positive predictive value, false discovery rate, and false negative rate of this novel screening method. RESULTS The EHR phenotype screening method had a positive predictive value of 76.3{\%} for dementia patients and 24.5{\%} for late-stage dementia patients; a false discovery rate of 23.7{\%} for dementia patients and 75.5{\%} for late-stage dementia patients compared to physician assesement. The sensitivity of this screening method was 59.7{\%} to identify hospitalized patients with dementia. Daily screening-including confirmatory chart reviews-averaged 20 minutes and was more feasible, efficient and more complete than manual screening. CONCLUSION A novel method using an EHR phenotype plus brief medical record review is effective to identify hospitalized patients with late-stage dementia. In healthcare systems with similar clinical data warehouses, this method may be applied to serious illness populations to improve enrollment in clinical trials of palliative care or to facilitate access to palliative care services.},
author = {Ernecoff, Natalie C. and Wessell, Kathryn L. and Gabriel, Stacey and Carey, Timothy S. and Hanson, Laura C.},
doi = {10.1016/j.jpainsymman.2017.12.480},
file = {:Users/na399/GitHub/thesis/references/papers/Ernecoff et al.{\_}2017{\_}A novel screening method to identify late-stage dementia patients for palliative care research and practice{\_}Journal.pdf:pdf},
issn = {08853924},
journal = {Journal of Pain and Symptom Management},
keywords = {computable phenotype,disease:dementia,ehr,electronic health record,family medicine,geriatrics,rank:90,relevancy:A,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {disease:dementia,rank:90,relevancy:A,topic:EHR,topic:phenotyping,type:research},
number = {4},
pages = {1152--1158.e1},
pmid = {29288881},
publisher = {Elsevier Inc},
title = {{A novel screening method to identify late-stage dementia patients for palliative care research and practice}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0885392417312435},
volume = {55},
year = {2017}
}
@article{Osop2016,
abstract = {Effective decision-making plays an important role in promoting optimal care delivery. Factors such as availability of data, timely access to data and organised information greatly influences the quality of decision-making as illustrated in a causal loop diagram. The contribution of practice-based evidence thus aims at structuring an approach where healthcare professionals can be consistently assisted in making effective decisions during routine primary care. Through a practice-based evidence e-health scenario and a data-flow diagram of clinical systems in a public hospital from Singapore, we have identified the importance of leveraging electronic health records as ideal resources in the pursuit of improving healthcare decision-making.},
author = {Osop, Hamzah and Sahama, Tony},
doi = {10.1109/HealthCom.2016.7749474},
file = {:Users/na399/GitHub/thesis/references/papers/Osop, Sahama{\_}2016{\_}Electronic health records Improvement to healthcare decision-making{\_}2016 IEEE 18th International Conference on e-Healt.pdf:pdf},
isbn = {9781509033706},
journal = {2016 IEEE 18th International Conference on e-Health Networking, Applications and Services, Healthcom 2016},
keywords = {ICT,data warehouse,decision-making,electronic health records,evidence-based practice,practice-based evidence,rank:n/a,relevancy:A},
mendeley-tags = {rank:n/a,relevancy:A},
title = {{Electronic health records: Improvement to healthcare decision-making}},
year = {2016}
}
@article{Zieselman2014,
abstract = {BACKGROUND: Alzheimer's disease is the most common form of progressive dementia and there is currently no known cure. The cause of onset is not fully understood but genetic factors are expected to play a significant role. We present here a bioinformatics approach to the genetic analysis of grey matter density as an endophenotype for late onset Alzheimer's disease. Our approach combines machine learning analysis of gene-gene interactions with large-scale functional genomics data for assessing biological relationships. RESULTS: We found a statistically significant synergistic interaction among two SNPs located in the intergenic region of an olfactory gene cluster. This model did not replicate in an independent dataset. However, genes in this region have high-confidence biological relationships and are consistent with previous findings implicating sensory processes in Alzheimer's disease. CONCLUSIONS: Previous genetic studies of Alzheimer's disease have revealed only a small portion of the overall variability due to DNA sequence differences. Some of this missing heritability is likely due to complex gene-gene and gene-environment interactions. We have introduced here a novel bioinformatics analysis pipeline that embraces the complexity of the genetic architecture of Alzheimer's disease while at the same time harnessing the power of functional genomics. These findings represent novel hypotheses about the genetic basis of this complex disease and provide open-access methods that others can use in their own studies.},
author = {Zieselman, Amanda L and Fisher, Jonathan M and Hu, Ting and Andrews, Peter C and Greene, Casey S and Shen, Li and Saykin, Andrew J and Moore, Jason H},
doi = {10.1186/1756-0381-7-17},
file = {:Users/na399/GitHub/thesis/references/papers/Zieselman et al.{\_}2014{\_}Computational genetics analysis of grey matter density in Alzheimer's disease{\_}BioData Min.pdf:pdf},
isbn = {1756-0381 (Electronic)$\backslash$r1756-0381 (Linking)},
issn = {1756-0381},
journal = {BioData Mining},
keywords = {rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
month = {dec},
number = {1},
pages = {17},
pmid = {25165488},
title = {{Computational genetics analysis of grey matter density in Alzheimer's disease}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25165488 http://biodatamining.biomedcentral.com/articles/10.1186/1756-0381-7-17},
volume = {7},
year = {2014}
}
@article{Zineh2013,
abstract = {I},
author = {Larson, Eric B. and Yaffe, Kristine and Langa, Kenneth M.},
doi = {10.1056/NEJMp1311405},
file = {:Users/na399/Downloads/Research Papers/Zineh, Pacanowski, Woodcock{\_}2013{\_}Pharmacogenetics and Coumarin Dosing — Recalibrating Expectations{\_}New England Journal of Medicine.pdf:pdf},
isbn = {0028-4793},
issn = {0028-4793},
journal = {New England Journal of Medicine},
keywords = {disease:dementia,rank:99,relevancy:C,topic:impact,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:impact,type:commentary},
month = {dec},
number = {24},
pages = {2275--2277},
pmid = {20573919},
title = {{New Insights into the Dementia Epidemic}},
url = {http://www.nejm.org/doi/10.1056/NEJMp1311405},
volume = {369},
year = {2013}
}
@article{Krenn2017,
author = {Krenn, Louis and Schlossman, David},
doi = {10.1016/j.pmrj.2017.04.001},
file = {:Users/na399/GitHub/thesis/references/papers/Krenn, Schlossman{\_}2017{\_}Have Electronic Health Records Improved the Quality of Patient Care{\_}Pm{\&}R.pdf:pdf},
issn = {19341482},
journal = {PM{\&}R},
keywords = {rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
month = {may},
number = {5},
pages = {S41--S50},
publisher = {American Academy of Physical Medicine and Rehabilitation},
title = {{Have Electronic Health Records Improved the Quality of Patient Care?}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1934148217304148},
volume = {9},
year = {2017}
}
@phdthesis{Liu2015,
author = {Liu, Yu-ying},
file = {:Users/na399/GitHub/thesis/references/papers/Liu{\_}2015{\_}Disease Progression Modeling Using Multi-Dimensional Continuous-Time Hidden Markov Model Disease Progression Modeling Using Mul.pdf:pdf},
keywords = {rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
number = {December},
title = {{Disease Progression Modeling Using Multi-Dimensional Continuous-Time Hidden Markov Model Disease Progression Modeling Using Multi-Dimensional Continuous-Time Hidden}},
year = {2015}
}
@inproceedings{AlTaleb2017,
author = {{Al Taleb}, Asma Rashed and Hoque, Mozaherul and Hasanat, Abul and Khan, Muhammad Badruddin},
booktitle = {2017 International Conference on Informatics, Health {\&} Technology (ICIHT)},
doi = {10.1109/ICIHT.2017.7899004},
file = {:Users/na399/GitHub/thesis/references/papers/Al Taleb, Abul Hasanat, Khan{\_}2017{\_}Application of Data Mining Techniques to Predict Length of Stay of Stroke Patients{\_}Informatics Health.pdf:pdf},
isbn = {978-1-4673-8765-1},
keywords = {and the prediction of,bayesian network,data mining,decision tree,factors determining the los,length of stay,los is made,most previous research uses,rank:n/a,relevancy:B,statistical techniques to identify,stroke patient},
mendeley-tags = {rank:n/a,relevancy:B},
month = {feb},
pages = {1--5},
publisher = {IEEE},
title = {{Application of data mining techniques to predict length of stay of stroke patients}},
url = {http://ieeexplore.ieee.org/document/7899004/},
year = {2017}
}
@article{Wei2016a,
abstract = {OBJECTIVE: To evaluate the phenotyping performance of three major electronic health record (EHR) components: International Classification of Disease (ICD) diagnosis codes, primary notes, and specific medications. MATERIALS AND METHODS: We conducted the evaluation using de-identified Vanderbilt EHR data. We preselected ten diseases: atrial fibrillation, Alzheimer's disease, breast cancer, gout, human immunodeficiency virus infection, multiple sclerosis, Parkinson's disease, rheumatoid arthritis, and types 1 and 2 diabetes mellitus. For each disease, patients were classified into seven categories based on the presence of evidence in diagnosis codes, primary notes, and specific medications. Twenty-five patients per disease category (a total number of 175 patients for each disease, 1750 patients for all ten diseases) were randomly selected for manual chart review. Review results were used to estimate the positive predictive value (PPV), sensitivity, andF-score for each EHR component alone and in combination. RESULTS: The PPVs of single components were inconsistent and inadequate for accurately phenotyping (0.06-0.71). Using two or more ICD codes improved the average PPV to 0.84. We observed a more stable and higher accuracy when using at least two components (mean ± standard deviation: 0.91 ± 0.08). Primary notes offered the best sensitivity (0.77). The sensitivity of ICD codes was 0.67. Again, two or more components provided a reasonably high and stable sensitivity (0.59 ± 0.16). Overall, the best performance (Fscore: 0.70 ± 0.12) was achieved by using two or more components. Although the overall performance of using ICD codes (0.67 ± 0.14) was only slightly lower than using two or more components, its PPV (0.71 ± 0.13) is substantially worse (0.91 ± 0.08). CONCLUSION: Multiple EHR components provide a more consistent and higher performance than a single one for the selected phenotypes. We suggest considering multiple EHR components for future phenotyping design in order to obtain an ideal result.},
author = {Wei, Wei Qi and Teixeira, Pedro L. and Mo, Huan and Cronin, Robert M. and Warner, Jeremy L. and Denny, Joshua C.},
doi = {10.1093/jamia/ocv130},
file = {:Users/na399/GitHub/thesis/references/papers/Wei et al.{\_}2016{\_}Combining billing codes, clinical notes, and medications from electronic health records provides superior phenotyping pe.pdf:pdf},
isbn = {1527-974X (Electronic)$\backslash$r1067-5027 (Linking)},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {Clinical notes,Diagnosis codes,Electronic health records,International classification of diseases,Medications,Phenotype,Problem lists,disease:dementia,disease:general,rank:90,relevancy:A,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {disease:dementia,disease:general,rank:90,relevancy:A,topic:EHR,topic:phenotyping,type:research},
number = {e1},
pages = {20--27},
pmid = {26338219},
title = {{Combining billing codes, clinical notes, and medications from electronic health records provides superior phenotyping performance}},
volume = {23},
year = {2016}
}
@article{Liu1973,
abstract = {The Continuous-Time Hidden Markov Model (CT-HMM) is an attractive approach to modeling disease progression due to its ability to describe noisy observations arriving irregularly in time. However, the lack of an efficient parameter learning algorithm for CT-HMM restricts its use to very small models or requires unrealistic constraints on the state transitions. In this paper, we present the first complete characterization of efficient EM-based learning methods for CT-HMM models. We demonstrate that the learning problem consists of two challenges: the estimation of posterior state probabilities and the computation of end-state conditioned statistics. We solve the first challenge by reformulating the estimation problem in terms of an equivalent discrete time-inhomogeneous hidden Markov model. The second challenge is addressed by adapting three approaches from the continuous time Markov chain literature to the CT-HMM domain. We demonstrate the use of CT-HMMs with more than 100 states to visualize and predict disease progression using a glaucoma dataset and an Alzheimer's disease dataset.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Liu, Yu-Ying and Li, Shuang and Li, Fuxin and Song, Le and Rehg, James M},
doi = {10.1016/j.bbamem.2015.02.010.Cationic},
eprint = {15334406},
file = {:Users/na399/GitHub/thesis/references/papers/Liu et al.{\_}2015{\_}Efficient Learning of Continuous-Time Hidden Markov Models for Disease Progression.{\_}Advances in neural information proce.pdf:pdf},
isbn = {0000000000000},
issn = {1049-5258},
journal = {Advances in neural information processing systems},
keywords = {rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
number = {12},
pages = {3599--3607},
pmid = {27019571},
title = {{Efficient Learning of Continuous-Time Hidden Markov Models for Disease Progression.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/27019571{\%}0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4804157 http://www.ncbi.nlm.nih.gov/pubmed/27019571 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4804157},
volume = {28},
year = {2015}
}
@article{Hu2016,
abstract = {The co-occurrence of diseases can inform the underlying network biology of shared and multifunctional genes and pathways. In addition, comorbidities help to elucidate the effects of external exposures, such as diet, lifestyle and patient care. With worldwide health transaction data now often being collected electronically, disease co-occurrences are starting to be quantitatively characterized. Linking network dynamics to the real-life, non-ideal patient in whom diseases co-occur and interact provides a valuable basis for generating hypotheses on molecular disease mechanisms, and provides knowledge that can facilitate drug repurposing and the development of targeted therapeutic strategies.},
author = {Hu, Jessica Xin and Thomas, Cecilia Engel and Brunak, S{\o}ren},
doi = {10.1038/nrg.2016.87},
file = {:Users/na399/GitHub/thesis/references/papers/Hu, Thomas, Brunak{\_}2016{\_}Network biology concepts in complex disease comorbidities{\_}Nature Reviews Genetics.pdf:pdf},
isbn = {1471-0056},
issn = {14710064},
journal = {Nature Reviews Genetics},
keywords = {disease:general,model:network,rank:99,relevancy:B,topic:bioinformatics,type:review},
mendeley-tags = {disease:general,model:network,rank:99,relevancy:B,topic:bioinformatics,type:review},
number = {10},
pages = {615--629},
pmid = {27498692},
publisher = {Nature Publishing Group},
title = {{Network biology concepts in complex disease comorbidities}},
url = {http://dx.doi.org/10.1038/nrg.2016.87},
volume = {17},
year = {2016}
}
@article{Coiera2005,
abstract = {From the very earliest moments in the modern history of the computer, scientists have dreamed of creating an " electronic brain " . Of all the modern technological quests, this search to create artificially intelligent (AI) computer systems has been one of the most ambitious and, not surprisingly, controversial. It also seems that very early on, scientists and doctors alike were captivated by the potential such a technology might have in medicine (e.g. Ledley and Lusted, 1959). With intelligent computers able to store and process vast stores of knowledge, the hope was that they would become perfect 'doctors in a box', assisting or surpassing clinicians with tasks like diagnosis. With such motivations, a small but talented community of computer scientists and healthcare professionals set about shaping a research program for a new discipline called Artificial Intelligence in Medicine (AIM). These researchers had a bold vision of the way AIM would revolutionise medicine, and push forward the frontiers of technology. AI in medicine at that time was a largely US-based research community.},
author = {McCartney, Patricia R.},
doi = {10.1097/00005721-200701000-00014},
file = {:Users/na399/GitHub/thesis/references/papers/Coiera{\_}2005{\_}Clinical Decision Support Systems{\_}Guide to Health Informatics.pdf:pdf},
isbn = {9783319319117},
issn = {0361-929X},
journal = {MCN, The American Journal of Maternal/Child Nursing},
keywords = {rank:50,relevancy:C},
mendeley-tags = {rank:50,relevancy:C},
month = {jan},
number = {1},
pages = {58},
title = {{Clinical Decision Support Systems}},
url = {https://insights.ovid.com/crossref?an=00005721-200701000-00014},
volume = {32},
year = {2007}
}
@article{Rasmussen2014,
abstract = {Background: Design patterns, in the context of software development and ontologies, provide generalized approaches and guidance to solving commonly occurring problems, or addressing common situations typically informed by intuition, heuristics and experience. While the biomedical literature contains broad coverage of specific phenotype algorithm implementations, no work to date has attempted to generalize common approaches into design patterns, which may then be distributed to the informatics community to efficiently develop more accurate phenotype algorithms. Methods: Using phenotyping algorithms stored in the Phenotype KnowledgeBase (PheKB), we conducted an independent iterative review to identify recurrent elements within the algorithm definitions. We extracted and generalized recurrent elements in these algorithms into candidate patterns. The authors then assessed the candidate patterns for validity by group consensus, and annotated them with attributes. Results: A total of 24 electronic Medical Records and Genomics (eMERGE) phenotypes available in PheKB as of 1/25/2013 were downloaded and reviewed. From these, a total of 21 phenotyping patterns were identified, which are available as an online data supplement. Conclusions: Repeatable patterns within phenotyping algorithms exist, and when codified and cataloged may help to educate both experienced and novice algorithm developers. The dissemination and application of these patterns has the potential to decrease the time to develop algorithms, while improving portability and accuracy.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Rasmussen, Luke V. and Thompson, Will K. and Pacheco, Jennifer A. and Kho, Abel N. and Carrell, David S. and Pathak, Jyotishman and Peissig, Peggy L. and Tromp, Gerard and Denny, Joshua C. and Starren, Justin B.},
doi = {10.1016/j.jbi.2014.06.007},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/Rasmussen et al.{\_}2014{\_}Design patterns for the development of electronic health record-driven phenotype extraction algorithms{\_}Journal of.pdf:pdf},
isbn = {1532-0464},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Algorithms,Design patterns,Electronic health record,Phenotype,Software design,model:NLP,rank:85,relevancy:C,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {rank:85,type:research,relevancy:C,topic:EHR,topic:phenotyping,model:NLP},
pages = {280--286},
pmid = {24960203},
publisher = {Elsevier Inc.},
title = {{Design patterns for the development of electronic health record-driven phenotype extraction algorithms}},
url = {http://dx.doi.org/10.1016/j.jbi.2014.06.007},
volume = {51},
year = {2014}
}
@article{Conway2011,
abstract = {The need for formal representations of eligibility criteria for clinical trials - and for phenotyping more generally - has been recognized for some time. Indeed, the availability of a formal computable representation that adequately reflects the types of data and logic evidenced in trial designs is a prerequisite for the automatic identification of study-eligible patients from Electronic Health Records. As part of the wider process of representation development, this paper reports on an analysis of fourteen Electronic Health Record oriented phenotyping algorithms (developed as part of the eMERGE project) in terms of their constituent data elements, types of logic used and temporal characteristics. We discovered that the majority of eMERGE algorithms analyzed include complex, nested boolean logic and negation, with several dependent on cardinality constraints and complex temporal logic. Insights gained from the study will be used to augment the CDISC Protocol Representation Model.},
author = {Conway, M and Berg, R L and Carrell, D and Denny, J C and Kho, A N and Kullo, I J and Linneman, J G and Pacheco, J A and Peissig, P and Rasmussen, L and Weston, N and Chute, C G and Pathak, J},
doi = {PMC3243189},
file = {:Users/na399/GitHub/thesis/references/papers/Conway et al.{\_}2011{\_}Analyzing the heterogeneity and complexity of Electronic Health Record oriented phenotyping algorithms{\_}AMIA Annu Symp.pdf:pdf},
isbn = {1942-597X (Electronic)$\backslash$r1559-4076 (Linking)},
issn = {1942-597X},
journal = {AMIA Annu Symp Proc},
keywords = {rank:50,relevancy:C},
mendeley-tags = {rank:50,relevancy:C},
number = {January 2011},
pages = {274--283},
pmid = {22195079},
title = {{Analyzing the heterogeneity and complexity of Electronic Health Record oriented phenotyping algorithms}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22195079{\%}5Cnhttp://www.ncbi.nlm.nih.gov/pmc/articles/PMC3243189/pdf/0274{\_}amia{\_}2011{\_}proc.pdf},
volume = {2011},
year = {2011}
}
@article{Marx2017,
abstract = {Comorbidity patterns have become a major source of information to explore shared mechanisms of pathogenesis between disorders. In hypothesis-free exploration of comorbid conditions, disease-disease networks are usually identified by pairwise methods. However, interpretation of the results is hindered by several confounders. In particular a very large number of pairwise associations can arise indirectly through other comorbidity associations and they increase exponentially with the increasing breadth of the investigated diseases. To investigate and filter this effect, we computed and compared pairwise approaches with a systems-based method, which constructs a sparse Bayesian direct multimorbidity map (BDMM) by systematically eliminating disease-mediated comorbidity relations. Additionally, focusing on depression-related parts of the BDMM, we evaluated correspondence with results from logistic regression, text-mining and molecular-level measures for comorbidities such as genetic overlap and the interactome-based association score. We used a subset of the UK Biobank Resource, a cross-sectional dataset including 247 diseases and 117,392 participants who filled out a detailed questionnaire about mental health. The sparse comorbidity map confirmed that depressed patients frequently suffer from both psychiatric and somatic comorbid disorders. Notably, anxiety and obesity show strong and direct relationships with depression. The BDMM identified further directly co-morbid somatic disorders, e.g. irritable bowel syndrome, fibromyalgia, or migraine. Using the subnetwork of depression and metabolic disorders for functional analysis, the interactome-based system-level score showed the best agreement with the sparse disease network. This indicates that these epidemiologically strong disease-disease relations have improved correspondence with expected molecular-level mechanisms. The substantially fewer number of comorbidity relations in the BDMM compared to pairwise methods implies that biologically meaningful comorbid relations may be less frequent than earlier pairwise methods suggested. The computed interactive comprehensive multimorbidity views over the diseasome are available on the web at Co=MorNet: bioinformatics.mit.bme.hu/UKBNetworks.},
author = {Marx, Peter and Antal, Peter and Bolgar, Bence and Bagdy, Gyorgy and Deakin, Bill and Juhasz, Gabriella},
doi = {10.1371/journal.pcbi.1005487},
editor = {Iakoucheva, Lilia M.},
file = {:Users/na399/GitHub/thesis/references/papers/Marx et al.{\_}2017{\_}Comorbidities in the diseasome are more apparent than real What Bayesian filtering reveals about the comorbidities of d.pdf:pdf},
isbn = {1111111111},
issn = {1553-7358},
journal = {PLOS Computational Biology},
keywords = {disease:psychiatry,model:Bayesian,rank:99,relevancy:B,topic:comorbidity,type:research},
mendeley-tags = {disease:psychiatry,model:Bayesian,rank:99,relevancy:B,topic:comorbidity,type:research},
month = {jun},
number = {6},
pages = {e1005487},
pmid = {28644851},
title = {{Comorbidities in the diseasome are more apparent than real: What Bayesian filtering reveals about the comorbidities of depression}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1005487},
volume = {13},
year = {2017}
}
@article{Hofmann-Apitius2015,
abstract = {The "big data" paradigm has gained a lot of attention recently, in particular in those areas of biomedicine where we face clear unmet medical needs. Coined as a new paradigm for complex problem solving, big data approaches seem to open promising perspectives in particular for a better understanding of complex diseases such as Alzheimer's disease and other dementias. In this commentary, we will provide a brief overview on big data principles and the potential they may bring to dementia research, and - most importantly - we will do a reality check in order to provide an answer to the question of whether dementia research is ready for big data approaches.},
author = {Hofmann-Apitius, Martin},
doi = {10.1186/s12916-015-0367-7},
file = {:Users/na399/GitHub/thesis/references/papers/Hofmann-Apitius{\_}2015{\_}Is dementia research ready for big data approaches{\_}BMC Medicine.pdf:pdf},
isbn = {1291601503},
issn = {1741-7015},
journal = {BMC Medicine},
keywords = {Big data,Data interoperability,Data mining,Disease mechanisms,Disease modeling,Semantic harmonization,disease:dementia,rank:99,relevancy:B,topic:dataMining,type:commentary},
mendeley-tags = {rank:99,disease:dementia,relevancy:B,type:commentary,topic:dataMining},
month = {dec},
number = {1},
pages = {145},
pmid = {26099627},
publisher = {BMC Medicine},
title = {{Is dementia research ready for big data approaches?}},
url = {http://dx.doi.org/10.1186/s12916-015-0367-7 http://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-015-0367-7},
volume = {13},
year = {2015}
}
@article{Alexiou2017,
abstract = {Alzheimer's disease treatment is still an open problem. The diversity of symptoms, the alterations in common pathophysiology, the existence of asymptomatic cases, the different types of sporadic and familial Alzheimer's and their relevance with other types of dementia and comorbidities, have already created a myth-fear against the leading disease of the twenty first century. Many failed latest clinical trials and novel medications have revealed the early diagnosis as the most critical treatment solution, even though scientists tested the amyloid hypothesis and few related drugs. Unfortunately, latest studies have indicated that the disease begins at the very young ages thus making it difficult to determine the right time of proper treatment. By taking into consideration all these multivariate aspects and unreliable factors against an appropriate treatment, we focused our research on a non-classic statistical evaluation of the most known and accepted Alzheimer's biomarkers. Therefore, in this paper, the code and few experimental results of a computational Bayesian tool have being reported, dedicated to the correlation and assessment of several Alzheimer's biomarkers to export a probabilistic medical prognostic process. This new statistical software is executable in the Bayesian software Winbugs, based on the latest Alzheimer's classification and the formulation of the known relative probabilities of the various biomarkers, correlated with Alzheimer's progression, through a set of discrete distributions. A user-friendly web page has been implemented for the supporting of medical doctors and researchers, to upload Alzheimer's tests and receive statistics on the occurrence of Alzheimer's disease development or presence, due to abnormal testing in one or more biomarkers.},
annote = {flawed paper},
author = {Alexiou, Athanasios and Mantzavinos, Vasileios D. and Greig, Nigel H. and Kamal, Mohammad A.},
doi = {10.3389/fnagi.2017.00077},
file = {:Users/na399/Downloads/Research Papers/Alexiou et al.{\_}2017{\_}A Bayesian model for the prediction and early diagnosis of Alzheimer's disease{\_}Frontiers in Aging Neuroscience.pdf:pdf},
isbn = {1663-4365},
issn = {16634365},
journal = {Frontiers in Aging Neuroscience},
keywords = {Alzheimer's disease,Bayesian statistics,Early diagnosis,Gibbs sampling,Markov chain monte carlo,Medical decision systems,Metropolis-hastings algorithm,Winbugs,disease:dementia,model:Bayesian,rank:90,relevancy:A,topic:prediction,type:research},
mendeley-tags = {disease:dementia,model:Bayesian,rank:90,relevancy:A,topic:prediction,type:research},
number = {MAR},
pages = {1--14},
pmid = {28408880},
title = {{A Bayesian model for the prediction and early diagnosis of Alzheimer's disease}},
volume = {9},
year = {2017}
}
@article{Rabin2017,
author = {Rabin, Laura A and Smart, Colette M and Amariglio, Rebecca E},
doi = {https://doi.org/10.1146/annurev-clinpsy-032816-045136},
file = {:Users/na399/GitHub/thesis/references/papers/Rabin, Smart, Amariglio{\_}2017{\_}Subjective Cognitive Decline in Preclinical Alzheimer's Disease{\_}Annual review of psychology.pdf:pdf},
journal = {Annual review of psychology},
keywords = {cognitive complaints,dementia,disease:dementia,early detection,impairment,mild cognitive,preclinical alzheimer,rank:99,relevancy:C,s disease,subjective cognitive decline,topic:diagnosis,type:review},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:diagnosis,type:review},
pages = {369--96},
title = {{Subjective Cognitive Decline in Preclinical Alzheimer's Disease}},
volume = {13},
year = {2017}
}
@article{Saykin2010,
abstract = {The role of the Alzheimer's Disease Neuroimaging Initiative Genetics Core is to facilitate the investigation of genetic influences on disease onset and trajectory as reflected in structural, functional, and molecular imaging changes; fluid biomarkers; and cognitive status. Major goals include (1) blood sample processing, genotyping, and dissemination, (2) genome-wide association studies (GWAS) of longitudinal phenotypic data, and (3) providing a central resource, point of contact and planning group for genetics within the Alzheimer's Disease Neuroimaging Initiative. Genome-wide array data have been publicly released and updated, and several neuroimaging GWAS have recently been reported examining baseline magnetic resonance imaging measures as quantitative phenotypes. Other preliminary investigations include copy number variation in mild cognitive impairment and Alzheimer's disease and GWAS of baseline cerebrospinal fluid biomarkers and longitudinal changes on magnetic resonance imaging. Blood collection for RNA studies is a new direction. Genetic studies of longitudinal phenotypes hold promise for elucidating disease mechanisms and risk, development of therapeutic strategies, and refining selection criteria for clinical trials. {\textcopyright} 2010 The Alzheimer's Association. All rights reserved.},
author = {Saykin, Andrew J. and Shen, Li and Foroud, Tatiana M. and Potkin, Steven G. and Swaminathan, Shanker and Kim, Sungeun and Risacher, Shannon L. and Nho, Kwangsik and Huentelman, Matthew J. and Craig, David W. and Thompson, Paul M. and Stein, Jason L. and Moore, Jason H. and Farrer, Lindsay A. and Green, Robert C. and Bertram, Lars and Jack, Clifford R. and Weiner, Michael W.},
doi = {10.1016/j.jalz.2010.03.013},
file = {:Users/na399/GitHub/thesis/references/papers/Saykin et al.{\_}2010{\_}Alzheimer's Disease Neuroimaging Initiative biomarkers as quantitative phenotypes Genetics core aims, progress, and p.pdf:pdf},
isbn = {1552-5279 (Electronic)$\backslash$n1552-5260 (Linking)},
issn = {15525260},
journal = {Alzheimer's and Dementia},
keywords = {Alzheimer's Disease Neuroimaging Initiative (ADNI),Alzheimer's disease,Cerebrospinal fluid (CSF),Copy number variation (CNV),Genome-wide association studies (GWAS),Magnetic resonance imaging (MRI),Mild cognitive impairment (MCI),disease:dementia,rank:99,relevancy:C,topic:GWAS,type:review},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:GWAS,type:review},
number = {3},
pages = {265--273},
pmid = {20451875},
publisher = {Elsevier Ltd},
title = {{Alzheimer's Disease Neuroimaging Initiative biomarkers as quantitative phenotypes: Genetics core aims, progress, and plans}},
url = {http://dx.doi.org/10.1016/j.jalz.2010.03.013},
volume = {6},
year = {2010}
}
@article{Lopez-Campos2016,
abstract = {CONTACT: guillermo.lopez@unimelb.edu.au.},
author = {Lopez-Campos, Guillermo H. and Martin-Sanchez, Fernando and Gray, Kathleen},
doi = {10.1093/bioinformatics/btw078},
file = {:Users/na399/GitHub/thesis/references/papers/Lopez-Campos, Martin-Sanchez, Gray{\_}2016{\_}Comment on 'Discovering hospital admission patterns using models learnt from electronic hospital.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
keywords = {disease:general,model:Bayesian,model:Markov,rank:99,relevancy:A,topic:EHR,topic:comorbidity,topic:prediction,type:commentary},
mendeley-tags = {disease:general,model:Bayesian,model:Markov,rank:99,relevancy:A,topic:EHR,topic:comorbidity,topic:prediction,type:commentary},
number = {13},
pages = {2079--2080},
pmid = {27153706},
title = {{Comment on 'Discovering hospital admission patterns using models learnt from electronic hospital records'. the importance of using the right codes}},
volume = {32},
year = {2016}
}
@article{Larner2004,
abstract = {Two patients whose diagnosis of Alzheimer's disease proved to be incorrect on follow-up are presented. Factors which contributed to the misdiagnosis included failure to obtain collateral history, failure to apply widely accepted diagnostic criteria, over-reliance on structural brain imaging and lack of longitudinal follow-up. Analysis of diagnostic errors may permit avoidance of similar pitfalls in future.},
author = {Larner, A. J.},
doi = {10.1111/j.1368-5031.2004.00314.x},
file = {:Users/na399/GitHub/thesis/references/papers/Larner{\_}2004{\_}Getting it wrong The clinical misdiagnosis of Alzheimer's disease{\_}International Journal of Clinical Practice.pdf:pdf},
isbn = {1351-5101},
issn = {13685031},
journal = {International Journal of Clinical Practice},
keywords = {Alzheimer's disease,Dementia,Diagnosis,disease:dementia,rank:80,relevancy:A},
mendeley-tags = {rank:80,relevancy:A,disease:dementia},
number = {11},
pages = {1092--1094},
pmid = {15605679},
title = {{Getting it wrong: The clinical misdiagnosis of Alzheimer's disease}},
volume = {58},
year = {2004}
}
@article{Walsh2017,
abstract = {Objective: Large database research in axial spondyloarthritis (SpA) is limited by a lack of methods for identifying most types of axial SpA. Our objective was to develop methods for identifying axial SpA concepts in the free text of documents from electronic medical records. Methods: Veterans with documents in the national Veterans Health Administration Corporate Data Warehouse between January 1, 2005 and June 30, 2015 were included. Methods were developed for exploring, selecting, and extracting meaningful terms that were likely to represent axial SpA concepts. With annotation, clinical experts reviewed sections of text containing the meaningful terms (snippets) and classified the snippets according to whether or not they represented the intended axial SpA concept. With natural language processing (NLP) tools, computers were trained to replicate the clinical experts' snippet classifications. Results: Three axial SpA concepts were selected by clinical experts, including sacroiliitis, terms including the prefix spond*, and HLA-B27 positivity (HLA-B27+). With supervised machine learning on annotated snippets, NLP models were developed with accuracies of 91.1{\%} for sacroiliitis, 93.5{\%} for spond*, and 97.2{\%} for HLA-B27+. With independent validation, the accuracies were 92.0{\%} for sacroiliitis, 91.0{\%} for spond*, and 99.0{\%} for HLA-B27+. Conclusion: We developed feasible and accurate methods for identifying axial SpA concepts in the free text of clinical notes. Additional research is required to determine combinations of concepts that will accurately identify axial SpA phenotypes. These novel methods will facilitate previously impractical observational research in axial SpA and may be applied to research with other diseases.Copyright {\textcopyright} 2016, American College of Rheumatology},
author = {Walsh, Jessica A. and Shao, Yijun and Leng, Jianwei and He, Tao and Teng, Chia Chen and Redd, Doug and {Treitler Zeng}, Qing and Burningham, Zachary and Clegg, Daniel O. and Sauer, Brian C.},
doi = {10.1002/acr.23140},
file = {:Users/na399/GitHub/thesis/references/papers/Walsh et al.{\_}2017{\_}Identifying Axial Spondyloarthritis in Electronic Medical Records of US Veterans{\_}Arthritis Care and Research.pdf:pdf},
issn = {21514658},
journal = {Arthritis Care and Research},
keywords = {disease:inflammatory,model:NLP,rank:85,relevancy:C,topic:EHR,topic:diagnosis,type:research},
mendeley-tags = {rank:85,disease:inflammatory,type:research,topic:EHR,topic:diagnosis,relevancy:C,model:NLP},
number = {9},
pages = {1414--1420},
pmid = {27813310},
title = {{Identifying Axial Spondyloarthritis in Electronic Medical Records of US Veterans}},
volume = {69},
year = {2017}
}
@article{Vasiljeva2017,
author = {Vasiljeva, Ieva and Arandjelovi{\'{c}}, Ognjen},
doi = {10.1089/cmb.2017.0023},
file = {:Users/na399/GitHub/thesis/references/papers/Vasiljeva, Arandjelovi{\'{c}}{\_}2017{\_}Diagnosis Prediction from Electronic Health Records Using the Binary Diagnosis History Vector Representati.pdf:pdf},
issn = {1557-8666},
journal = {Journal of Computational Biology},
keywords = {bayesian,disease,electronic medical records,emrs,epidemiology,rank:80,relevancy:A,risk},
mendeley-tags = {rank:80,relevancy:A},
number = {8},
pages = {767--786},
title = {{Diagnosis Prediction from Electronic Health Records Using the Binary Diagnosis History Vector Representation}},
url = {http://online.liebertpub.com/doi/10.1089/cmb.2017.0023},
volume = {24},
year = {2017}
}
@article{Koola2018,
abstract = {OBJECTIVE Hepatorenal Syndrome (HRS) is a devastating form of acute kidney injury (AKI) in advanced liver disease patients with high morbidity and mortality, but phenotyping algorithms have not yet been developed using large electronic health record (EHR) databases. We evaluated and compared multiple phenotyping methods to achieve an accurate algorithm for HRS identification. MATERIALS AND METHODS A national retrospective cohort of patients with cirrhosis and AKI admitted to 124 Veterans Affairs hospitals was assembled from electronic health record data collected from 2005 to 2013. AKI was defined by the Kidney Disease: Improving Global Outcomes criteria. Five hundred and four hospitalizations were selected for manual chart review and served as the gold standard. Electronic Health Record based predictors were identified using structured and free text clinical data, subjected through NLP from the clinical Text Analysis Knowledge Extraction System. We explored several dimension reduction techniques for the NLP data, including newer high-throughput phenotyping and word embedding methods, and ascertained their effectiveness in identifying the phenotype without structured predictor variables. With the combined structured and NLP variables, we analyzed five phenotyping algorithms: penalized logistic regression, na{\"{i}}ve Bayes, support vector machines, random forest, and gradient boosting. Calibration and discrimination metrics were calculated using 100 bootstrap iterations. In the final model, we report odds ratios and 95{\%} confidence intervals. RESULTS The area under the receiver operating characteristic curve (AUC) for the different models ranged from 0.73 to 0.93; with penalized logistic regression having the best discriminatory performance. Calibration for logistic regression was modest, but gradient boosting and support vector machines were superior. NLP identified 6985 variables; a priori variable selection performed similarly to dimensionality reduction using high-throughput phenotyping and semantic similarity informed clustering (AUC of 0.81 - 0.82). CONCLUSION This study demonstrated improved phenotyping of a challenging AKI etiology, HRS, over ICD-9 coding. We also compared performance among multiple approaches to EHR-derived phenotyping, and found similar results between methods. Lastly, we showed that automated NLP dimension reduction is viable for acute illness.},
author = {Koola, Jejo D. and Davis, Sharon E. and Al-Nimri, Omar and Parr, Sharidan K. and Fabbri, Daniel and Malin, Bradley A. and Ho, Samuel B. and Matheny, Michael E.},
doi = {10.1016/j.jbi.2018.03.001},
file = {:Users/na399/GitHub/thesis/references/papers/Koola et al.{\_}2018{\_}Development of an automated phenotyping algorithm for hepatorenal syndrome{\_}Journal of Biomedical Informatics.pdf:pdf},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {acute kidney injury,cirrhosis,dimension reduction,hepatorenal syndrome,model:NLP,model:SVM,model:logisticRegression,natural language processing,phenotyping,rank:85,relevancy:C,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {rank:85,relevancy:C,type:research,model:NLP,model:SVM,topic:EHR,topic:phenotyping,model:logisticRegression},
number = {July 2017},
pages = {87--95},
pmid = {29530803},
publisher = {Elsevier},
title = {{Development of an automated phenotyping algorithm for hepatorenal syndrome}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/29530803{\%}0Ahttp://linkinghub.elsevier.com/retrieve/pii/S153204641830039X},
volume = {80},
year = {2018}
}
@article{Lichtenberg2012,
abstract = {The intense focus on Alzheimer's disease has led even experienced practitioners to misdiagnose older adults' cognitive impairment as Alzheimer's. The impact of misdiagnosis may be greatest in cases of capacity, especially conservatorship and testamentary capacity. Two case examples are presented, with an emphasis on diagnostic issues and the importance of accurate diagnosis in light of increasing cases of cognitive dysfunction in older adults. In the first case, issues of delirium and frailty were misdiagnosed as Alzheimer's disease, while in the second case, overreliance on family report and a lack of cultural competency caused a woman with mild cognitive impairment (executive functioning type) to be diagnosed with moderate Alzheimer's disease. As the older adult population grows, clinical gerontologists will continue to be called on to assess capacity, and accurate diagnosis is essential for accurate assessment.},
author = {Lichtenberg, Peter A.},
doi = {10.1080/07317115.2011.626516},
file = {:Users/na399/GitHub/thesis/references/papers/Lichtenberg{\_}2012{\_}Misdiagnosis of Alzheimer's Disease Case Studies in Capacity Assessment{\_}Clinical Gerontologist.pdf:pdf},
isbn = {Clinical Gerontologist, Vol. 35, No. 1, January-February 2012: pp. 42–56},
issn = {07317115},
journal = {Clinical Gerontologist},
keywords = {Alzheimer's disease,capacity,misdiagnosis,rank:60,relevancy:C},
mendeley-tags = {rank:60,relevancy:C},
number = {1},
pages = {42--56},
title = {{Misdiagnosis of Alzheimer's Disease: Case Studies in Capacity Assessment}},
volume = {35},
year = {2012}
}
@article{Fan2015,
abstract = {The purpose of this study is to leverage modern technology (such as mobile or web apps in Beckman et al. (2014)) to enrich epidemiology data and infer the transmission of disease. Homogeneity related research on population level has been intensively studied in previous work. In contrast, we develop hierarchical Graph-Coupled Hidden Markov Models (hGCHMMs) to simultaneously track the spread of infection in a small cell phone community and capture person-specific infection parameters by leveraging a link prior that incorporates additional covariates. We also reexamine the model evolution of the hGCHMM from simple HMMs and LDA, elucidating additional flexibility and interpretability. Due to the non-conjugacy of sparsely coupled HMMs, we design a new approximate distribution, allowing our approach to be more applicable to other application areas. Additionally, we investigate two common link functions, the beta-exponential prior and sigmoid function, both of which allow the development of a principled Bayesian hierarchical framework for disease transmission. The results of our model allow us to predict the probability of infection for each person on each day, and also to infer personal physical vulnerability and the relevant association with covariates. We demonstrate our approach experimentally on both simulation data and real epidemiological records.},
archivePrefix = {arXiv},
arxivId = {1509.00110},
author = {Fan, Kai and Aiello, Allison E. and Heller, Katherine A.},
eprint = {1509.00110},
file = {:Users/na399/GitHub/thesis/references/papers/Fan, Aiello, Heller{\_}2015{\_}Bayesian Models for Heterogeneous Personalized Health Data{\_}Unknown.pdf:pdf},
keywords = {dynamic bayesian modeling,flu diffusion,message pass-,rank:n/a,relevancy:B,social networks},
mendeley-tags = {rank:n/a,relevancy:B},
month = {aug},
pages = {1--35},
title = {{Bayesian Models for Heterogeneous Personalized Health Data}},
url = {http://arxiv.org/abs/1509.00110},
volume = {1},
year = {2015}
}
@article{Forkan2017,
abstract = {The advance in wearable and wireless sensors technology have made it possible to monitor multiple vital signs (e.g. heart rate, blood pressure) of a patient anytime, anywhere. Vital signs are an essential part of daily monitoring and disease prevention. When multiple vital sign data from many patients are accumulated for a long period they evolve into big data. The objective of this study is to build a prognostic model, ViSiBiD, that can accurately identify dangerous clinical events of a home-monitoring patient in advance using knowledge learned from the patterns of multiple vital signs from a large number of similar patients. We developed an innovative technique that amalgamates existing data mining methods with smartly extracted features from vital sign correlations, and demonstrated its effectiveness on cloud platforms through comparative evaluations that showed its potential to become a new tool for predictive healthcare. Four clinical events are identified from 4893 patient records in publicly available databases where six bio-signals deviate from normality and different features are extracted prior to 1–2 h from 10 to 30 min observed data of those events. Known data mining algorithms along with some MapReduce implementations have been used for learning on a cloud platform. The best accuracy (95.85{\%}) was obtained through a Random Forest classifier using all features. The encouraging learning performance using hybrid feature space proves the existence of discriminatory patterns in vital sign big data can identify severe clinical danger well ahead of time.},
author = {Forkan, Abdur Rahim Mohammad and Khalil, Ibrahim and Atiquzzaman, Mohammed},
doi = {10.1016/j.comnet.2016.12.019},
file = {:Users/na399/GitHub/thesis/references/papers/Forkan, Khalil, Atiquzzaman{\_}2017{\_}ViSiBiD A learning model for early discovery and real-time prediction of severe clinical events using v.pdf:pdf},
isbn = {1389-1286},
issn = {13891286},
journal = {Computer Networks},
keywords = {Big data,Cloud computing,Correlations,Data mining,Knowledge discovery,Vital sign,model:tree,rank:85,relevancy:C,topic:prediction},
mendeley-tags = {rank:85,model:tree,relevancy:C,topic:prediction},
pages = {244--257},
publisher = {Elsevier B.V.},
title = {{ViSiBiD: A learning model for early discovery and real-time prediction of severe clinical events using vital signs as big data}},
url = {http://dx.doi.org/10.1016/j.comnet.2016.12.019},
volume = {113},
year = {2017}
}
@article{Wiens2018,
abstract = {The increasing availability of electronic health data presents a major opportunity in healthcare for both discovery and practical applications to improve healthcare. However, for healthcare epidemiologists to best use these data, computational techniques that can handle large complex datasets are required. Machine learning (ML), the study of tools and methods for identifying patterns in data, can help. The appropriate application of ML to these data promises to transform patient risk stratification broadly in the field of medicine and especially in infectious diseases. This, in turn, could lead to targeted interventions that reduce the spread of healthcare-associated pathogens. In this review, we begin with an introduction to the basics of ML. We then move on to discuss how ML can transform healthcare epidemiology, providing examples of successful applications. Finally, we present special considerations for those healthcare epidemiologists who want to use and apply ML.},
author = {Wiens, Jenna and Shenoy, Erica S.},
doi = {10.1093/cid/cix731},
file = {:Users/na399/GitHub/thesis/references/papers/Wiens, Shenoy{\_}2018{\_}Machine Learning for Healthcare On the Verge of a Major Shift in Healthcare Epidemiology{\_}Clinical Infectious Diseases.pdf:pdf},
isbn = {1058-4838},
issn = {15376591},
journal = {Clinical Infectious Diseases},
keywords = {Machine learning,computation,data-driven,healthcare epidemiologist,patient risk stratification,rank:95,relevancy:A,topic:ML,type:analysis},
mendeley-tags = {rank:95,relevancy:A,topic:ML,type:analysis},
number = {1},
pages = {149--153},
pmid = {29020316},
title = {{Machine Learning for Healthcare: On the Verge of a Major Shift in Healthcare Epidemiology}},
volume = {66},
year = {2018}
}
@inproceedings{Popescu2011,
abstract = {Many older adults in the US prefer to live independently for as long as they are able, despite the onset of conditions such as frailty and dementia. Sensor networks have emerged in the last decade, together with telehealth and internet based electronic health records (EHR), as a possible solution to older adult health monitoring. Many commercial solutions for EHRs, telehealth monitoring and sensor networks are available but, as far as we know, no integrated system exists. In this paper we present an integrated eldercare EHR system (IEEHR) that merges health data with sensor and telehealth (vital signs) measurements. The benefit of an EEHR system is three fold: provides physicians a wider gamut of tools for chronic disease management, reduces nursing workload and allows the development of health context aware algorithms for predictive health assessment. In this paper we present the integrated EEHR system we are developing at TigerPlace, an assisted living community in Columbia, Missouri. Several examples of possible applications are also presented. 2011 IEEE.},
author = {Popescu, Mihail and Chronis, George and Ohol, Rohan and Skubic, Marjorie and Rantz, Marilyn},
booktitle = {2011 IEEE 13th International Conference on e-Health Networking, Applications and Services},
doi = {10.1109/HEALTH.2011.6026742},
file = {:Users/na399/GitHub/thesis/references/papers/Popescu et al.{\_}2011{\_}An eldercare electronic health record system for predictive health assessment{\_}2011 IEEE 13th International Conferenc.pdf:pdf},
isbn = {978-1-61284-695-8},
keywords = {Diseases,Health,Medical computing,Monitoring,Rating,Records management,Sensor networks,Sensors,Telemedicine,rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
month = {jun},
pages = {193--196},
publisher = {IEEE},
title = {{An eldercare electronic health record system for predictive health assessment}},
url = {http://dx.doi.org/10.1109/HEALTH.2011.6026742 http://ieeexplore.ieee.org/document/6026742/},
year = {2011}
}
@incollection{Marx2015,
abstract = {The use of multiple diseases and complex phenotypic descriptors is a new$\backslash$ntrend of genetic association analysis, motivated by the pathway diseases$\backslash$nand network medicine paradigms. Comorbidity information is an important$\backslash$nresource in this exploration of shared molecular background. To extend$\backslash$nthe current pairwise, correlation based methods, we investigate a$\backslash$nsystems-based approach for the use of separated large-scale$\backslash$nmulti-morbidity data to explore common latent factors of related$\backslash$ndiseases. We constructed a multi-morbidity dataset from the UK Biobank$\backslash$nby filtering rare diseases. In the first phase of our method, we use a$\backslash$nMarkov Chain Monte Carlo method over Bayesian networks to construct a$\backslash$nBayesian dependency map, which is confounded with many known factors. In$\backslash$nthe second phase, the method could incorporate prior causal information$\backslash$nbetween the diseases and information about the known confounding by$\backslash$ndemographic, medical, genetic, environmental factors. The difference$\backslash$nbetween the known causal and confounding relations and the observed$\backslash$ndependencies is used to bind the extent of further latent factors. This$\backslash$nreconstruction of the shared latent factors happens hierarchically in a$\backslash$ntop-down fashion, terminating with the identification of latent factors$\backslash$nfor pair of diseases. We compare our method with other comorbidity$\backslash$nmethods and systems-based network approaches in the field of psychiatry,$\backslash$nfocusing on depression and anxiety. We demonstrate the use of molecular,$\backslash$nsymptomatic and environmental knowledge bases to interpret the$\backslash$nreconstructed latent factors. This research has been conducted using the$\backslash$nUK Biobank Resource.},
address = {Singapore},
author = {Marx, P. and Antal, P.},
booktitle = {IFMBE Proceedings},
doi = {10.1007/978-981-287-573-0_10},
editor = {Jobb{\'{a}}gy, {\'{A}}kos},
file = {:Users/na399/GitHub/thesis/references/papers/Marx, Antal{\_}2015{\_}Decomposition of shared latent factors using Bayesian multi-morbidity dependency maps{\_}IFMBE Proceedings.pdf:pdf},
isbn = {9789812875723},
issn = {16800737},
keywords = {Bayesian networks,Confounding,Monte carlo methods,Multi-morbidity,rank:10,relevancy:B},
mendeley-tags = {rank:10,relevancy:B},
pages = {40--43},
publisher = {Springer Singapore},
series = {IFMBE Proceedings},
title = {{Decomposition of Shared Latent Factors Using Bayesian Multi-morbidity Dependency Maps}},
url = {http://link.springer.com/10.1007/978-981-287-573-0 http://link.springer.com/10.1007/978-981-287-573-0{\_}10},
volume = {50},
year = {2015}
}
@article{Mooney2016,
abstract = {Aging research is undergoing a paradigm shift, which has led to new and inno- vative methods of exploring this complex phenomenon. The systems biology approach endeavors to understand biological systems in a holistic manner, by taking account of intrinsic interactions, while also attempting to account for the impact of external inputs, such as diet. A key technique employed in systems biology is computational modeling, which involves mathematically describing and simulating the dynamics of biological systems. Although a large number of computational models have been developed in recent years, these models have focused on various discrete components of the aging process, and to date no model has succeeded in completely representing the full scope of aging. Com- bining existing models or developing new models may help to address this need and in so doing could help achieve an improved understanding of the intrinsic mechanisms which underpin aging.},
author = {Mooney, Kathleen M. and Morgan, Amy E. and {Mc Auley}, Mark T.},
doi = {10.1002/wsbm.1328},
file = {:Users/na399/Downloads/Research Papers/Mooney, Morgan, Mc Auley{\_}2016{\_}Aging and computational systems biology{\_}Wiley Interdisciplinary Reviews Systems Biology and Medicine.pdf:pdf},
issn = {19395094},
journal = {Wiley Interdisciplinary Reviews: Systems Biology and Medicine},
keywords = {disease:dementia,rank:80,relevancy:C},
mendeley-tags = {rank:80,relevancy:C,disease:dementia},
month = {mar},
number = {2},
pages = {123--139},
pmid = {28096317},
title = {{Aging and computational systems biology}},
url = {http://doi.wiley.com/10.1002/wsbm.1328},
volume = {8},
year = {2016}
}
@article{Yu2015,
abstract = {OBJECTIVE Analysis of narrative (text) data from electronic health records (EHRs) can improve population-scale phenotyping for clinical and genetic research. Currently, selection of text features for phenotyping algorithms is slow and laborious, requiring extensive and iterative involvement by domain experts. This paper introduces a method to develop phenotyping algorithms in an unbiased manner by automatically extracting and selecting informative features, which can be comparable to expert-curated ones in classification accuracy. MATERIALS AND METHODS Comprehensive medical concepts were collected from publicly available knowledge sources in an automated, unbiased fashion. Natural language processing (NLP) revealed the occurrence patterns of these concepts in EHR narrative notes, which enabled selection of informative features for phenotype classification. When combined with additional codified features, a penalized logistic regression model was trained to classify the target phenotype. RESULTS The authors applied our method to develop algorithms to identify patients with rheumatoid arthritis and coronary artery disease cases among those with rheumatoid arthritis from a large multi-institutional EHR. The area under the receiver operating characteristic curves (AUC) for classifying RA and CAD using models trained with automated features were 0.951 and 0.929, respectively, compared to the AUCs of 0.938 and 0.929 by models trained with expert-curated features. DISCUSSION Models trained with NLP text features selected through an unbiased, automated procedure achieved comparable or slightly higher accuracy than those trained with expert-curated features. The majority of the selected model features were interpretable. CONCLUSION The proposed automated feature extraction method, generating highly accurate phenotyping algorithms with improved efficiency, is a significant step toward high-throughput phenotyping.},
author = {Yu, Sheng and Liao, Katherine P. and Shaw, Stanley Y. and Gainer, Vivian S. and Churchill, Susanne E. and Szolovits, Peter and Murphy, Shawn N. and Kohane, Isaac S. and Cai, Tianxi},
doi = {10.1093/jamia/ocv034},
file = {:Users/na399/GitHub/thesis/references/papers/Yu et al.{\_}2015{\_}Toward high-throughput phenotyping Unbiased automated feature extraction and selection from knowledge sources{\_}Journal of.pdf:pdf},
isbn = {1527974X (Electronic)},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {model:NLP,rank:90,relevancy:C,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {model:NLP,rank:90,relevancy:C,topic:EHR,topic:phenotyping,type:research},
number = {5},
pages = {993--1000},
pmid = {25929596},
title = {{Toward high-throughput phenotyping: Unbiased automated feature extraction and selection from knowledge sources}},
volume = {22},
year = {2015}
}
@article{Vardy2006,
abstract = {Despite decades of intense research, therapeutics for Alzheimer's disease (AD) are still limited to symptomatic treatments that possess only short-term efficacy. Recently, several large-scale Phase III trials targeting amyloid-$\beta$ production or clearance have failed to show efficacy, leading to a reexami-nation of the amyloid hypothesis as well as highlighting the need to explore alternatives in both clinical testing strategies and drug discovery targets. In this review, we discuss therapeutics currently being tested in clinical trials and up-and-coming interventions that have shown promise in animal models, devoting attention to the mechanisms that may underlie their ability to influ-ence disease progression and placing particular emphasis on tau therapeutics.},
author = {Vardy, Emma R L C and Hussain, Ishrut and Hooper, Nigel M.},
doi = {10.1586/14737175.6.5.695},
file = {:Users/na399/GitHub/thesis/references/papers/Vardy, Hussain, Hooper{\_}2006{\_}Emerging therapeutics for Alzheimer's disease{\_}Expert Review of Neurotherapeutics.pdf:pdf},
isbn = {1545-4304 (Electronic)$\backslash$r0362-1642 (Linking)},
issn = {14737175},
journal = {Expert Review of Neurotherapeutics},
keywords = {Amyloid,Immunization,Inflammation,Insulin degrading enzyme,Neprilysin,Neurofibrillary tangle,Secretase,Tau,Therapeutics,disease:dementia,rank:80,relevancy:C},
mendeley-tags = {rank:80,relevancy:C,disease:dementia},
number = {5},
pages = {695--704},
pmid = {24392696},
title = {{Emerging therapeutics for Alzheimer's disease}},
volume = {6},
year = {2006}
}
@article{Wellner2017,
abstract = {BACKGROUND Early warning scores aid in the detection of pediatric clinical deteriorations but include limited data inputs, rarely include data trends over time, and have limited validation. OBJECTIVE Machine learning methods that make use of large numbers of predictor variables are now commonplace. This work examines how different types of predictor variables derived from the electronic health record affect the performance of predicting unplanned transfers to the intensive care unit (ICU) at three large children's hospitals. METHODS We trained separate models with data from three different institutions from 2011 through 2013 and evaluated models with 2014 data. Cases consisted of patients who transferred from the floor to the ICU and met one or more of 5 different priori defined criteria for suspected unplanned transfers. Controls were patients who were never transferred to the ICU. Predictor variables for the models were derived from vitals, labs, acuity scores, and nursing assessments. Classification models consisted of L1 and L2 regularized logistic regression and neural network models. We evaluated model performance over prediction horizons ranging from 1 to 16 hours. RESULTS Across the three institutions, the c-statistic values for our best models were 0.892 (95{\%} CI 0.875-0.904), 0.902 (95{\%} CI 0.880-0.923), and 0.899 (95{\%} CI 0.879-0.919) for the task of identifying unplanned ICU transfer 6 hours before its occurrence and achieved 0.871 (95{\%} CI 0.855-0.888), 0.872 (95{\%} CI 0.850-0.895), and 0.850 (95{\%} CI 0.825-0.875) for a prediction horizon of 16 hours. For our first model at 80{\%} sensitivity, this resulted in a specificity of 80.5{\%} (95{\%} CI 77.4-83.7) and a positive predictive value of 5.2{\%} (95{\%} CI 4.5-6.2). CONCLUSIONS Feature-rich models with many predictor variables allow for patient deterioration to be predicted accurately, even up to 16 hours in advance.},
author = {Wellner, Ben and Grand, Joan and Canzone, Elizabeth and Coarr, Matt and Brady, Patrick W and Simmons, Jeffrey and Kirkendall, Eric and Dean, Nathan and Kleinman, Monica and Sylvester, Peter},
doi = {10.2196/medinform.8680},
file = {:Users/na399/GitHub/thesis/references/papers/Wellner et al.{\_}2017{\_}Predicting Unplanned Transfers to the Intensive Care Unit A Machine Learning Approach Leveraging Diverse Clinical El.pdf:pdf},
issn = {2291-9694},
journal = {JMIR Medical Informatics},
keywords = {2017,4,clinical deterioration,clinical laboratory techniques,data mining,e45,electronic health record,http,jmir,machine learning,medinform,nursing assessment,org,patient acuity,rank:n/a,relevancy:C,vital signs},
mendeley-tags = {rank:n/a,relevancy:C},
month = {nov},
number = {4},
pages = {e45},
pmid = {29167089},
title = {{Predicting Unplanned Transfers to the Intensive Care Unit: A Machine Learning Approach Leveraging Diverse Clinical Elements}},
url = {http://medinform.jmir.org/2017/4/e45/},
volume = {5},
year = {2017}
}
@article{Ellinghaus2016,
abstract = {We simultaneously investigated the genetic landscape of ankylosing spondylitis, Crohn's disease, psoriasis, primary sclerosing cholangitis and ulcerative colitis to investigate pleiotropy and the relationship between these clinically related diseases. Using high-density genotype data from more than 86,000 individuals of European ancestry, we identified 244 independent multidisease signals, including 27 new genome-wide significant susceptibility loci and 3 unreported shared risk loci. Complex pleiotropy was supported when contrasting multidisease signals with expression data sets from human, rat and mouse together with epigenetic and expressed enhancer profiles. The comorbidities among the five immune diseases were best explained by biological pleiotropy rather than heterogeneity (a subgroup of cases genetically identical to those with another disease, possibly owing to diagnostic misclassification, molecular subtypes or excessive comorbidity). In particular, the strong comorbidity between primary sclerosing cholangitis and inflammatory bowel disease is likely the result of a unique disease, which is genetically distinct from classical inflammatory bowel disease phenotypes.},
author = {Ellinghaus, David and Jostins, Luke and Spain, Sarah L. and Cortes, Adrian and Bethune, J{\"{o}}rn and Han, Buhm and Park, Yu Rang and Raychaudhuri, Soumya and Pouget, Jennie G. and H{\"{u}}benthal, Matthias and Folseraas, Trine and Wang, Yunpeng and Esko, Tonu and Metspalu, Andres and Westra, Harm Jan and Franke, Lude and Pers, Tune H. and Weersma, Rinse K. and Collij, Valerie and D'Amato, Mauro and Halfvarson, Jonas and Jensen, Anders Boeck and Lieb, Wolfgang and Degenhardt, Franziska and Forstner, Andreas J. and Hofmann, Andrea and Schreiber, Stefan and Mrowietz, Ulrich and Juran, Brian D. and Lazaridis, Konstantinos N. and Brunak, S{\O}ren and Dale, Anders M. and Trembath, Richard C. and Weidinger, Stephan and Weichenthal, Michael and Ellinghaus, Eva and Elder, James T. and Barker, Jonathan N.W.N. and Andreassen, Ole A. and McGovern, Dermot P. and Karlsen, Tom H. and Barrett, Jeffrey C. and Parkes, Miles and Brown, Matthew A. and Franke, Andre},
doi = {10.1038/ng.3528},
file = {:Users/na399/GitHub/thesis/references/papers/Ellinghaus et al.{\_}2016{\_}Analysis of five chronic inflammatory diseases identifies 27 new associations and highlights disease-specific pat.pdf:pdf},
isbn = {1546-1718 (Electronic)$\backslash$r1061-4036 (Linking)},
issn = {15461718},
journal = {Nature Genetics},
keywords = {disease:inflammatory,rank:99,relevancy:C,topic:GWAS,topic:bioinformatics,type:research},
mendeley-tags = {disease:inflammatory,rank:99,relevancy:C,topic:GWAS,topic:bioinformatics,type:research},
number = {5},
pages = {510--518},
pmid = {26974007},
title = {{Analysis of five chronic inflammatory diseases identifies 27 new associations and highlights disease-specific patterns at shared loci}},
volume = {48},
year = {2016}
}
@article{Kingdom2017a,
author = {Blecker, Saul and Katz, Stuart D. and Horwitz, Leora I. and Kuperman, Gilad and Park, Hannah and Gold, Alex and Sontag, David},
doi = {10.1001/jamacardio.2016.3236},
file = {:Users/na399/GitHub/thesis/references/papers/Blecker et al.{\_}2016{\_}Comparison of Approaches for Heart Failure Case Identification From Electronic Health Record Data{\_}JAMA Cardiology.pdf:pdf},
isbn = {0000000000000},
issn = {2380-6583},
journal = {JAMA Cardiology},
keywords = {disease:CVD,epidemiology,monoresistance,public health,rank:95,relevancy:A,topic:CDSS,topic:EHR,topic:diagnosis,type:analysis},
mendeley-tags = {disease:CVD,rank:95,relevancy:A,topic:CDSS,topic:EHR,topic:diagnosis,type:analysis},
month = {dec},
number = {9},
pages = {1014},
title = {{Comparison of Approaches for Heart Failure Case Identification From Electronic Health Record Data}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1071916417311612 http://cardiology.jamanetwork.com/article.aspx?doi=10.1001/jamacardio.2016.3236},
volume = {1},
year = {2016}
}
@incollection{Carvalho2017a,
address = {Cham},
author = {Carvalho, Carolina Medeiros and Seixas, Fl{\'{a}}vio Luiz and Conci, Aura and Muchaluat-Saade, D{\'{e}}bora Christina and Laks, Jerson},
doi = {10.1007/978-3-319-62416-7_13},
editor = {Perner, Petra},
file = {:Users/na399/GitHub/thesis/references/papers/Carvalho et al.{\_}2017{\_}Improving a Bayesian Decision Model for Supporting Diagnosis of Alzheimer's Disease and Related Disorders{\_}Unknown.pdf:pdf},
isbn = {978-3-319-62415-0},
keywords = {clinical decision support systems,cognitive impairment,dementia {\'{a}} alzheimer,rank:n/a,relevancy:A,s disease {\'{a}} mild,{\'{a}} bayesian decision model},
mendeley-tags = {rank:n/a,relevancy:A},
pages = {176--191},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Improving a Bayesian Decision Model for Supporting Diagnosis of Alzheimer's Disease and Related Disorders}},
url = {http://link.springer.com/10.1007/978-3-319-62416-7 http://link.springer.com/10.1007/978-3-319-62416-7{\_}13},
volume = {10358},
year = {2017}
}
@article{Huang2015a,
abstract = {Background and objective: Risk stratification aims to provide physicians with the accurate assessment of a patient's clinical risk such that an individualized prevention or management strategy can be developed and delivered. Existing risk stratification techniques mainly focus on predicting the overall risk of an individual patient in a supervised manner, and, at the cohort level, often offer little insight beyond a flat score-based segmentation from the labeled clinical dataset. To this end, in this paper, we propose a new approach for risk stratification by exploring a large volume of electronic health records (EHRs) in an unsupervised fashion. Methods: Along this line, this paper proposes a novel probabilistic topic modeling framework called probabilistic risk stratification model (PRSM) based on Latent Dirichlet Allocation (LDA). The proposed PRSM recognizes a patient clinical state as a probabilistic combination of latent sub-profiles, and generates sub-profile-specific risk tiers of patients from their EHRs in a fully unsupervised fashion. The achieved stratification results can be easily recognized as high-, medium- and low-risk, respectively. In addition, we present an extension of PRSM, called weakly supervised PRSM (WS-PRSM) by incorporating minimum prior information into the model, in order to improve the risk stratification accuracy, and to make our models highly portable to risk stratification tasks of various diseases. Results: We verify the effectiveness of the proposed approach on a clinical dataset containing 3463 coronary heart disease (CHD) patient instances. Both PRSM and WS-PRSM were compared with two established supervised risk stratification algorithms, i.e., logistic regression and support vector machine, and showed the effectiveness of our models in risk stratification of CHD in terms of the Area Under the receiver operating characteristic Curve (AUC) analysis. As well, in comparison with PRSM, WS-PRSM has over 2{\%} performance gain, on the experimental dataset, demonstrating that incorporating risk scoring knowledge as prior information can improve the performance in risk stratification. Conclusions: Experimental results reveal that our models achieve competitive performance in risk stratification in comparison with existing supervised approaches. In addition, the unsupervised nature of our models makes them highly portable to the risk stratification tasks of various diseases. Moreover, patient sub-profiles and sub-profile-specific risk tiers generated by our models are coherent and informative, and provide significant potential to be explored for the further tasks, such as patient cohort analysis. We hypothesize that the proposed framework can readily meet the demand for risk stratification from a large volume of EHRs in an open-ended fashion.},
author = {Huang, Zhengxing and Dong, Wei and Duan, Huilong},
doi = {10.1016/j.jbi.2015.09.005},
file = {:Users/na399/GitHub/thesis/references/papers/Huang, Dong, Duan{\_}2015{\_}A probabilistic topic model for clinical risk stratification from electronic health records{\_}Journal of Biomedical.pdf:pdf},
isbn = {1532-0480 (Electronic) 1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Electronic health record,Joint patient sub-profile-risk modeling,Latent Dirichlet Allocation,Patient sub-profile,Probabilistic topic model,Risk stratification,disease:CVD,model:LDA,model:SVM,model:logisticRegression,rank:85,relevancy:B,topic:EHR,topic:prediction},
mendeley-tags = {rank:85,disease:CVD,topic:prediction,topic:EHR,model:LDA,model:logisticRegression,model:SVM,relevancy:B},
pages = {28--36},
pmid = {26370451},
publisher = {Elsevier Inc.},
title = {{A probabilistic topic model for clinical risk stratification from electronic health records}},
url = {http://dx.doi.org/10.1016/j.jbi.2015.09.005},
volume = {58},
year = {2015}
}
@article{McCoy2017,
abstract = {Objective To better understand variation in reported rates of delirium, this study characterized delirium occurrence rate by department of service and primary admitting diagnosis. Method Nine consecutive years (2005–2013) of general hospital admissions (N = 831,348) were identified across two academic medical centers using electronic health records. The primary admitting diagnosis and the treating clinical department were used to calculate occurrence rates of a previously published delirium definition composed of billing codes and natural language processing of discharge summaries. Results Delirium rates varied significantly across both admitting diagnosis group (X210 = 12786, p {\textless} 0.001) and department of care (X26 = 12106, p {\textless} 0.001). In both cases obstetrical admissions showed the lowest incidences of delirium (86/109764; 0.08{\%}) and neurological admissions the greatest (2851/25450; 11.2{\%}). Although the rate of delirium varied across the two hospitals the relative rates within departments (r = 0.96, p {\textless} 0.001) and diagnostic categories (r = 0.98, p {\textless} 0.001) were consistent across the two institutions. Conclusions The frequency of delirium varies significantly across admitting diagnosis and hospital department. Both admitting diagnosis and department of care are even stronger predictors of risk than age; as such, simple risk stratification may offer avenues for targeted prevention and treatment efforts.},
author = {McCoy, Thomas H. and Hart, Kamber L. and Perlis, Roy H.},
doi = {10.1016/j.genhosppsych.2017.01.006},
file = {:Users/na399/GitHub/thesis/references/papers/McCoy, Hart, Perlis{\_}2017{\_}Characterizing and predicting rates of delirium across general hospital settings{\_}General Hospital Psychiatry.pdf:pdf},
issn = {18737714},
journal = {General Hospital Psychiatry},
keywords = {Acute confusional state,Delirium,Electronic health record,Epidemiology,rank:75,relevancy:B},
mendeley-tags = {rank:75,relevancy:B},
number = {2017},
pages = {1--6},
pmid = {28622808},
publisher = {Elsevier Inc.},
title = {{Characterizing and predicting rates of delirium across general hospital settings}},
url = {http://dx.doi.org/10.1016/j.genhosppsych.2017.01.006},
volume = {46},
year = {2017}
}
@article{Blecker2017,
abstract = {Background: Interventions to reduce readmissions after acute heart failure hospitalization require early identification of patients. The purpose of this study was to develop and test accuracies of various approaches to identify patients with acute decompensated heart failure (ADHF) with the use of data derived from the electronic health record. Methods and Results: We included 37,229 hospitalizations of adult patients at a single hospital during 2013-2015. We developed 4 algorithms to identify hospitalization with a principal discharge diagnosis of ADHF: 1) presence of 1 of 3 clinical characteristics, 2) logistic regression of 31 structured data elements, 3) machine learning with unstructured data, and 4) machine learning with the use of both structured and unstructured data. In data validation, algorithm 1 had a sensitivity of 0.98 and positive predictive value (PPV) of 0.14 for ADHF. Algorithm 2 had an area under the receiver operating characteristic curve (AUC) of 0.96, and both machine learning algorithms had AUCs of 0.99. Based on a brief survey of 3 providers who perform chart review for ADHF, we estimated that providers spent 8.6 minutes per chart review; using this this parameter, we estimated that providers would spend 61.4, 57.3, 28.7, and 25.3 minutes on secondary chart review for each case of ADHF if initial screening were done with algorithms 1, 2, 3, and 4, respectively. Conclusions: Machine learning algorithms with unstructured notes had the best performance for identification of ADHF and can improve provider efficiency for delivery of quality improvement interventions.},
author = {Blecker, Saul and Sontag, David and Horwitz, Leora I. and Kuperman, Gilad and Park, Hannah and Reyentovich, Alex and Katz, Stuart D.},
doi = {10.1016/j.cardfail.2017.08.458},
file = {:Users/na399/GitHub/thesis/references/papers/Blecker et al.{\_}2017{\_}Early Identification of Patients With Acute Decompensated Heart Failure{\_}Journal of Cardiac Failure.pdf:pdf},
issn = {15328414},
journal = {Journal of Cardiac Failure},
keywords = {Electronic health record,Heart failure,Hospitalization,Phenotype,rank:80,relevancy:B},
mendeley-tags = {rank:80,relevancy:B},
pmid = {28887109},
publisher = {Elsevier Inc.},
title = {{Early Identification of Patients With Acute Decompensated Heart Failure}},
url = {https://doi.org/10.1016/j.cardfail.2017.08.458},
year = {2017}
}
@article{Tsaousides2009,
abstract = {Cognitive rehabilitation refers to a set of interventions that aim to improve a person's ability to perform cognitive tasks by retraining previously learned skills and teaching compensatory strategies. Cognitive rehabilitation begins with a thorough neuropsychological assessment to identify cognitive strengths and weaknesses and the degree of change in cognitive ability following a brain injury. The conclusions of the assessment are used to formulate appropriate treatment plans. Common interventions for improvements in attention, memory, and executive function, as well as the nature of comprehensive programs, which combine treatment modalities, are reviewed. Cognitive rehabilitation is effective for mild-to-severe injuries and beneficial at any time post-injury. Sufficient evidence exists supporting the efficacy and effectiveness of cognitive rehabilitation, which has become the treatment of choice for cognitive impairments and leads to improvements in cognitive and psychosocial functioning.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Rothman, Brian and Leonard, Joan C. and Vigoda, Michael M.},
doi = {10.1002/msj.21351},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/Tsaousides, Gordon{\_}2009{\_}Cognitive rehabilitation following traumatic brain injury assessment to treatment.{\_}The Mount Sinai journal of me.pdf:pdf},
isbn = {1931-7581},
issn = {00272507},
journal = {Mount Sinai Journal of Medicine: A Journal of Translational and Personalized Medicine},
keywords = {adaptive immunity,autoimmunity,diabetes,genetics in type 1,innate immunity,rank:n/a,relevancy:B,type},
mendeley-tags = {rank:n/a,relevancy:B},
month = {nov},
number = {6},
pages = {757--768},
pmid = {19306374},
title = {{Future of Electronic Health Records: Implications for Decision Support}},
url = {http://doi.wiley.com/10.1002/msj.21351},
volume = {79},
year = {2012}
}
@article{Karantzoulis2011,
abstract = {Alzheimer's disease (AD) is the most common and most studied cause of dementia. Significant advances have been made since the first set of clinical criteria for AD were put forth in 1984 that are now captured in the new criteria for AD published in 2011. Key features include recognition of a broad AD spectrum (from preclinical to mild cognitive impairment to AD dementia) and requirement of AD biomarkers for diagnosis. Correctly diagnosing dementia type is increasingly important in an era when potential disease-modifying agents are soon to be marketed. The typical AD dementia syndrome has at its core, an amnestic syndrome of the hippocampal type, followed by associated deficits in word-finding, spatial cognition, executive functions and neuropsychiatric changes. Atypical presentations of AD have also been identified that are presumed to have a different disease course. It can be difficult to distinguish between the various dementia syndromes given the overlap in many common clinical features across the dementias. The clinical difficulty in diagnosis may reflect the underlying pathology, as AD often co-occurs with other pathologies at autopsy, such as cerebrovascular disease or Lewy bodies. Neuropsychological evaluation has provided clinicians and researchers with profiles of cognitive strengths and weaknesses that help to define the dementias. There is yet no single behavioral marker that can reliably discriminate AD from the other dementias. The combined investigation of cognitive and neurobehavioral symptoms coupled with imaging markers could provide a more accurate approach for differentiating between AD and other major dementia syndromes in the future.},
author = {Karantzoulis, Stella and Galvin, James E.},
doi = {10.1586/ern.11.155},
file = {:Users/na399/GitHub/thesis/references/papers/Karantzoulis, Galvin{\_}2011{\_}Distinguishing Alzheimer's disease from other major forms of dementia{\_}Expert Review of Neurotherapeutics.pdf:pdf},
isbn = {1744-8360 (Electronic)$\backslash$n1473-7175 (Linking)},
issn = {14737175},
journal = {Expert Review of Neurotherapeutics},
keywords = {Alzheimer's disease,Lewy body,cognition,dementia,depression,differential diagnosis,disease:dementia,frontotemporal dementia,rank:80,relevancy:A,vascular},
mendeley-tags = {rank:80,relevancy:A,disease:dementia},
number = {11},
pages = {1579--1591},
pmid = {22014137},
title = {{Distinguishing Alzheimer's disease from other major forms of dementia}},
volume = {11},
year = {2011}
}
@article{Sikder2013,
abstract = {Healthcare is universally regarded as one of the basic needs of human being. Access to healthcare facilities is the most challenging task for developing countries like Bangladesh due to overpopulation, poor infrastructure, corruption, political instability and a slow implementation of economic reforms. The recent development of Electronic Health Record(EHR) system has enormous effect on health informatics. As far we are conscious, there is no central EHR system in Bangladesh. In this paper, we present a typical EHR system along with phenotypic term binding to predict human disease and improve healthcare facilities to the doorsteps all over the country. We evaluate our method by considering different criteria and retrieve a convincing result that shows the effectiveness of our system. {\textcopyright} 2013 IEEE.},
author = {Sikder, M K A and Chy, A N and Seddiqui, M H},
file = {:Users/na399/GitHub/thesis/references/papers/Sikder, Chy, Seddiqui{\_}2013{\_}Electronic health record system for human disease prediction and healthcare improvement in Bangladesh{\_}2013 In.pdf:pdf},
isbn = {9781479904006},
journal = {2013 International Conference on Informatics, Electronics and Vision, ICIEV 2013},
keywords = {rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
title = {{Electronic health record system for human disease prediction and healthcare improvement in Bangladesh}},
url = {internal-pdf://111.109.217.172/Sikder{\_}EHRBangladesh{\_}ICIEVProc{\_}2013.pdf{\%}5Cnhttp://www.scopus.com/inward/record.url?eid=2-s2.0-84883334762{\&}partnerID=40{\&}md5=b75e6ea8c1d9725b3fc62e87886911e6},
year = {2013}
}
@article{Yan2015,
abstract = {As the most common type of dementia, Alzheimer's disease (AD) is a neurodegenerative disorder initially manifested by impaired memory performances. While the diagnosis information indicates a dichotomous status of a patient, memory scores have the potential to capture the continuous nature of the disease progression and may provide more insights into the underlying mechanism. In this work, we performed a targeted genetic study of memory scores on an AD cohort to identify the associations between a set of genes highly expressed in the hippocampal region and seven cognitive scores related to episodic memory. Both main effects and interaction effects of the targeted genetic markers on these correlated memory scores were examined. In addition to well-known AD genetic markers APOE and TOMM40, our analysis identified a new risk gene NAV2 through the gene-level main effect analysis. NAV2 was found to be significantly and consistently associated with all seven episodic memory scores. Genetic interaction analysis also yielded a few promising hits warranting further investigation, especially for the RAVLT list B Score.},
author = {Yan, Jingwen and Kim, Sungeun and Nho, Kwangsik and Chen, Rui and Risacher, Shannon L. and Moore, Jason H. and Saykin, Andrew J. and Shen, Li},
doi = {10.3389/fgene.2015.00117},
file = {:Users/na399/GitHub/thesis/references/papers/Yan et al.{\_}2015{\_}Hippocampal transcriptome-guided genetic analysis of correlated episodic memory phenotypes in Alzheimer's disease{\_}Fronti.pdf:pdf},
isbn = {1664-8021 (Linking)},
issn = {16648021},
journal = {Frontiers in Genetics},
keywords = {Alzheimer's disease,Correlated phenotypes,Episodic memory,Genetic associate study,Hippocampus,disease:dementia,rank:75,relevancy:D},
mendeley-tags = {rank:75,relevancy:D,disease:dementia},
number = {MAR},
pages = {1--9},
pmid = {25859259},
title = {{Hippocampal transcriptome-guided genetic analysis of correlated episodic memory phenotypes in Alzheimer's disease}},
volume = {6},
year = {2015}
}
@article{Hidalgo2009,
abstract = {To help the understanding of physiological failures, diseases are defined as specific sets of phenotypes affecting one or several physiological systems. Yet, the complexity of biological systems implies that our working definitions of diseases are careful discretizations of a complex phenotypic space. To reconcile the discrete nature of diseases with the complexity of biological organisms, we need to understand how diseases are connected, as connections between these different discrete categories can be informative about the mechanisms causing physiological failures. Here we introduce the Phenotypic Disease Network (PDN) as a map summarizing phenotypic connections between diseases and show that diseases progress preferentially along the links of this map. Furthermore, we show that this progression is different for patients with different genders and racial backgrounds and that patients affected by diseases that are connected to many other diseases in the PDN tend to die sooner than those affected by less connected diseases. Additionally, we have created a queryable online database (http://hudine.neu.edu/) of the 18 different datasets generated from the more than 31 million patients in this study. The disease associations can be explored online or downloaded in bulk.},
archivePrefix = {arXiv},
arxivId = {0909.3893},
author = {Hidalgo, C{\'{e}}sar A. and Blumm, Nicholas and Barab{\'{a}}si, Albert-L{\'{a}}szl{\'{o}} and Christakis, Nicholas A.},
doi = {10.1371/journal.pcbi.1000353},
editor = {Meyers, Lauren Ancel},
eprint = {0909.3893},
file = {:Users/na399/GitHub/thesis/references/papers/Hidalgo et al.{\_}2009{\_}A Dynamic Network Approach for the Study of Human Phenotypes{\_}PLoS Computational Biology.PDF:PDF},
isbn = {1553-734x},
issn = {1553-7358},
journal = {PLoS Computational Biology},
keywords = {disease:general,model:network,rank:99,relevancy:A,topic:progression,type:research},
mendeley-tags = {disease:general,model:network,rank:99,relevancy:A,topic:progression,type:research},
month = {apr},
number = {4},
pages = {e1000353},
pmid = {19360091},
title = {{A Dynamic Network Approach for the Study of Human Phenotypes}},
url = {http://dx.plos.org/10.1371/journal.pcbi.1000353},
volume = {5},
year = {2009}
}
@article{Castaneda2015,
abstract = {As research laboratories and clinics collaborate to achieve precision medicine, both communities are required to understand mandated electronic health/medical record (EHR/EMR) initiatives that will be fully implemented in all clinics in the United States by 2015. Stakeholders will need to evaluate current record keeping practices and optimize and standardize methodologies to capture nearly all information in digital format. Collaborative efforts from academic and industry sectors are crucial to achieving higher efficacy in patient care while minimizing costs. Currently existing digitized data and information are present in multiple formats and are largely unstructured. In the absence of a universally accepted management system, departments and institutions continue to generate silos of information. As a result, invaluable and newly discovered knowledge is difficult to access. To accelerate biomedical research and reduce healthcare costs, clinical and bioinformatics systems must employ common data elements to create structured annotation forms enabling laboratories and clinics to capture sharable data in real time. Conversion of these datasets to knowable information should be a routine institutionalized process. New scientific knowledge and clinical discoveries can be shared via integrated knowledge environments defined by flexible data models and extensive use of standards, ontologies, vocabularies, and thesauri. In the clinical setting, aggregated knowledge must be displayed in user-friendly formats so that physicians, non-technical laboratory personnel, nurses, data/research coordinators, and end-users can enter data, access information, and understand the output. The effort to connect astronomical numbers of data points, including '-omics'-based molecular data, individual genome sequences, experimental data, patient clinical phenotypes, and follow-up data is a monumental task. Roadblocks to this vision of integration and interoperability include ethical, legal, and logistical concerns. Ensuring data security and protection of patient rights while simultaneously facilitating standardization is paramount to maintaining public support. The capabilities of supercomputing need to be applied strategically. A standardized, methodological implementation must be applied to developed artificial intelligence systems with the ability to integrate data and information into clinically relevant knowledge. Ultimately, the integration of bioinformatics and clinical data in a clinical decision support system promises precision medicine and cost effective and personalized patient care.},
author = {Castaneda, Christian and Nalley, Kip and Mannion, Ciaran and Bhattacharyya, Pritish and Blake, Patrick and Pecora, Andrew and Goy, Andre and Suh, K Stephen},
doi = {10.1186/s13336-015-0019-3},
file = {:Users/na399/GitHub/thesis/references/papers/Castaneda et al.{\_}2015{\_}Clinical decision support systems for improving diagnostic accuracy and achieving precision medicine{\_}Journal of Cl.pdf:pdf},
isbn = {9788476662106},
issn = {2043-9113},
journal = {Journal of Clinical Bioinformatics},
keywords = {Bioinform,Personalized medicine,Precision medicine,artificial intelligence,bioinformatics,clinical decision support,clinical informatics,clinical outcome,correspondence,hackensackumc,integrated knowledge environment,ksuh,org,patient care,personalized medicine,precision medicine,rank:55,relevancy:B,system,watson},
mendeley-tags = {rank:55,relevancy:B},
number = {1},
pages = {4},
pmid = {25834725},
title = {{Clinical decision support systems for improving diagnostic accuracy and achieving precision medicine}},
url = {http://www.jclinbioinformatics.com/content/5/1/4},
volume = {5},
year = {2015}
}
@article{SalaFrigerio2016,
abstract = {Ten years of remarkable progress in understanding of the fundamental biochemistry of Alzheimer?s disease have been followed by ten years of remarkable and increasing clinical insight into the natural progression of the disorder. The concept of a long intermediary, prodromal phase between the first appearance of amyloid plaques and tangles and the manifestation of dementia is now well established. The major challenge for the next decade is to chart the many cellular processes that underlie this phase and link the biochemical alterations to the clinical manifestation of Alzheimer?s disease. We discuss here how genetics, new cell culture systems and improved animal models will fuel this work. We anticipate that the resulting novel insights will provide a basis to further drug development for this terrible disease. Expected final online publication date for the Annual Review of Neuroscience Volume 39 is July 8, 2016. Please see http://www.annualreviews.org/catalog/pubdates.aspx for revised estimates.},
author = {{Sala Frigerio}, Carlo and {De Strooper}, Bart},
doi = {10.1146/annurev-neuro-070815-014015},
file = {:Users/na399/GitHub/thesis/references/papers/Sala Frigerio, De Strooper{\_}2016{\_}Alzheimer's Disease Mechanisms and Emerging Roads to Novel Therapeutics{\_}Annual Review of Neuroscience.pdf:pdf},
isbn = {1545-4126 (Electronic)$\backslash$r0147-006X (Linking)},
issn = {0147-006X},
journal = {Annual Review of Neuroscience},
keywords = {amyloid- $\beta$,disease:dementia,ipsc,preclinical alzheimer,rank:99,relevancy:C,s disease,tau,topic:treatment,type:review},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:treatment,type:review},
number = {1},
pages = {57--79},
pmid = {27050320},
title = {{Alzheimer's Disease Mechanisms and Emerging Roads to Novel Therapeutics}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-neuro-070815-014015},
volume = {39},
year = {2016}
}
@article{Marier2015,
abstract = {OBJECTIVE: Falls are physically and financially costly, but may be preventable with targeted intervention. The Minimum Data Set (MDS) is one potential source of information on fall risk factors among nursing home residents, but its limited breadth and relatively infrequent updates may limit its practical utility. Richer, more frequently updated data from electronic medical records (EMRs) may improve ability to identify individuals at highest risk for falls.$\backslash$n$\backslash$nMETHODS: The authors applied a repeated events survival model to analyze MDS 3.0 and EMR data for 5129 residents in 13 nursing homes within a single large California chain that uses a centralized EMR system from a leading vendor. Estimated regression parameters were used to project resident fall probability. The authors examined the proportion of observed falls within each projected fall risk decile to assess improvements in predictive power from including EMR data.$\backslash$n$\backslash$nRESULTS: In a model incorporating fall risk factors from the MDS only, 28.6{\%} of observed falls occurred among residents in the highest projected risk decile. In an alternative specification incorporating more frequently updated measures for the same risk factors from the EMR data, 32.3{\%} of observed falls occurred among residents in the highest projected risk decile, a 13{\%} increase over the base MDS-only specification.$\backslash$n$\backslash$nCONCLUSIONS: Incorporating EMR data improves ability to identify those at highest risk for falls relative to prediction using MDS data alone. These improvements stem chiefly from the greater frequency with which EMR data are updated, with minimal additional gains from availability of additional risk factor variables.},
author = {Marier, Allison and Olsho, Lauren E W and Rhodes, William and Spector, William D},
doi = {10.1093/jamia/ocv061},
file = {:Users/na399/GitHub/thesis/references/papers/Marier et al.{\_}2015{\_}Improving prediction of fall risk among nursing home residents using electronic medical records.{\_}Journal of the Ameri.pdf:pdf},
isbn = {1527-974X (Electronic)$\backslash$r1067-5027 (Linking)},
issn = {1527-974X},
journal = {Journal of the American Medical Informatics Association : JAMIA},
keywords = {0,electronic medical records,meaningful use,minimum data set 3,nursing home falls,prediction,rank:90,relevancy:B,topic:EHR,topic:prediction,type:research},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,topic:prediction,type:research},
pages = {ocv061},
pmid = {26104743},
title = {{Improving prediction of fall risk among nursing home residents using electronic medical records.}},
url = {http://jamia.oxfordjournals.org/content/early/2015/06/22/jamia.ocv061.abstract},
year = {2015}
}
@article{Dudley2002,
abstract = {OBJECTIVES: In later life, cognitive impairment is common in depression often making it difficult to distinguish a dementing illness from depression. We examined whether people with depression could be differentiated from those with dementia on their performance on a task that examines attentional bias to depression related material.$\backslash$n$\backslash$nMETHODS: Twelve older adults who fulfilled DSM-IV criteria for major depression were compared with 12 people with Alzheimer's Disease (AD) and 12 age matched controls on a test of cognitive biases: the Emotional Stroop task. In this task participants were presented with words written in different coloured inks, and they had to name the colour the word was written in. Four types of material were presented-neutral, positive, and negative emotion words as well as a condition of meaningless symbols.$\backslash$n$\backslash$nRESULTS: People with depression and those with AD were both slower than the controls on the task generally. However, the depressed group alone showed a statistically significant and specific increase in response time when colour naming the negative emotion words. The other two groups did not demonstrate such a pattern and colour named neutral, positive and negative words equally quickly.$\backslash$n$\backslash$nCONCLUSIONS: The biased processing of depression related material may have a valuable role in distinguishing depression from dementia in later life. Although the Emotional Stroop in its present form is not sufficient for such a purpose. Furthermore, the demonstration that older adults with depression exhibit such biases helps provide a theoretical basis for the application of cognitive behavioural treatments with older adults.},
author = {Dudley, Robert and O'Brien, John and Barnett, Nichola and McGuckin, Liz and Britton, Peter},
doi = {10.1002/gps.514},
file = {:Users/na399/Downloads/Research Papers/Dudley et al.{\_}2002{\_}Distinguishing depression from dementia in later life A pilot study employing the Emotional Stroop task{\_}International.pdf:pdf},
isbn = {1099-1166(Electronic);0885-6230(Print)},
issn = {08856230},
journal = {International Journal of Geriatric Psychiatry},
keywords = {Alzheimers' dementia,Depression,Emotional Stroop,disease:dementia,rank:80,relevancy:C},
mendeley-tags = {rank:80,relevancy:C,disease:dementia},
number = {1},
pages = {48--53},
pmid = {11802230},
title = {{Distinguishing depression from dementia in later life: A pilot study employing the Emotional Stroop task}},
volume = {17},
year = {2002}
}
@article{Vock2016,
abstract = {Models for predicting the probability of experiencing various health outcomes or adverse events over a certain time frame (e.g., having a heart attack in the next 5 years) based on individual patient characteristics are important tools for managing patient care. Electronic health data (EHD) are appealing sources of training data because they provide access to large amounts of rich individual-level data from present-day patient populations. However, because EHD are derived by extracting information from administrative and clinical databases, some fraction of subjects will not be under observation for the entire time frame over which one wants to make predictions; this loss to follow-up is often due to disenrollment from the health system. For subjects without complete follow-up, whether or not they experienced the adverse event is unknown, and in statistical terms the event time is said to be right-censored. Most machine learning approaches to the problem have been relatively ad hoc; for example, common approaches for handling observations in which the event status is unknown include (1) discarding those observations, (2) treating them as non-events, (3) splitting those observations into two observations: one where the event occurs and one where the event does not. In this paper, we present a general-purpose approach to account for right-censored outcomes using inverse probability of censoring weighting (IPCW). We illustrate how IPCW can easily be incorporated into a number of existing machine learning algorithms used to mine big health care data including Bayesian networks, k-nearest neighbors, decision trees, and generalized additive models. We then show that our approach leads to better calibrated predictions than the three ad hoc approaches when applied to predicting the 5-year risk of experiencing a cardiovascular adverse event, using EHD from a large U.S. Midwestern healthcare system.},
author = {Vock, David M. and Wolfson, Julian and Bandyopadhyay, Sunayan and Adomavicius, Gediminas and Johnson, Paul E. and Vazquez-Benitez, Gabriela and O'Connor, Patrick J.},
doi = {10.1016/j.jbi.2016.03.009},
file = {:Users/na399/GitHub/thesis/references/papers/Vock et al.{\_}2016{\_}Adapting machine learning techniques to censored time-to-event health record data A general-purpose approach using inve.pdf:pdf},
isbn = {1532-0464},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Censored data,Electronic health data,Inverse probability weighting,Machine learning,Risk prediction,Survival analysis,model:Bayesian,rank:85,relevancy:A,topic:ML,type:research},
mendeley-tags = {rank:85,type:research,relevancy:A,topic:ML,model:Bayesian},
pages = {119--131},
pmid = {26992568},
publisher = {Elsevier Inc.},
title = {{Adapting machine learning techniques to censored time-to-event health record data: A general-purpose approach using inverse probability of censoring weighting}},
url = {http://dx.doi.org/10.1016/j.jbi.2016.03.009},
volume = {61},
year = {2016}
}
@article{Bealisle2002,
author = {B{\'{e}}alisle, Patrick and Joseph, Lawrence and Wolfson, David B and Zhou, Xiaojie},
doi = {10.2307/3315864},
file = {:Users/na399/GitHub/thesis/references/papers/B{\'{e}}alisle et al.{\_}2002{\_}Bayesian estimation of cognitive decline in patients with alzheimer's disease{\_}Canadian Journal of Statistics.pdf:pdf},
issn = {03195724},
journal = {Canadian Journal of Statistics},
keywords = {disease:dementia,rank:50,relevancy:B},
mendeley-tags = {rank:50,relevancy:B,disease:dementia},
month = {mar},
number = {1},
pages = {37--54},
title = {{Bayesian estimation of cognitive decline in patients with alzheimer's disease}},
url = {http://doi.wiley.com/10.2307/3315864},
volume = {30},
year = {2002}
}
@article{Esteban2017,
abstract = {Background and Objective Recent progression towards precision medicine has encouraged the use of electronic health records (EHRs) as a source for large amounts of data, which is required for studying the effect of treatments or risk factors in more specific subpopulations. Phenotyping algorithms allow to automatically classify patients according to their particular electronic phenotype thus facilitating the setup of retrospective cohorts. Our objective is to compare the performance of different classification strategies (only using standardized problems, rule-based algorithms, statistical learning algorithms (six learners) and stacked generalization (five versions)), for the categorization of patients according to their diabetic status (diabetics, not diabetics and inconclusive; Diabetes of any type) using information extracted from EHRs. Methods Patient information was extracted from the EHR at Hospital Italiano de Buenos Aires, Buenos Aires, Argentina. For the derivation and validation datasets, two probabilistic samples of patients from different years (2005: n = 1663; 2015: n = 800) were extracted. The only inclusion criterion was age (≥40 {\&} {\textless}80 years). Four researchers manually reviewed all records and classified patients according to their diabetic status (diabetic: diabetes registered as a health problem or fulfilling the ADA criteria; non-diabetic: not fulfilling the ADA criteria and having at least one fasting glycemia below 126 mg/dL; inconclusive: no data regarding their diabetic status or only one abnormal value). The best performing algorithms within each strategy were tested on the validation set. Results The standardized codes algorithm achieved a Kappa coefficient value of 0.59 (95{\%} CI 0.49, 0.59) in the validation set. The Boolean logic algorithm reached 0.82 (95{\%} CI 0.76, 0.88). A slightly higher value was achieved by the Feedforward Neural Network (0.9, 95{\%} CI 0.85, 0.94). The best performing learner was the stacked generalization meta-learner that reached a Kappa coefficient value of 0.95 (95{\%} CI 0.91, 0.98). Conclusions The stacked generalization strategy and the feedforward neural network showed the best classification metrics in the validation set. The implementation of these algorithms enables the exploitation of the data of thousands of patients accurately.},
author = {Esteban, Santiago and {Rodr{\'{i}}guez Tablado}, Manuel and Peper, Francisco E. and Mahumud, Yamila S. and Ricci, Ricardo I. and Kopitowski, Karin S. and Terrasa, Sergio A.},
doi = {10.1016/j.cmpb.2017.09.009},
file = {:Users/na399/GitHub/thesis/references/papers/Esteban et al.{\_}2017{\_}Development and validation of various phenotyping algorithms for Diabetes Mellitus using data from electronic health.pdf:pdf},
isbn = {9781614998297},
issn = {18727565},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Diabetes Mellitus,Electronic health records,Electronic phenotyping algorithms,Stacked generalization,rank:80,relevancy:C},
mendeley-tags = {rank:80,relevancy:C},
number = {2017},
pages = {53--70},
pmid = {29054261},
publisher = {Elsevier Ireland Ltd},
title = {{Development and validation of various phenotyping algorithms for Diabetes Mellitus using data from electronic health records}},
url = {https://doi.org/10.1016/j.cmpb.2017.09.009},
volume = {152},
year = {2017}
}
@article{Shen2014,
abstract = {In this paper, we introduce our efforts on an application of semantic web technologies to phenotyping algorithms in Electronic Health Records (EHR) data for the purpose of facilitating the reasoning and inferring processes of some patients groups in an intelligent manner.},
author = {Shen, Feichen and Li, Dingcheng and Liu, Hongfang and Lee, Yugyung and Pathak, Jyotishman and Chute, Christopher G. and Tao, Cui},
doi = {10.1109/BHI.2014.6864419},
file = {:Users/na399/GitHub/thesis/references/papers/Shen et al.{\_}2014{\_}Using semantic web technologies for quality measure phenotyping algorithm representation and automatic execution on EHR.pdf:pdf},
isbn = {9781479921317},
journal = {2014 IEEE-EMBS International Conference on Biomedical and Health Informatics, BHI 2014},
keywords = {Healthcare knowledge computerization,execution,i,rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
pages = {531--534},
title = {{Using semantic web technologies for quality measure phenotyping algorithm representation and automatic execution on EHR data}},
year = {2014}
}
@article{Jensen2012,
abstract = {Clinical data describing the phenotypes and treatment of patients represents an underused data source that has much greater research potential than is currently realized. Mining of electronic health records (EHRs) has the potential for establishing new patient-stratification principles and for revealing unknown disease correlations. Integrating EHR data with genetic data will also give a finer understanding of genotype-phenotype relationships. However, a broad range of ethical, legal and technical reasons currently hinder the systematic deposition of these data in EHRs and their mining. Here, we consider the potential for furthering medical research and clinical care using EHR data and the challenges that must be overcome before this is a reality.},
author = {Jensen, Peter B. and Jensen, Lars J. and Brunak, So{\o}ren},
doi = {10.1038/nrg3208},
file = {:Users/na399/GitHub/thesis/references/papers/Jensen, Jensen, Brunak{\_}2012{\_}Mining electronic health records Towards better research applications and clinical care{\_}Nature Reviews Genet.pdf:pdf},
isbn = {1471-0064 (Electronic)$\backslash$r1471-0056 (Linking)},
issn = {14710056},
journal = {Nature Reviews Genetics},
keywords = {disease:general,rank:99,relevancy:A,topic:EHR,type:review},
mendeley-tags = {disease:general,rank:99,relevancy:A,topic:EHR,type:review},
number = {6},
pages = {395--405},
pmid = {22549152},
publisher = {Nature Publishing Group},
title = {{Mining electronic health records: Towards better research applications and clinical care}},
url = {http://dx.doi.org/10.1038/nrg3208},
volume = {13},
year = {2012}
}
@article{Barak-Corren2017,
abstract = {Objective: The purpose of this article was to determine whether longitudinal historical data, commonly available in electronic health record (EHR) systems, can be used to predict patients' future risk of suicidal behavior. Method: Bayesian models were developed using a retro-spective cohort approach. EHR data from a large health care database spanning 15 years (1998–2012) of inpatient and outpatient visits were used to predict future documented suicidal behavior (i.e., suicide attempt or death). Patients with three or more visits (N=1,728,549) were included. ICD-9-based case definition for suicidal behavior was derived by expert clinician consensus review of 2,700 narrative EHR notes (from 520 patients), supplemented by state death certificates. Model performance was evaluated retrospec-tively using an independent testing set. Results: Among the study population, 1.2{\%} (N=20,246) met the case definition for suicidal behavior. The model achieved},
author = {Barak-Corren, Yuval and Castro, Victor M. and Javitt, Solomon and Hoffnagle, Alison G. and Dai, Yael and Perlis, Roy H. and Nock, Matthew K. and Smoller, Jordan W. and Reis, Ben Y.},
doi = {10.1176/appi.ajp.2016.16010077},
file = {:Users/na399/GitHub/thesis/references/papers/Barak-Corren et al.{\_}2017{\_}Predicting suicidal behavior from longitudinal electronic health records{\_}American Journal of Psychiatry.pdf:pdf},
issn = {15357228},
journal = {American Journal of Psychiatry},
keywords = {disease:psychiatry,model:Bayesian,rank:99,relevancy:A,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:psychiatry,model:Bayesian,rank:99,relevancy:A,topic:EHR,topic:prediction,type:research},
number = {2},
pages = {154--162},
pmid = {27609239},
title = {{Predicting suicidal behavior from longitudinal electronic health records}},
volume = {174},
year = {2017}
}
@article{Kalbe2013,
abstract = {Many cognitive screening instruments have been developed during the last decades to detect mild cognitive dysfunction and dementia, and there is an ongoing discussion as to which tool should be used in which setting and which challenges have to be considered. Among other aspects, dependence on age is a recognized problem in screening tools which still has not found its way into common scoring procedures. Another aspect which has been handled very heterogeneously is which domain is represented in which proportion in the total score. Furthermore, screening ethnic minority patients has been identified as an important but so far widely unresolved matter. In this review, four cognitive screening tools that all follow a common, stringent concept and pay regard to some critical aspects are described: the DemTect, a "generic" tool; the PANDA for Parkinson's disease patients; the EASY, a non-verbal, culture-fair screening test for patients with migration background; and the MUSIC for patients with multiple sclerosis. All of these screening instruments have an age-correction, provide a total score in which the different subtests are weighted according to their individual sensitivity and specificity, and include tasks that are specifically aligned to the cognitive profile of the target group, including the EASY with non-verbal, culture-fair tasks to overcome language and cultural barriers. The development, main characteristics, data, and limitations of these tools are presented and discussed against the background of the current landscape of cognitive screening tools.},
author = {Kalbe, Elke and Calabrese, Pasquale and Fengler, Sophie and Kessler, Josef},
doi = {10.3233/JAD-122128},
file = {:Users/na399/Downloads/Research Papers/Kalbe et al.{\_}2013{\_}DemTect, PANDA, EASY, and MUSIC Cognitive screening tools with age correction and weighting of subtests according to t.pdf:pdf},
isbn = {1387-2877},
issn = {13872877},
journal = {Journal of Alzheimer's Disease},
keywords = {Alzheimer's disease,Parkinson's disease,cognition,cultural diversity,dementia,disease:dementia,early diagnosis,mild cognitive impairment,multiple sclerosis,rank:95,relevancy:C,topic:diagnosis,type:research},
mendeley-tags = {disease:dementia,rank:95,relevancy:C,topic:diagnosis,type:research},
number = {4},
pages = {813--834},
pmid = {23313929},
title = {{DemTect, PANDA, EASY, and MUSIC: Cognitive screening tools with age correction and weighting of subtests according to their sensitivity and specificity}},
volume = {34},
year = {2013}
}
@inproceedings{MariniSDagliatiASacchiL2016,
author = {Marini, Simone and Dagliati, Arianna and Sacchi, Lucia and Bellazzi, Riccardo},
booktitle = {Proceedings of the 9th International Joint Conference on Biomedical Engineering Systems and Technologies},
doi = {10.5220/0005708103380344},
file = {:Users/na399/GitHub/thesis/references/papers/Marini S, Dagliati A, Sacchi L{\_}2016{\_}Learning T2D evolving complexity from EMR and administrative data by means of Continuous time Bayesi.pdf:pdf},
isbn = {978-989-758-170-0},
keywords = {rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
number = {Biostec},
pages = {338--344},
publisher = {SCITEPRESS - Science and and Technology Publications},
title = {{Learning T2D Evolving Complexity from EMR and Administrative Data by Means of Continuous Time Bayesian Networks}},
url = {http://www.scitepress.org/DigitalLibrary/Link.aspx?doi=10.5220/0005708103380344},
volume = {5},
year = {2016}
}
@article{BECK2017,
abstract = {Most studies of disease etiologies focus on one disease only and not the full spectrum of multimorbidities that many patients have. Some disease pairs have shared causal origins, others represent common follow-on diseases, while yet other co-occurring diseases may manifest themselves in random order of appearance. We discuss these different types of disease co-occurrences, and use the two diseases "sleep apnea" and "diabetes" to showcase the approach which otherwise can be applied to any disease pair. We benefit from seven million electronic medical records covering the entire population of Denmark for more than 20 years. Sleep apnea is the most common sleep-related breathing disorder and it has previously been shown to be bidirectionally linked to diabetes, meaning that each disease increases the risk of acquiring the other. We confirm that there is no significant temporal relationship, as approximately half of patients with both diseases are diagnosed with diabetes first. However, we also show that patients diagnosed with diabetes before sleep apnea have a higher disease burden compared to patients diagnosed with sleep apnea before diabetes. The study clearly demonstrates that it is not only the diagnoses in the patient's disease history that are important, but also the specific order in which these diagnosis are given that matters in terms of outcome. We suggest that this should be considered for patient stratification.},
author = {Beck, Mette K and Westergaard, David and Jensen, Anders Boeck and Groop, Leif and Brunak, S{\o}ren},
doi = {10.1142/9789813207813_0036},
file = {:Users/na399/GitHub/thesis/references/papers/BECK et al.{\_}2017{\_}Temporal Order of Disease Pairs Affects Subsequent Disease Trajectories the Case of Diabetes and Sleep Apnea{\_}Biocomputi.pdf:pdf},
isbn = {978-981-320-780-6},
issn = {2335-6936},
journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
keywords = {rank:n/a,relevancy:A},
mendeley-tags = {rank:n/a,relevancy:A},
month = {jan},
pages = {380--389},
pmid = {27896991},
publisher = {WORLD SCIENTIFIC},
title = {{TEMPORAL ORDER OF DISEASE PAIRS AFFECTS SUBSEQUENT DISEASE TRAJECTORIES: THE CASE OF DIABETES AND SLEEP APNEA.}},
url = {http://www.worldscientific.com/doi/abs/10.1142/9789813207813{\_}0036 http://www.ncbi.nlm.nih.gov/pubmed/27896991},
volume = {22},
year = {2017}
}
@article{Beheshti2015,
abstract = {High-dimensional classification methods have been a major target of machine learning for the automatic classification of patients who suffer from Alzheimer's disease (AD). One major issue of automatic classification is the feature-selection method from high-dimensional data. In this paper, a novel approach for statistical feature reduction and selection in high-dimensional magnetic resonance imaging (MRI) data based on the probability distribution function (PDF) is introduced. To develop an automatic computer-aided diagnosis (CAD) technique, this research explores the statistical patterns extracted from structural MRI (sMRI) data on four systematic levels. First, global and local differences of gray matter in patients with AD compared to healthy controls (HCs) using the voxel-based morphometric (VBM) technique with 3-Tesla 3D T1-weighted MRI are investigated. Second, feature extraction based on the voxel clusters detected by VBM on sMRI and voxel values as volume of interest (VOI) is used. Third, a novel statistical feature-selection process is employed, utilizing the PDF of the VOI to represent statistical patterns of the respective high-dimensional sMRI sample. Finally, the proposed feature-selection method for early detection of AD with support vector machine (SVM) classifiers compared to other standard feature selection methods, such as partial least squares (PLS) techniques, is assessed. The performance of the proposed technique is evaluated using 130 AD and 130 HC MRI data from the ADNI dataset with 10-fold cross validation. The results show that the PDF-based feature selection approach is a reliable technique that is highly competitive with respect to the state-of-the-art techniques in classifying AD from high-dimensional sMRI samples.},
author = {Beheshti, I. and Demirel, H.},
doi = {10.1016/j.compbiomed.2015.07.006},
file = {:Users/na399/Downloads/Research Papers/Beheshti, Demirel{\_}2015{\_}Probability distribution function-based classification of structural MRI for the detection of Alzheimer's disease.pdf:pdf},
isbn = {1879-0534 (Electronic)$\backslash$r0010-4825 (Linking)},
issn = {18790534},
journal = {Computers in Biology and Medicine},
keywords = {Alzheimer's disease,Classification,Computer-aided diagnosis,Fisher criterion,Probability distribution function,Statistical feature extraction,Structural MRI,Voxel-based morphometry,rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
pages = {208--216},
pmid = {26226415},
publisher = {Elsevier},
title = {{Probability distribution function-based classification of structural MRI for the detection of Alzheimer's disease}},
url = {http://dx.doi.org/10.1016/j.compbiomed.2015.07.006},
volume = {64},
year = {2015}
}
@misc{Informatics,
author = {Informatics, Health},
file = {:Users/na399/GitHub/thesis/references/papers/Informatics{\_}Unknown{\_}Clinical Decision Support Systems{\_}Unknown.epub:epub},
isbn = {9783319319117},
keywords = {rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
title = {{Clinical Decision Support Systems}}
}
@article{Wiens2014,
abstract = {BACKGROUND:Data-driven risk stratification models built using data from a single hospital often have a paucity of training data. However, leveraging data from other hospitals can be challenging owing to institutional differences with patients and with data coding and capture.$\backslash$n$\backslash$nOBJECTIVE:To investigate three approaches to learning hospital-specific predictions about the risk of hospital-associated infection with Clostridium difficile, and perform a comparative analysis of the value of different ways of using external data to enhance hospital-specific predictions.$\backslash$n$\backslash$nMATERIALS AND METHODS:We evaluated each approach on 132 853 admissions from three hospitals, varying in size and location. The first approach was a single-task approach, in which only training data from the target hospital (ie, the hospital for which the model was intended) were used. The second used only data from the other two hospitals. The third approach jointly incorporated data from all hospitals while seeking a solution in the target space.$\backslash$n$\backslash$nRESULTS:The relative performance of the three different approaches was found to be sensitive to the hospital selected as the target. However, incorporating data from all hospitals consistently had the highest performance.$\backslash$n$\backslash$nDISCUSSION:The results characterize the challenges and opportunities that come with (1) using data or models from collections of hospitals without adapting them to the site at which the model will be used, and (2) using only local data to build models for small institutions or rare events.$\backslash$n$\backslash$nCONCLUSIONS:We show how external data from other hospitals can be successfully and efficiently incorporated into hospital-specific models.},
author = {Wiens, Jenna and Guttag, John and Horvitz, Eric},
doi = {10.1136/amiajnl-2013-002162},
file = {:Users/na399/GitHub/thesis/references/papers/Wiens, Guttag, Horvitz{\_}2014{\_}A study in transfer learning Leveraging data from multiple hospitals to enhance hospital-specific prediction.pdf:pdf},
isbn = {10.1136/amiajnl-2013-002162},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {rank:90,relevancy:C,topic:transfer},
mendeley-tags = {rank:90,relevancy:C,topic:transfer},
number = {4},
pages = {699--706},
pmid = {24481703},
title = {{A study in transfer learning: Leveraging data from multiple hospitals to enhance hospital-specific predictions}},
volume = {21},
year = {2014}
}
@article{Jensen2014,
abstract = {A key prerequisite for precision medicine is the estimation of disease progression from the current patient state. Disease correlations and temporal disease progression (trajectories) have mainly been analysed with focus on a small number of diseases or using large-scale approaches without time consideration, exceeding a few years. So far, no large-scale studies have focused on defining a comprehensive set of disease trajectories. Here we present a discovery-driven analysis of temporal disease progression patterns using data from an electronic health registry covering the whole population of Denmark. We use the entire spectrum of diseases and convert 14.9 years of registry data on 6.2 million patients into 1,171 significant trajectories. We group these into patterns centred on a small number of key diagnoses such as chronic obstructive pulmonary disease (COPD) and gout, which are central to disease progression and hence important to diagnose early to mitigate the risk of adverse outcomes. We suggest such trajectory analyses may be useful for predicting and preventing future diseases of individual patients},
author = {Jensen, Anders Boeck and Moseley, Pope L. and Oprea, Tudor I. and Elles{\o}e, Sabrina Gade and Eriksson, Robert and Schmock, Henriette and Jensen, Peter Bj{\o}dstrup and Jensen, Lars Juhl and Brunak, S{\o}ren},
doi = {10.1038/ncomms5022},
file = {:Users/na399/GitHub/thesis/references/papers/Jensen et al.{\_}2014{\_}Temporal disease trajectories condensed from population-wide registry data covering 6.2 million patients{\_}Nature Commu.pdf:pdf},
isbn = {2041-1723},
issn = {2041-1723},
journal = {Nature Communications},
keywords = {disease:general,rank:99,relevancy:A,topic:EHR,type:research},
mendeley-tags = {disease:general,rank:99,relevancy:A,topic:EHR,type:research},
month = {jun},
number = {May},
pages = {4022},
pmid = {24959948},
title = {{Temporal disease trajectories condensed from population-wide registry data covering 6.2 million patients}},
url = {http://www.nature.com/doifinder/10.1038/ncomms5022 http://www.ncbi.nlm.nih.gov/pubmed/24959948 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4090719},
volume = {5},
year = {2014}
}
@article{Guo2017a,
author = {Guo, Zhi-gao and Gao, Xiao-guang and Ren, Hao and Yang, Yu and Di, Ruo-hai and Chen, Da-qing},
doi = {10.1016/j.ijar.2017.08.009},
file = {:Users/na399/GitHub/thesis/references/papers/Guo et al.{\_}2017{\_}Learning Bayesian network parameters from small data sets A further constrained qualitatively maximum a posteriori metho.pdf:pdf},
issn = {0888613X},
journal = {International Journal of Approximate Reasoning},
keywords = {model:Bayesian,rank:90,relevancy:B,topic:ML,type:research},
mendeley-tags = {model:Bayesian,rank:90,topic:ML,type:research,relevancy:B},
pages = {22--35},
publisher = {Elsevier Inc.},
title = {{Learning Bayesian network parameters from small data sets: A further constrained qualitatively maximum a posteriori method}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0888613X16302250},
volume = {91},
year = {2017}
}
@article{McCarty2011,
abstract = {The eMERGE (electronic MEdical Records and GEnomics) Network is an NHGRI-supported consortium of five institutions to explore the utility of DNA repositories coupled to Electronic Medical Record (EMR) systems for advancing discovery in genome science. eMERGE also includes a special emphasis on the ethical, legal and social issues related to these endeavors. The five sites are supported by an Administrative Coordinating Center. Setting of network goals is initiated by working groups: (1) Genomics, (2) Informatics, and (3) Consent {\&} Community Consultation, which also includes active participation by investigators outside the eMERGE funded sites, and (4) Return of Results Oversight Committee. The Steering Committee, comprised of site PIs and representatives and NHGRI staff, meet three times per year, once per year with the External Scientific Panel. The primary site-specific phenotypes for which samples have undergone genome-wide association study (GWAS) genotyping are cataract and HDL, dementia, electrocardiographic QRS duration, peripheral arterial disease, and type 2 diabetes. A GWAS is also being undertaken for resistant hypertension in ≈2,000 additional samples identified across the network sites, to be added to data available for samples already genotyped. Funded by ARRA supplements, secondary phenotypes have been added at all sites to leverage the genotyping data, and hypothyroidism is being analyzed as a cross-network phenotype. Results are being posted in dbGaP. Other key eMERGE activities include evaluation of the issues associated with cross-site deployment of common algorithms to identify cases and controls in EMRs, data privacy of genomic and clinically-derived data, developing approaches for large-scale meta-analysis of GWAS data across five sites, and a community consultation and consent initiative at each site. Plans are underway to expand the network in diversity of populations and incorporation of GWAS findings into clinical care. By combining advanced clinical informatics, genome science, and community consultation, eMERGE represents a first step in the development of data-driven approaches to incorporate genomic information into routine healthcare delivery.},
author = {McCarty, Catherine A. and Chisholm, Rex L. and Chute, Christopher G. and Kullo, Iftikhar J. and Jarvik, Gail P. and Larson, Eric B. and Li, Rongling and Masys, Daniel R. and Ritchie, Marylyn D. and Roden, Dan M. and Struewing, Jeffery P. and Wolf, Wendy A.},
doi = {10.1186/1755-8794-4-13},
file = {:Users/na399/GitHub/thesis/references/papers/McCarty et al.{\_}2011{\_}The eMERGE Network A consortium of biorepositories linked to electronic medical records data for conducting genomic.pdf:pdf},
isbn = {1755-8794},
issn = {17558794},
journal = {BMC Medical Genomics},
keywords = {rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
pages = {1--11},
pmid = {21269473},
title = {{The eMERGE Network: A consortium of biorepositories linked to electronic medical records data for conducting genomic studies}},
volume = {4},
year = {2011}
}
@article{Yadav2017,
abstract = {The continuously increasing cost of the US healthcare system has received significant attention. Central to the ideas aimed at curbing this trend is the use of technology, in the form of the mandate to implement electronic health records (EHRs). EHRs consist of patient information such as demographics, medications, laboratory test results, diagnosis codes and procedures. Mining EHRs could lead to improvement in patient health management as EHRs contain detailed information related to disease prognosis for large patient populations. In this manuscript, we provide a structured and comprehensive overview of data mining techniques for modeling EHR data. We first provide a detailed understanding of the major application areas to which EHR mining has been applied and then discuss the nature of EHR data and its accompanying challenges. Next, we describe major approaches used for EHR mining, the metrics associated with EHRs, and the various study designs. With this foundation, we then provide a systematic and methodological organization of existing data mining techniques used to model EHRs and discuss ideas for future research. We conclude this survey with a comprehensive summary of clinical data mining applications of EHR data, as illustrated in the online supplement.},
archivePrefix = {arXiv},
arxivId = {1702.03222},
author = {Yadav, Pranjul and Steinbach, Michael and Kumar, Vipin and Simon, Gyorgy},
doi = {10.1145/3127881},
eprint = {1702.03222},
file = {:Users/na399/GitHub/thesis/references/papers/Yadav et al.{\_}2018{\_}Mining Electronic Health Records (EHRs){\_}ACM Computing Surveys.pdf:pdf},
issn = {03600300},
journal = {ACM Computing Surveys},
keywords = {EHR,disease:general,rank:99,relevancy:A,topic:EHR,type:review},
mendeley-tags = {disease:general,rank:99,relevancy:A,topic:EHR,type:review},
month = {jan},
number = {6},
pages = {1--40},
title = {{Mining Electronic Health Records (EHRs)}},
url = {http://arxiv.org/abs/1702.03222 http://dl.acm.org/citation.cfm?doid=3161158.3127881},
volume = {50},
year = {2018}
}
@article{Ye2017,
abstract = {OBJECTIVES: This study evaluates the accuracy and transferability of Bayesian case detection systems (BCD) that use clinical notes from emergency department (ED) to detect influenza cases. METHODS: A BCD uses natural language processing (NLP) to infer the presence or absence of clinical findings from ED notes, which are fed into a Bayesain network classifier (BN) to infer patients' diagnoses. We developed BCDs at the University of Pittsburgh Medical Center (BCDUPMC) and Intermountain Healthcare in Utah (BCDIH). At each site, we manually built a rule-based NLP and trained a Bayesain network classifier from over 40,000 ED encounters between Jan. 2008 and May. 2010 using feature selection, machine learning, and expert debiasing approach. Transferability of a BCD in this study may be impacted by seven factors: development (source) institution, development parser, application (target) institution, application parser, NLP transfer, BN transfer, and classification task. We employed an ANOVA analysis to study their impacts on BCD performance. RESULTS: Both BCDs discriminated well between influenza and non-influenza on local test cases (AUCs {\textgreater} 0.92). When tested for transferability using the other institution's cases, BCDUPMC discriminations declined minimally (AUC decreased from 0.95 to 0.94, p{\textless}0.01), and BCDIH discriminations declined more (from 0.93 to 0.87, p{\textless}0.0001). We attributed the BCDIH decline to the lower recall of the IH parser on UPMC notes. The ANOVA analysis showed five significant factors: development parser, application institution, application parser, BN transfer, and classification task. CONCLUSION: We demonstrated high influenza case detection performance in two large healthcare systems in two geographically separated regions, providing evidentiary support for the use of automated case detection from routinely collected electronic clinical notes in national influenza surveillance. The transferability could be improved by training Bayesian network classifier locally and increasing the accuracy of the NLP parser.},
author = {Ye, Ye and Wagner, Michael M. and Cooper, Gregory F. and Ferraro, Jeffrey P. and Su, Howard and Gesteland, Per H. and Haug, Peter J. and Millett, Nicholas E. and Aronis, John M. and Nowalk, Andrew J. and Ruiz, Victor M. and {L{\'{o}}pez Pineda}, Arturo and Shi, Lingyun and {Van Bree}, Rudy and Ginter, Thomas and Tsui, Fuchiang},
doi = {10.1371/journal.pone.0174970},
editor = {Chuang, Jen-Hsiang},
file = {:Users/na399/GitHub/thesis/references/papers/Ye et al.{\_}2017{\_}A study of the transferability of influenza case detection systems between two large healthcare systems{\_}PLoS ONE.pdf:pdf},
isbn = {1111111111},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {disease:CD,model:Bayesian,model:NLP,rank:90,relevancy:B,topic:diagnosis,topic:transfer,type:research},
mendeley-tags = {disease:CD,model:Bayesian,model:NLP,rank:90,relevancy:B,topic:diagnosis,topic:transfer,type:research},
month = {apr},
number = {4},
pages = {e0174970},
pmid = {28380048},
title = {{A study of the transferability of influenza case detection systems between two large healthcare systems}},
url = {http://dx.plos.org/10.1371/journal.pone.0174970},
volume = {12},
year = {2017}
}
@article{Edwards1991,
abstract = {Bayesian scientific reasoning has a sound foundation in logic and provides a unified approach to the evaluation of deterministic and statistical theories, unlike its main rivals},
author = {EDWARDS, A. W. F.},
doi = {10.1038/352386b0},
file = {:Users/na399/GitHub/thesis/references/papers/Edwards{\_}1991{\_}Bayesian reasoning in science{\_}Nature.pdf:pdf},
isbn = {alphabetical},
issn = {0028-0836},
journal = {Nature},
keywords = {model:Bayesian,rank:99,relevancy:A,type:education},
mendeley-tags = {model:Bayesian,rank:99,relevancy:A,type:education},
month = {aug},
number = {6334},
pages = {386--387},
pmid = {4224},
title = {{Bayesian reasoning in science}},
url = {http://www.nature.com/doifinder/10.1038/352386b0},
volume = {352},
year = {1991}
}
@article{Calderon-Larranaga2014,
abstract = {BACKGROUND: The epidemiologic study of comorbidities of an index health problem represents a methodological challenge. This study cross-sectionally describes and analyzes the comorbidities associated with dementia in older patients and reviews the existing similarities and differences between identified comorbid diseases using the statistical methods most frequently applied in current research. METHODS: Cross-sectional study of 72,815 patients over 64 seen in 19 Spanish primary care centers during 2008. Chronic diseases were extracted from electronic health records and grouped into Expanded Diagnostic Clusters. Three different statistical methods were applied (i.e., analysis of prevalence data, multiple regression and factor analysis), stratifying by sex. RESULTS: The two most frequent comorbidities both for men and women with dementia were hypertension and diabetes. Yet, logistic regression and factor analysis demonstrated that the comorbidities significantly associated with dementia were Parkinson's disease, congestive heart failure, cerebrovascular disease, anemia, cardiac arrhythmia, chronic skin ulcers, osteoporosis, thyroid disease, retinal disorders, prostatic hypertrophy, insomnia and anxiety and neurosis. CONCLUSIONS: The analysis of the comorbidities associated with an index disease (e.g., dementia) must not be exclusively based on prevalence rates, but rather on methodologies that allow the discovery of non-random associations between diseases. A deep and reliable knowledge about how different diseases are grouped and associated around an index disease such as dementia may orient future longitudinal studies aimed at unraveling causal associations.},
author = {Calderon-Larranaga, A and Marta-Moreno, J and Hancco-Saavedra, J and Sicras-Mainar, A and Soljak, M and Prados-Torres, A},
doi = {10.1186/1471-244X-14-84},
file = {:Users/na399/GitHub/thesis/references/papers/Calderon-Larranaga et al.{\_}2014{\_}Comorbidity of dementia a cross-sectional study of primary care older patients{\_}BMC Psychiatry.pdf:pdf},
isbn = {1471-244X(Electronic)},
issn = {1471-244X},
journal = {BMC Psychiatry},
keywords = {Anxiety Disorders/ep [Epidemiology],Cerebrovascular Disorders/ep [Epidemiology],Sleep Initiation and Maintenance Disorders/ep [Epi,Spain,aged,chronic disease,comorbidity,cross sectional study,dementia/di [Diagnosis],dementia/ep [Epidemiology],diabetes mellitus/ep [Epidemiology],disease:dementia,electronic medical record,epidemiology,female,human,hypertension/ep [Epidemiology],longitudinal study,male,middle aged,prevalence,primary health care,rank:85,relevancy:A,severity of illness index,statistical model,statistics and numerical data,topic:comorbidity,type:research,very elderly},
mendeley-tags = {rank:85,disease:dementia,type:research,relevancy:A,topic:comorbidity},
pages = {84},
pmid = {24645776},
title = {{Comorbidity of dementia: a cross-sectional study of primary care older patients}},
url = {http://ovidsp.ovid.com/ovidweb.cgi?T=JS{\&}CSC=Y{\&}NEWS=N{\&}PAGE=fulltext{\&}D=emed12{\&}AN=24645776{\%}5Cnhttp://sfx.ucl.ac.uk/sfx{\_}local?sid=OVID:embase{\&}id=pmid:24645776{\&}id=doi:10.1186/1471-244X-14-84{\&}issn=1471-244X{\&}isbn={\&}volume=14{\&}issue=1{\&}spage=84{\&}pages=84{\&}date=2014{\&}ti},
volume = {14},
year = {2014}
}
@article{Mowery2016,
abstract = {BACKGROUND: In the United States, 795,000 people suffer strokes each year; 10-15 {\%} of these strokes can be attributed to stenosis caused by plaque in the carotid artery, a major stroke phenotype risk factor. Studies comparing treatments for the management of asymptomatic carotid stenosis are challenging for at least two reasons: 1) administrative billing codes (i.e., Current Procedural Terminology (CPT) codes) that identify carotid images do not denote which neurovascular arteries are affected and 2) the majority of the image reports are negative for carotid stenosis. Studies that rely on manual chart abstraction can be labor-intensive, expensive, and time-consuming. Natural Language Processing (NLP) can expedite the process of manual chart abstraction by automatically filtering reports with no/insignificant carotid stenosis findings and flagging reports with significant carotid stenosis findings; thus, potentially reducing effort, costs, and time.$\backslash$n$\backslash$nMETHODS: In this pilot study, we conducted an information content analysis of carotid stenosis mentions in terms of their report location (Sections), report formats (structures) and linguistic descriptions (expressions) from Veteran Health Administration free-text reports. We assessed an NLP algorithm, pyConText's, ability to discern reports with significant carotid stenosis findings from reports with no/insignificant carotid stenosis findings given these three document composition factors for two report types: radiology (RAD) and text integration utility (TIU) notes.$\backslash$n$\backslash$nRESULTS: We observed that most carotid mentions are recorded in prose using categorical expressions, within the Findings and Impression sections for RAD reports and within neither of these designated sections for TIU notes. For RAD reports, pyConText performed with high sensitivity (88 {\%}), specificity (84 {\%}), and negative predictive value (95 {\%}) and reasonable positive predictive value (70 {\%}). For TIU notes, pyConText performed with high specificity (87 {\%}) and negative predictive value (92 {\%}), reasonable sensitivity (73 {\%}), and moderate positive predictive value (58 {\%}). pyConText performed with the highest sensitivity processing the full report rather than the Findings or Impressions independently.$\backslash$n$\backslash$nCONCLUSION: We conclude that pyConText can reduce chart review efforts by filtering reports with no/insignificant carotid stenosis findings and flagging reports with significant carotid stenosis findings from the Veteran Health Administration electronic health record, and hence has utility for expediting a comparative effectiveness study of treatment strategies for stroke prevention.},
author = {Mowery, Danielle L. and Chapman, Brian E. and Conway, Mike and South, Brett R. and Madden, Erin and Keyhani, Salomeh and Chapman, Wendy W.},
doi = {10.1186/S13326-016-0065-1},
file = {:Users/na399/GitHub/thesis/references/papers/Mowery et al.{\_}2016{\_}Extracting a stroke phenotype risk factor from veteran health administration clinical reports An information content.pdf:pdf},
isbn = {2041-1480},
issn = {20491891},
journal = {Journal of Animal Science and Biotechnology},
keywords = {Information extraction,Natural language processing,Phenotype,Stroke,disease:CVD,model:NLP,rank:90,relevancy:C,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:CVD,model:NLP,rank:90,relevancy:C,topic:EHR,topic:prediction,type:research},
number = {1},
pages = {1--12},
pmid = {27175226},
publisher = {Journal of Biomedical Semantics},
title = {{Extracting a stroke phenotype risk factor from veteran health administration clinical reports: An information content analysis}},
url = {http://dx.doi.org/10.1186/s13326-016-0065-1},
volume = {7},
year = {2016}
}
@article{Lyall2016,
abstract = {BACKGROUND the apolipoprotein (APOE) e4 locus is a genetic risk factor for dementia. Carriers of the e4 allele may be more vulnerable to conditions that are independent risk factors for cognitive decline, such as cardiometabolic diseases. OBJECTIVE we tested whether any association with APOE e4 status on cognitive ability was larger in older ages or in those with cardiometabolic diseases. SUBJECTS UK Biobank includes over 500,000 middle- and older aged adults who have undergone detailed medical and cognitive phenotypic assessment. Around 150,000 currently have genetic data. We examined 111,739 participants with complete genetic and cognitive data. METHODS baseline cognitive data relating to information processing speed, memory and reasoning were used. We tested for interactions with age and with the presence versus absence of type 2 diabetes (T2D), coronary artery disease (CAD) and hypertension. RESULTS in several instances, APOE e4 dosage interacted with older age and disease presence to affect cognitive scores. When adjusted for potentially confounding variables, there was no APOE e4 effect on the outcome variables. CONCLUSIONS future research in large independent cohorts should continue to investigate this important question, which has potential implications for aetiology related to dementia and cognitive impairment.},
author = {Lyall, Donald M. and Ward, Joey and Ritchie, Stuart J. and Davies, Gail and Cullen, Breda and Celis, Carlos and Bailey, Mark E.S. and Anderson, Jana and Evans, Jon and Mckay, Daniel F. and Mcintosh, Andrew M. and Sattar, Naveed and Smith, Daniel J. and Deary, Ian J. and Pell, Jill P.},
doi = {10.1093/ageing/afw068},
file = {:Users/na399/GitHub/thesis/references/papers/Lyall et al.{\_}2016{\_}Alzheimer disease genetic risk factor APOE e4 and cognitive abilities in 111,739 UK Biobank participants{\_}Age and Agein.pdf:pdf},
isbn = {1468-2834 (Electronic)$\backslash$r0002-0729 (Linking)},
issn = {14682834},
journal = {Age and Ageing},
keywords = {APOE,Alzheimer disease,Cognitive ability,Epidemiology,Older people,UK Biobank,disease:dementia,rank:95,relevancy:A,topic:bioinformatics,topic:diagnosis,type:research},
mendeley-tags = {disease:dementia,rank:95,relevancy:A,topic:bioinformatics,topic:diagnosis,type:research},
number = {4},
pages = {511--517},
pmid = {27103599},
title = {{Alzheimer disease genetic risk factor APOE e4 and cognitive abilities in 111,739 UK Biobank participants}},
volume = {45},
year = {2016}
}
@article{Dubois2007,
abstract = {The NINCDS-ADRDA and the DSM-IV-TR criteria for Alzheimer's disease (AD) are the prevailing diagnostic standards in research; however, they have now fallen behind the unprecedented growth of scientific knowledge. Distinctive and reliable biomarkers of AD are now available through structural MRI, molecular neuroimaging with PET, and cerebrospinal fluid analyses. This progress provides the impetus for our proposal of revised diagnostic criteria for AD. Our framework was developed to capture both the earliest stages, before full-blown dementia, as well as the full spectrum of the illness. These new criteria are centred on a clinical core of early and significant episodic memory impairment. They stipulate that there must also be at least one or more abnormal biomarkers among structural neuroimaging with MRI, molecular neuroimaging with PET, and cerebrospinal fluid analysis of amyloid $\beta$ or tau proteins. The timeliness of these criteria is highlighted by the many drugs in development that are directed at changing pathogenesis, particularly at the production and clearance of amyloid $\beta$ as well as at the hyperphosphorylation state of tau. Validation studies in existing and prospective cohorts are needed to advance these criteria and optimise their sensitivity, specificity, and accuracy. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Dubois, Bruno and Feldman, Howard H. and Jacova, Claudia and DeKosky, Steven T. and Barberger-Gateau, Pascale and Cummings, Jeffrey and Delacourte, Andr{\'{e}} and Galasko, Douglas and Gauthier, Serge and Jicha, Gregory and Meguro, Kenichi and O'Brien, John and Pasquier, Florence and Robert, Philippe and Rossor, Martin and Salloway, Steven and Stern, Yaakov and Visser, Pieter J. and Scheltens, Philip},
doi = {10.1016/S1474-4422(07)70178-3},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/Dubois et al.{\_}2007{\_}Research criteria for the diagnosis of Alzheimer's disease revising the NINCDS-ADRDA criteria{\_}Lancet Neurology.pdf:pdf},
isbn = {1474-4422},
issn = {14744422},
journal = {The Lancet Neurology},
keywords = {disease:dementia,rank:99,relevancy:C,topic:diagnosis,topic:diagnostic criteria,type:commentary},
mendeley-tags = {disease:dementia,rank:99,relevancy:C,topic:diagnosis,topic:diagnostic criteria,type:commentary},
month = {aug},
number = {8},
pages = {734--746},
pmid = {17616482},
title = {{Research criteria for the diagnosis of Alzheimer's disease: revising the NINCDS–ADRDA criteria}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1474442207701783},
volume = {6},
year = {2007}
}
@article{Chute2014,
abstract = {Historically, clinical epidemiologic research has been constrained by the costs and time associated with manually identifying cases and abstracting clinical data. In this issue, Carrell et al. (Am J Epidemiol. 2014;000(000):000-000) report on their impressive success using natural language processing techniques to correctly identify cases of cancer recurrence among women with previous breast cancer. They report a 10-fold decrease in the need for chart abstraction, though with an 8{\%} loss in case detection. This commentary outlines some recent history associated with the development of "high-throughput clinical phenotyping" of electronic health records and speculates on the impact such computational capabilities may have for observational research and patient consent.},
author = {Chute, Christopher G.},
doi = {10.1093/aje/kwt443},
file = {:Users/na399/GitHub/thesis/references/papers/Chute{\_}2014{\_}Invited commentary Observational research in the age of the electronic health record{\_}American Journal of Epidemiology.pdf:pdf},
isbn = {1476-6256},
issn = {14766256},
journal = {American Journal of Epidemiology},
keywords = {clinical case retrieval,electronic medical records,high-throughput clinical phenotyping,natural language processing,rank:80,relevancy:C},
mendeley-tags = {rank:80,relevancy:C},
number = {6},
pages = {759--761},
pmid = {24488512},
title = {{Invited commentary: Observational research in the age of the electronic health record}},
volume = {179},
year = {2014}
}
@article{Graham2017,
abstract = {Alzheimer's disease (AD) is the primary cause of age-related dementia. Effective strategies to prevent and treat AD remain elusive despite major efforts to understand its basic biology and clinical pathophysiology. Significant investments in therapeutic drug discovery programs over the past two decades have yielded some important insights but no blockbuster drugs to alter the course of disease. Because significant memory loss and cognitive decline are associated with neuron death and loss of gray matter, especially in the frontal cortex and hippocampus, some focus in drug development has shifted to early prevention of cellular pathology. Although clinical trial design is challenging, due in part to a lack of robust biomarkers with predictive value, some optimism has come from the identification and study of inherited forms of early-onset AD and genetic risk factors that provide insights about molecular pathophysiology and potential drug targets. In addition, better understanding of the A$\beta$ amyloid pathway and the tau pathway-leading to amyloid plaques and neurofibrillary tangles, respectively, which are histopathological hallmarks of AD-continues to drive significant drug research and development programs. The main focus of this review is to summarize the most recent basic biology, biochemistry, and pharmacology that serve as a foundation for more than 50 active advanced-phase clinical trials for AD prevention and therapy.},
author = {Graham, W. Vallen and Bonito-Oliva, Alessandra and Sakmar, Thomas P.},
doi = {10.1146/annurev-med-042915-103753},
file = {:Users/na399/GitHub/thesis/references/papers/Graham, Bonito-Oliva, Sakmar{\_}2017{\_}Update on Alzheimer's Disease Therapy and Prevention Strategies{\_}Annual Review of Medicine.pdf:pdf},
isbn = {1545-326X (Electronic) 0066-4219 (Linking)},
issn = {0066-4219},
journal = {Annual Review of Medicine},
keywords = {amyloid,cognitive impairment,dementia,disease:dementia,neurodegeneration,neurofibrillary tangle,plaque,rank:99,relevancy:B,topic:prevention,topic:treatment,type:review},
mendeley-tags = {disease:dementia,rank:99,relevancy:B,topic:prevention,topic:treatment,type:review},
number = {1},
pages = {413--430},
pmid = {28099083},
title = {{Update on Alzheimer's Disease Therapy and Prevention Strategies}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-med-042915-103753},
volume = {68},
year = {2017}
}
@article{Razavian2015a,
abstract = {Abstract We present a new approach to population health, in which data-driven predictive models are learned for outcomes such as type 2 diabetes. Our approach enables risk assessment from readily available electronic claims data on large populations, without additional screening cost. Proposed model uncovers early and late-stage risk factors. Using administrative claims, pharmacy records, healthcare utilization, and laboratory results of 4.1 million individuals between 2005 and 2009, an initial set of 42,000 variables were derived that together describe the full health status and history of every individual. Machine learning was then used to methodically enhance predictive variable set and fit models predicting onset of type 2 diabetes in 2009–2011, 2010–2012, and 2011–2013. We compared the enhanced model with a parsimonious model consisting of known diabetes risk factors in a real-world environment, where missing values are common and prevalent. Furthermore, we analyzed novel and known risk factors emerg...},
author = {Razavian, Narges and Blecker, Saul and Schmidt, Ann Marie and Smith-McLallen, Aaron and Nigam, Somesh and Sontag, David},
doi = {10.1089/big.2015.0020},
file = {:Users/na399/GitHub/thesis/references/papers/Razavian et al.{\_}2015{\_}Population-Level Prediction of Type 2 Diabetes From Claims Data and Analysis of Risk Factors{\_}Big Data.pdf:pdf},
isbn = {1111111111},
issn = {2167-6461},
journal = {Big Data},
keywords = {big data analytics,data mining,disease,longitudinal study,machine learning,prediction,predictive analytics,rank:50,relevancy:A,risk assessment},
mendeley-tags = {rank:50,relevancy:A},
number = {4},
pages = {277--287},
pmid = {27441408},
title = {{Population-Level Prediction of Type 2 Diabetes From Claims Data and Analysis of Risk Factors}},
url = {http://online.liebertpub.com/doi/10.1089/big.2015.0020},
volume = {3},
year = {2015}
}
@article{Popescu2012,
abstract = {BACKGROUND: Many older adults in the US prefer to live independently for as long as they are able, despite the onset of conditions such as frailty and dementia. Solutions are needed to enable independent living, while enhancing safety and peace of mind for their families. Elderly patients are particularly at-risk for late assessment of cognitive changes. OBJECTIVES: We predict early signs of illness in older adults by using the data generated by a continuous, unobtrusive nursing home monitoring system. METHODS: We describe the possibility of employing a multiple instance learning (MIL) framework for early illness detection. The MIL framework is suitable for training classifiers when the available data presents temporal or location uncertainties. RESULTS: We provide experiments on three datasets that prove the utility of the MIL framework. We first tuned our algorithms on a set of 200 normal/abnormal behavior patterns produced by a dedicated simulator. We then conducted two retrospective studies on residents from the Tiger Place aging in place facility, aged over 70, which have been monitored with motion and bed sensors for over two years. The presence or absence of the illness was manually assessed based on the nursing visit reports. CONCLUSIONS: The use of simulated sensor data proved to be very useful for algorithm development and testing. The results obtained using MIL for six Tiger Place residents, an average area under the receiver operator characteristic curve (AROC) of 0.7, are promising. However, more sophisticated MIL classifiers are needed to improve the performance.},
author = {Popescu, Mihail and Mahnot, A.},
doi = {10.3414/ME11-02-0042},
file = {:Users/na399/GitHub/thesis/references/papers/Popescu, Mahnot{\_}2012{\_}Early illness recognition using in-home monitoring sensors and multiple instance learning{\_}Methods of Information in.pdf:pdf},
isbn = {0026-1270},
issn = {00261270},
journal = {Methods of Information in Medicine},
keywords = {Automated pattern recognition,Eldercare,Multiple instance learning,disease:dementia,rank:90,relevancy:D,topic:monitor,topic:sensor,type:research},
mendeley-tags = {disease:dementia,rank:90,relevancy:D,topic:monitor,topic:sensor,type:research},
number = {4},
pages = {359--367},
pmid = {22814617},
title = {{Early illness recognition using in-home monitoring sensors and multiple instance learning}},
volume = {51},
year = {2012}
}
@article{Abbott2011,
abstract = {The article focuses on the report "World Alzheimer Report 2010," commissioned by Alzheimer's Disease International (ADI) to asses the economic impact of dementia. The report reveals that the global economic impact of the disease in 2010 was 604 billion U.S. dollars and expects an 85{\%} cost increase by 2030 based on demographics. The report also says that less than half of people with dementia reside in high-income countries, 39{\%} in middle-income nations, and 14{\%} in low-income countries.},
author = {Abbott, Alison},
doi = {10.1038/475S2a},
file = {:Users/na399/Downloads/Research Papers/Abbott{\_}2011{\_}Dementia A problem for our age{\_}Nature.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$n0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
keywords = {disease:dementia,rank:99,relevancy:C,topic:impact,type:commentary},
mendeley-tags = {rank:99},
month = {jul},
number = {7355},
pages = {S2--S4},
pmid = {21760579},
title = {{Dementia: A problem for our age}},
url = {http://www.nature.com/doifinder/10.1038/475S2a},
volume = {475},
year = {2011}
}
@article{Krishnan2016,
abstract = {Gaussian state space models have been used for decades as generative models of sequential data. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption. We introduce a unified algorithm to efficiently learn a broad class of linear and non-linear state space models, including variants where the emission and transition distributions are modeled by deep neural networks. Our learning algorithm simultaneously learns a compiled inference network and the generative model, leveraging a structured variational approximation parameterized by recurrent neural networks to mimic the posterior distribution. We apply the learning algorithm to both synthetic and real-world datasets, demonstrating its scalability and versatility. We find that using the structured approximation to the posterior results in models with significantly higher held-out likelihood.},
archivePrefix = {arXiv},
arxivId = {1609.09869},
author = {Krishnan, Rahul G. and Shalit, Uri and Sontag, David},
eprint = {1609.09869},
file = {:Users/na399/GitHub/thesis/references/papers/Krishnan, Shalit, Sontag{\_}2016{\_}Structured Inference Networks for Nonlinear State Space Models{\_}Unknown.pdf:pdf},
keywords = {rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
title = {{Structured Inference Networks for Nonlinear State Space Models}},
url = {http://arxiv.org/abs/1609.09869},
year = {2016}
}
@article{McCoy2016,
abstract = {Background Delirium is an acute neuropsychiatric syndrome that portends poor prognosis and represents a significant burden to the health care system. Although detection allows for efficacious treatment, the diagnosis is frequently overlooked. This underdiagnosis makes delirium an appealing target for translational predictive algorithmic modeling; however, such approaches require accurate identification in clinical training datasets. Methods Using the Massachusetts All-Payers Claims Database, encompassing health claims for Massachusetts residents for 2012, we calculated the rate of delirium diagnosis in index hospitalizations by reported ICD-9 diagnosis code. We performed a review of published studies formally assessing delirium to establish an expected rate of delirium when formally assessed. Secondarily, we reported a sociodemographic comparison of cases and noncases. Results Rates of delirium reported in the literature vary widely, from 3.6-73{\%} with a mean of 23.6{\%}. The statewide claims data (Massachusetts All-Payers Claims Database) identified the rate of delirium among index hospitalizations to be only 2.1{\%}. For Massachusetts All-Payers Claims Database hospitalizations, delirium was coded in 2.8{\%} of patients {\textgreater}65 years old and for 1.2{\%} of patients ≤65. Conclusion The lower incidence of delirium in claims data may reflect a failure to diagnose, a failure to code, or a lower rate in community hospitals. The relative absence of the phenotype from large databases may limit the utility of data-driven predictive modeling to the problem of delirium recognition.},
author = {McCoy, Thomas H. and Snapper, Leslie and Stern, Theodore A. and Perlis, Roy H.},
doi = {10.1016/j.psym.2016.06.001},
file = {:Users/na399/GitHub/thesis/references/papers/McCoy et al.{\_}2016{\_}Underreporting of Delirium in Statewide Claims Data Implications for Clinical Care and Predictive Modeling{\_}Psychosomat.pdf:pdf},
issn = {00333182},
journal = {Psychosomatics},
keywords = {claims data,delirium,predictive modeling.,prevalence,rank:70,relevancy:B},
mendeley-tags = {rank:70,relevancy:B},
month = {sep},
number = {5},
pages = {480--488},
pmid = {27480944},
publisher = {Elsevier},
title = {{Underreporting of Delirium in Statewide Claims Data: Implications for Clinical Care and Predictive Modeling}},
url = {http://dx.doi.org/10.1016/j.psym.2016.06.001 http://linkinghub.elsevier.com/retrieve/pii/S0033318216300561},
volume = {57},
year = {2016}
}
@article{Ye2014,
abstract = {OBJECTIVES: To evaluate factors affecting performance of influenza detection, including accuracy of natural language processing (NLP), discriminative ability of Bayesian network (BN) classifiers, and feature selection.$\backslash$n$\backslash$nMETHODS: We derived a testing dataset of 124 influenza patients and 87 non-influenza (shigellosis) patients. To assess NLP finding-extraction performance, we measured the overall accuracy, recall, and precision of Topaz and MedLEE parsers for 31 influenza-related findings against a reference standard established by three physician reviewers. To elucidate the relative contribution of NLP and BN classifier to classification performance, we compared the discriminative ability of nine combinations of finding-extraction methods (expert, Topaz, and MedLEE) and classifiers (one human-parameterized BN and two machine-parameterized BNs). To assess the effects of feature selection, we conducted secondary analyses of discriminative ability using the most influential findings defined by their likelihood ratios.$\backslash$n$\backslash$nRESULTS: The overall accuracy of Topaz was significantly better than MedLEE (with post-processing) (0.78 vs 0.71, p{\textless}0.0001). Classifiers using human-annotated findings were superior to classifiers using Topaz/MedLEE-extracted findings (average area under the receiver operating characteristic (AUROC): 0.75 vs 0.68, p=0.0113), and machine-parameterized classifiers were superior to the human-parameterized classifier (average AUROC: 0.73 vs 0.66, p=0.0059). The classifiers using the 17 'most influential' findings were more accurate than classifiers using all 31 subject-matter expert-identified findings (average AUROC: 0.76{\textgreater}0.70, p{\textless}0.05).$\backslash$n$\backslash$nCONCLUSIONS: Using a three-component evaluation method we demonstrated how one could elucidate the relative contributions of components under an integrated framework. To improve classification performance, this study encourages researchers to improve NLP accuracy, use a machine-parameterized classifier, and apply feature selection methods.},
author = {Ye, Ye and Tsui, Fuchiang Rich and Wagner, Michael and Espino, Jeremy U. and Li, Qi},
doi = {10.1136/amiajnl-2013-001934},
file = {:Users/na399/GitHub/thesis/references/papers/Ye et al.{\_}2014{\_}Influenza detection from emergency department reports using natural language processing and Bayesian network classifiers{\_}.pdf:pdf},
isbn = {1067-5027, 1527-974X},
issn = {1527974X},
journal = {Journal of the American Medical Informatics Association},
keywords = {disease:CD,rank:90,relevancy:B,topic:prediction,type:research},
mendeley-tags = {disease:CD,rank:90,relevancy:B,topic:prediction,type:research},
number = {5},
pages = {815--823},
pmid = {24406261},
title = {{Influenza detection from emergency department reports using natural language processing and Bayesian network classifiers}},
volume = {21},
year = {2014}
}
@article{Kovalchuk2017,
abstract = {The UK government has recently recognised the need to improve mental health services in the country. Electronic health records provide a rich source of patient data which could help policymakers to better understand needs of the service users. The main objective of this study is to unveil statistics of diagnoses recorded in the Case Register of the South London and Maudsley NHS Foundation Trust, one of the largest mental health providers in the UK and Europe serving a source population of over 1.2 million people residing in south London. Based on over 500,000 diagnoses recorded in ICD10 codes for a cohort of approximately 200,000 mental health patients, we established frequency rate of each diagnosis (the ratio of the number of patients for whom a diagnosis has ever been recorded to the number of patients in the entire population who have made contact with mental disorders). Wealso investigated differences in diagnoses prevalence between subgroups of patients stratified by gender and ethnicity. The most common diagnoses in the considered population were (recurrent) depression (ICD10 codes F32-33; 16.4{\%} of patients), reaction to severe stress and adjustment disorders (F43; 7.1{\%}), mental/behavioural disorders due to use of alcohol (F10; 6.9{\%}), and schizophrenia (F20; 5.6{\%}).Wealso found many diagnoses which were more likely to be recorded in patients of a certain gender or ethnicity. For example, mood (affective) disorders (F31-F39); neurotic, stress-related and somatoform disorders (F40- F48, except F42); and eating disorders (F50) were more likely to be found in records of female patients, while males were more likely to be diagnosed with mental/behavioural dis- orders due to psychoactive substance use (F10-F19). Furthermore, mental/behavioural dis- orders due to use of alcohol and opioids were more likely to be recorded in patients of white ethnicity, and disorders due to use of cannabinoids in those of black ethnicity.},
author = {Kovalchuk, Yevgeniya and Stewart, Robert and Broadbent, Matthew and Hubbard, Tim J. P. and Dobson, Richard J. B.},
doi = {10.1371/journal.pone.0171526},
editor = {Abe, Takeru},
file = {:Users/na399/GitHub/thesis/references/papers/Kovalchuk et al.{\_}2017{\_}Analysis of diagnoses extracted from Electronic health records in a large mental health Case Register{\_}PLoS ONE.pdf:pdf},
isbn = {1111111111},
issn = {1932-6203},
journal = {PLOS ONE},
keywords = {disease:psychiatry,rank:90,relevancy:D,topic:EHR,type:research},
mendeley-tags = {disease:psychiatry,rank:90,relevancy:D,topic:EHR,type:research},
month = {feb},
number = {2},
pages = {e0171526},
pmid = {28207753},
title = {{Analysis of diagnoses extracted from electronic health records in a large mental health case register}},
url = {http://dx.plos.org/10.1371/journal.pone.0171526},
volume = {12},
year = {2017}
}
@article{Swainson2001,
abstract = {The development of novel treatments for Alzheimer's disease (AD), aimed at ameliorating symptoms and modifying disease processes, increases the need for early diagnosis. Neuropsychological deficits such as poor episodic memory are a consistent feature of early-in-the-course AD, but they overlap with the cognitive impairments in other disorders such as depression, making differential diagnosis difficult. Computerised and traditional tests of memory, attention and executive function were given to four subject groups: mild AD (n = 26); questionable dementia (QD; n = 43); major depression (n = 37) and healthy controls (n = 39). A visuo-spatial associative learning test accurately distinguished AD from depressed/control subjects and revealed an apparent sub-group of QD patients who performed like AD patients. QD patients' performance correlated with the degree of subsequent global cognitive decline. Elements of contextual and cued recall may account for the task's sensitivity and specificity for AD.},
author = {Swainson, R. and Hodges, J R and Galton, C J and Semple, J. and Michael, A. and Dunn, B D and Iddon, J L and Robbins, T W and Sahakian, B J},
doi = {10.1159/000051269},
file = {:Users/na399/Downloads/Research Papers/Swainson et al.{\_}2001{\_}Early Detection and Differential Diagnosis of Alzheimer ' s Disease and Depression with{\_}Dementia and Geriatric Co.pdf:pdf},
issn = {1420-8008},
journal = {Dementia and geriatric cognitive disorders},
keywords = {diagnosis w neural and,disease:dementia,early detection w alzheimer,neuropsychological assessment w differential,pharmacotherapeutic,rank:85,relevancy:A,s disease w depression,topic:diagnosis,type:research,w},
mendeley-tags = {rank:85,disease:dementia,type:research,topic:diagnosis,relevancy:A},
number = {4},
pages = {265--80},
pmid = {11351138},
title = {{Early detection and differential diagnosis of Alzheimer's disease and depression with neuropsychological tasks.}},
url = {https://www.karger.com/Article/FullText/51269 http://www.ncbi.nlm.nih.gov/pubmed/11351138},
volume = {12},
year = {2001}
}
@incollection{Czekierda2015,
address = {Berlin, M{\"{u}}nchen, Boston},
author = {Czekierda, {\L}ukasz and Gackowski, Andrzej and Konieczny, Marek and Malawski, Filip and Ska{\l}kowski, Kornel and Szyd{\l}o, Tomasz and Zieli{\'{n}}ski, Krzysztof},
booktitle = {Simulations in Medicine},
doi = {10.1515/9783110406344-015},
file = {:Users/na399/GitHub/thesis/references/papers/Czekierda et al.{\_}2015{\_}From telemedicine to modeling and proactive medicine{\_}Simulations in Medicine Pre-Clinical and Clinical Application.pdf:pdf},
isbn = {9783110406344},
keywords = {rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
pages = {271--294},
publisher = {DE GRUYTER},
title = {{13. From telemedicine to modeling and proactive medicine}},
url = {https://www.degruyter.com/view/books/9783110406344/9783110406344-015/9783110406344-015.xml},
year = {2015}
}
@article{Ben-Assuli2016,
abstract = {In the last decade, health providers have implemented information systems to improve accuracy in medical diagnosis and decision-making. This article evaluates the impact of an electronic health record on emergency department physicians' diagnosis and admission decisions. A decision analytic approach using a decision tree was constructed to model the admission decision process to assess the added value of medical information retrieved from the electronic health record. Using a Bayesian statistical model, this method was evaluated on two coronary artery disease scenarios. The results show that the cases of coronary artery disease were better diagnosed when the electronic health record was consulted and led to more informed admission decisions. Furthermore, the value of medical information required for a specific admission decision in emergency departments could be quantified. The findings support the notion that physicians and patient healthcare can benefit from implementing electronic health record systems in emergency departments.},
author = {Ben-Assuli, Ofir and Leshno, Moshe},
doi = {10.1177/1460458215584203},
file = {:Users/na399/GitHub/thesis/references/papers/Ben-Assuli, Leshno{\_}2016{\_}Assessing electronic health record systems in emergency departments Using a decision analytic Bayesian model{\_}Hea.pdf:pdf},
issn = {1460-4582},
journal = {Health Informatics Journal},
keywords = {Bayesian statistics,decision support systems,decision trees,electronic health records,emergency department,medical decision-making,rank:65,relevancy:B},
mendeley-tags = {rank:65,relevancy:B},
month = {sep},
number = {3},
pages = {712--729},
title = {{Assessing electronic health record systems in emergency departments: Using a decision analytic Bayesian model}},
url = {http://journals.sagepub.com/doi/10.1177/1460458215584203},
volume = {22},
year = {2016}
}
@article{Kim2017b,
abstract = {{\textcopyright} 2017 The Author(s).Background: Rapid advancement of next generation sequencing technologies such as whole genome sequencing (WGS) has facilitated the search for genetic factors that influence disease risk in the field of human genetics. To identify rare variants associated with human diseases or traits, an efficient genome-wide binning approach is needed. In this study we developed a novel biological knowledge-based binning approach for rare-variant association analysis and then applied the approach to structural neuroimaging endophenotypes related to late-onset Alzheimer's disease (LOAD). Methods: For rare-variant analysis, we used the knowledge-driven binning approach implemented in Bin-KAT, an automated tool, that provides 1) binning/collapsing methods for multi-level variant aggregation with a flexible, biologically informed binning strategy and 2) an option of performing unified collapsing and statistical rare variant analyses in one tool. A total of 750 non-Hispanic Caucasian participants from the Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort who had both WGS data and magnetic resonance imaging (MRI) scans were used in this study. Mean bilateral cortical thickness of the entorhinal cortex extracted from MRI scans was used as an AD-related neuroimaging endophenotype. SKAT was used for a genome-wide gene- and region-based association analysis of rare variants (MAF (minor allele frequency) {\textless} 0.05) and potential confounding factors (age, gender, years of education, intracranial volume (ICV) and MRI field strength) for entorhinal cortex thickness were used as covariates. Significant associations were determined using FDR adjustment for multiple comparisons. Results: Our knowledge-driven binning approach identified 16 functional exonic rare variants in FANCC significantly associated with entorhinal cortex thickness (FDR-corrected p-value {\textless} 0.05). In addition, the approach identified 7 evolutionary conserved regions, which were mapped to FAF1, RFX7, LYPLAL1 and GOLGA3, significantly associated with entorhinal cortex thickness (FDR-corrected p-value {\textless} 0.05). In further analysis, the functional exonic rare variants in FANCC were also significantly associated with hippocampal volume and cerebrospinal fluid (CSF) A$\beta$1-42 (p-value {\textless} 0.05). Conclusions: Our novel binning approach identified rare variants in FANCC as well as 7 evolutionary conserved regions significantly associated with a LOAD-related neuroimaging endophenotype. FANCC (fanconi anemia complementation group C) has been shown to modulate TLR and p38 MAPK-dependent expression of IL-1$\beta$ in macrophages. Our results warrant further investigation in a larger independent cohort and demonstrate that the biological knowledge-driven binning approach is a powerful strategy to identify rare variants associated with AD and other complex disease.},
author = {Kim, Dokyoon and Basile, Anna O. and Bang, Lisa and Horgusluoglu, Emrin and Lee, Seunggeun and Ritchie, Marylyn D. and Saykin, Andrew J. and Nho, Kwangsik},
doi = {10.1186/s12911-017-0454-0},
file = {:Users/na399/GitHub/thesis/references/papers/Kim et al.{\_}2017{\_}Knowledge-driven binning approach for rare variant association analysis application to neuroimaging biomarkers in Alzh.pdf:pdf},
issn = {14726947},
journal = {BMC Medical Informatics and Decision Making},
keywords = {Alzheimer's disease,Imaging genomics,Rare variant analysis,disease:dementia,rank:80,relevancy:C},
mendeley-tags = {rank:80,relevancy:C,disease:dementia},
number = {Suppl 1},
pages = {1--7},
title = {{Knowledge-driven binning approach for rare variant association analysis: application to neuroimaging biomarkers in Alzheimer's disease}},
volume = {17},
year = {2017}
}
@article{Brenner2013,
abstract = {We give a new consistent scoring function for structure learning of Bayesian networks. In contrast to traditional approaches to score-based structure learning, such as BDeu or MDL, the complexity penalty that we pro-pose is data-dependent and is given by the probability that a conditional independence test correctly shows that an edge cannot ex-ist. What really distinguishes this new scor-ing function from earlier work is that it has the property of becoming computationally easier to maximize as the amount of data in-creases. We prove a polynomial sample com-plexity result, showing that maximizing this score is guaranteed to correctly learn a struc-ture with no false edges and a distribution close to the generating distribution, when-ever there exists a Bayesian network which is a perfect map for the data generating distri-bution. Although the new score can be used with any search algorithm, we give empirical results showing that it is particularly effec-tive when used together with a linear pro-gramming relaxation approach to Bayesian network structure learning.},
author = {Brenner, Eliot and Sontag, David},
file = {:Users/na399/GitHub/thesis/references/papers/Brenner, Sontag{\_}2013{\_}SparsityBoost A New Scoring Function for Learning Bayesian Network Structure{\_}Proceedings of the Twenty-Ninth Confer.pdf:pdf},
journal = {Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial Intelligence ({\{}UAI{\}}-13)},
keywords = {rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
pages = {112--121},
title = {{SparsityBoost: A New Scoring Function for Learning Bayesian Network Structure}},
url = {http://www.cs.nyu.edu/{~}dsontag/papers/BrennerSontag{\_}uai13.pdf},
year = {2013}
}
@article{Seixas2014,
abstract = {Population aging has been occurring as a global phenomenon with heterogeneous consequences in both developed and developing countries. Neurodegenerative diseases, such as Alzheimer׳s Disease (AD), have high prevalence in the elderly population. Early diagnosis of this type of disease allows early treatment and improves patient quality of life. This paper proposes a Bayesian network decision model for supporting diagnosis of dementia, AD and Mild Cognitive Impairment (MCI). Bayesian networks are well-suited for representing uncertainty and causality, which are both present in clinical domains. The proposed Bayesian network was modeled using a combination of expert knowledge and data-oriented modeling. The network structure was built based on current diagnostic criteria and input from physicians who are experts in this domain. The network parameters were estimated using a supervised learning algorithm from a dataset of real clinical cases. The dataset contains data from patients and normal controls from the Duke University Medical Center (Washington, USA) and the Center for Alzheimer׳s Disease and Related Disorders (at the Institute of Psychiatry of the Federal University of Rio de Janeiro, Brazil). The dataset attributes consist of predisposal factors, neuropsychological test results, patient demographic data, symptoms and signs. The decision model was evaluated using quantitative methods and a sensitivity analysis. In conclusion, the proposed Bayesian network showed better results for diagnosis of dementia, AD and MCI when compared to most of the other well-known classifiers. Moreover, it provides additional useful information to physicians, such as the contribution of certain factors to diagnosis.},
author = {Seixas, Fl{\'{a}}vio Luiz and Zadrozny, Bianca and Laks, Jerson and Conci, Aura and {Muchaluat Saade}, D{\'{e}}bora Christina},
doi = {10.1016/j.compbiomed.2014.04.010},
file = {:Users/na399/GitHub/thesis/references/papers/Seixas et al.{\_}2014{\_}A Bayesian network decision model for supporting the diagnosis of dementia, Alzheimer׳s disease and mild cognitive i.pdf:pdf},
isbn = {0010-4825},
issn = {00104825},
journal = {Computers in Biology and Medicine},
keywords = {Alzheimer׳s disease,Bayesian network,Clinical decision support system,Dementia,Mild cognitive impairment,clinical decision support system,disease:dementia,model:Bayesian,rank:70,relevancy:A,topic:CDSS},
mendeley-tags = {rank:70,relevancy:A,model:Bayesian,disease:dementia,topic:CDSS},
pages = {140--158},
pmid = {24946259},
publisher = {Elsevier},
title = {{A Bayesian network decision model for supporting the diagnosis of dementia, Alzheimer׳s disease and mild cognitive impairment}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0010482514000961},
volume = {51},
year = {2014}
}
@article{Kourou2015,
abstract = {Cancer has been characterized as a heterogeneous disease consisting of many different subtypes. The early diagnosis and prognosis of a cancer type have become a necessity in cancer research, as it can facilitate the subsequent clinical management of patients. The importance of classifying cancer patients into high or low risk groups has led many research teams, from the biomedical and the bioinformatics field, to study the application of machine learning (ML) methods. Therefore, these techniques have been utilized as an aim to model the progression and treatment of cancerous conditions. In addition, the ability of ML tools to detect key features from complex datasets reveals their importance. A variety of these techniques, including Artificial Neural Networks (ANNs), Bayesian Networks (BNs), Support Vector Machines (SVMs) and Decision Trees (DTs) have been widely applied in cancer research for the development of predictive models, resulting in effective and accurate decision making. Even though it is evident that the use of ML methods can improve our understanding of cancer progression, an appropriate level of validation is needed in order for these methods to be considered in the everyday clinical practice. In this work, we present a review of recent ML approaches employed in the modeling of cancer progression. The predictive models discussed here are based on various supervised ML techniques as well as on different input features and data samples. Given the growing trend on the application of ML methods in cancer research, we present here the most recent publications that employ these techniques as an aim to model cancer risk or patient outcomes.},
archivePrefix = {arXiv},
arxivId = {9781591404590},
author = {Kourou, Konstantina and Exarchos, Themis P. and Exarchos, Konstantinos P. and Karamouzis, Michalis V. and Fotiadis, Dimitrios I.},
doi = {10.1016/j.csbj.2014.11.005},
eprint = {9781591404590},
file = {:Users/na399/GitHub/thesis/references/papers/Kourou et al.{\_}2015{\_}Machine learning applications in cancer prognosis and prediction{\_}Computational and Structural Biotechnology Journal.pdf:pdf},
isbn = {2001-0370 (Electronic)$\backslash$r2001-0370 (Linking)},
issn = {20010370},
journal = {Computational and Structural Biotechnology Journal},
keywords = {Cancer recurrence,Cancer survival,Cancer susceptibility,Machine learning,Predictive models,disease:cancer,rank:85,relevancy:A,topic:ML,topic:prediction,type:review},
mendeley-tags = {disease:cancer,rank:85,relevancy:A,topic:ML,topic:prediction,type:review},
pages = {8--17},
pmid = {25750696},
publisher = {Elsevier B.V.},
title = {{Machine learning applications in cancer prognosis and prediction}},
url = {http://dx.doi.org/10.1016/j.csbj.2014.11.005},
volume = {13},
year = {2015}
}
@article{Lee2016a,
abstract = {Background and objective Fall risk assessment is the first step toward prevention, and a risk assessment tool with high validity should be used. This study aimed to develop and validate an automated fall risk assessment system (Auto-FallRAS) to assess fall risks based on electronic medical records (EMRs) without additional data collected or entered by nurses.Methods This study was conducted in a 1335-bed university hospital in Seoul, South Korea. The Auto-FallRAS was developed using 4211 fall-related clinical data extracted from EMRs. Participants included fall patients and non-fall patients (868 and 3472 for the development study; 752 and 3008 for the validation study; and 58 and 232 for validation after clinical application, respectively). The system was evaluated for predictive validity and concurrent validity.Results The final 10 predictors were included in the logistic regression model for the risk-scoring algorithm. The results of the Auto-FallRAS were shown as high/moderate/low risk on the EMR screen. The predictive validity analyzed after clinical application of the Auto-FallRAS was as follows: sensitivity = 0.95, NPV = 0.97 and Youden index = 0.44. The validity of the Morse Fall Scale assessed by nurses was as follows: sensitivity = 0.68, NPV = 0.88 and Youden index = 0.28.Conclusion This study found that the Auto-FallRAS results were better than were the nurses{\&}{\#}039; predictions. The advantage of the Auto-FallRAS is that it automatically analyzes information and shows patients{\&}{\#}039; fall risk assessment results without requiring additional time from nurses.},
author = {Lee, Ju Young and Jin, Yinji and Piao, Jinshi and Lee, Sun-Mi},
doi = {10.1093/intqhc/mzv122},
file = {:Users/na399/GitHub/thesis/references/papers/Lee et al.{\_}2016{\_}Development and evaluation of an automated fall risk assessment system{\_}International Journal for Quality in Health Care.pdf:pdf},
isbn = {1353-4505},
issn = {1353-4505},
journal = {International Journal for Quality in Health Care},
keywords = {accidental falls,prevention,rank:90,relevancy:C,risk assessment,topic:EHR,topic:prediction,type:research,validity},
mendeley-tags = {rank:90,relevancy:C,topic:EHR,topic:prediction,type:research},
number = {2},
pages = {175--182},
title = {{Development and evaluation of an automated fall risk assessment system}},
url = {https://academic.oup.com/intqhc/article-lookup/doi/10.1093/intqhc/mzv122},
volume = {28},
year = {2016}
}
@article{Beinhoff2005,
abstract = {The current increase in aged individuals in number and proportion of the general population warrants dependable strategies to improve early detection of cognitive impairment. It was the goal of the present study to develop a triage for bedside testing and outpatient services. In a prospective clinical cohort study at the outpatient Memory Clinic, University of Ulm, Germany, 232 subjects were diagnosed with Alzheimer's disease [AD; NINCDS-ADRDA criteria; n = 66; age 65.9 +/- 7.3 years (mean +/- SD); Mini Mental State Examination (MMSE) score 23.4 +/- 4.1], mild cognitive impairment (MCI; criteria of Petersen et al.; n = 48; age 66.4 +/- 7.1 years; MMSE score 28.3 +/- 1.5), and major depressive disorder (DSM-IV criteria; n = 61; age 63.4 +/- 8.0 years; MMSE score 28.6 +/- 1.6). Diagnosis was secured with extensive neuropsychological, clinical, radiological, and laboratory investigations. Six brief screening tests including the Memory Impairment Screen (MIS), Letter Sorting Test (LST), Verbal Fluency (VF), and Clock Drawing Test (CDT) were assessed independently from the diagnostic procedure. We compared single items and composite scores. LST yielded a diagnostic accuracy of 0.81 and 0.62 for AD and MCI patients versus controls, respectively. With the MIS, diagnostic accuracy was 0.89 and 0.71, respectively. With a combination of LST, MIS, VF, and CDT, a sensitivity for AD and MCI patients of 1.00 and 0.83 was achieved. Thus, single-item screening (e.g. LST, VF) taking little more than 1 min and suitable for bedside testing or brief screening in the general practitioner's office yields diagnostic accuracy comparable to standard laboratory tests for other diseases. A composite of screening tests suitable for application in general outpatient care in neurological and psychiatric services reliably detects patients with AD and MCI.},
author = {Beinhoff, Ulrike and Hilbert, Verena and Bittner, Daniel and Gron, Georg and Riepe, Matthias W.},
doi = {10.1159/000088249},
file = {:Users/na399/Downloads/Research Papers/Beinhoff et al.{\_}2005{\_}Screening for cognitive impairment A triage for outpatient care{\_}Dementia and Geriatric Cognitive Disorders.pdf:pdf},
isbn = {1420-8008},
issn = {1420-8008},
journal = {Dementia and geriatric cognitive disorders},
keywords = {Alzheimer's disease,Cognitive impairment,Major depression,Mild cognitive impairment,Neuropsychological investigations,Screening tests,disease:dementia,rank:85,relevancy:B,topic:diagnosis,type:research},
mendeley-tags = {disease:dementia,rank:85,relevancy:B,topic:diagnosis,type:research},
number = {5},
pages = {278--85},
pmid = {16158010},
title = {{Screening for cognitive impairment: a triage for outpatient care.}},
url = {https://www.karger.com/Article/FullText/88249 http://www.ncbi.nlm.nih.gov/pubmed/16158010},
volume = {20},
year = {2005}
}
@article{Beaulieu-Jones2016,
abstract = {Patient interactions with health care providers result in entries to electronic health records (EHRs). EHRs were built for clinical and billing purposes but contain many data points about an individual. Mining these records provides opportunities to extract electronic phenotypes, which can be paired with genetic data to identify genes underlying common human diseases. This task remains challenging: high quality phenotyping is costly and requires physician review; many fields in the records are sparsely filled; and our definitions of diseases are continuing to improve over time. Here we develop and evaluate a semi-supervised learning method for EHR phenotype extraction using denoising autoencoders for phenotype stratification. By combining denoising autoencoders with random forests we find classification improvements across multiple simulation models and improved survival prediction in ALS clinical trial data. This is particularly evident in cases where only a small number of patients have high quality phenotypes, a common scenario in EHR-based research. Denoising autoencoders perform dimensionality reduction enabling visualization and clustering for the discovery of new subtypes of disease. This method represents a promising approach to clarify disease subtypes and improve genotype-phenotype association studies that leverage EHRs.},
author = {Beaulieu-Jones, Brett K. and Greene, Casey S.},
doi = {10.1016/j.jbi.2016.10.007},
file = {:Users/na399/GitHub/thesis/references/papers/Beaulieu-Jones, Greene{\_}2016{\_}Semi-supervised learning of the electronic health record for phenotype stratification{\_}Journal of Biomedical.pdf:pdf},
isbn = {1532-0480 (Electronic) 1532-0464 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Denoising autoencoder,Disease subtyping,Electronic health record,Electronic phenotyping,Patient stratification,Unsupervised,rank:85,relevancy:C,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {rank:85,type:research,topic:EHR,topic:phenotyping,relevancy:C},
pages = {168--178},
pmid = {27744022},
publisher = {The Author(s)},
title = {{Semi-supervised learning of the electronic health record for phenotype stratification}},
url = {http://dx.doi.org/10.1016/j.jbi.2016.10.007},
volume = {64},
year = {2016}
}
@article{Arandjelovic2015,
abstract = {MOTIVATION: Electronic medical records, nowadays routinely collected in many developed countries, open a new avenue for medical knowledge acquisition. In this paper this vast amount of information is used to develop a novel model for hospital admission type prediction. RESULTS: I introduce a novel model for hospital admission type prediction based on the representation of a patient's medical history in the form of a binary history vector. This representation is motivated using empirical evidence from previous work and validated using a large data corpus of medical records from a local hospital. The proposed model allows exploration, visualization, and patient-specific prognosis making in an intuitive and readily understood manner. Its power is demonstrated using a large, real-world data corpus collected by a local hospital on which it is shown to outperform previous state-of-the-art in the literature, achieving over 82{\%} accuracy in the prediction of the first future diagnosis. The model was vastly superior for long-term prognosis as well, outperforming previous work in 82{\%} of the cases, while producing comparable performance in the remaining 18{\%} of the cases. AVAILABILITY: Full Matlab source code is freely available for download at: http://ognjen-arandjelovic.t15.org/data/dprog.zip CONTACT: ognjen.arandjelovic@gmail.com.},
author = {Arandjelovi{\'{c}}, Ognjen},
doi = {10.1093/bioinformatics/btv508},
file = {:Users/na399/GitHub/thesis/references/papers/Arandjelovi{\'{c}}{\_}2015{\_}Discovering hospital admission patterns using models learnt from electronic hospital records{\_}Bioinformatics.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
keywords = {disease:general,model:Bayesian,model:Markov,rank:99,relevancy:A,topic:EHR,topic:comorbidity,topic:prediction,type:research},
mendeley-tags = {disease:general,model:Bayesian,model:Markov,rank:99,relevancy:A,topic:EHR,topic:comorbidity,topic:prediction,type:research},
number = {24},
pages = {3970--3976},
pmid = {26338769},
title = {{Discovering hospital admission patterns using models learnt from electronic hospital records}},
volume = {31},
year = {2015}
}
@article{Lipton2016,
abstract = {Supervised machine learning models boast remarkable predictive capabilities. But can you trust your model? Will it work in deployment? What else can it tell you about the world? We want models to be not only good, but interpretable. And yet the task of interpretation appears underspecified. Papers provide diverse and sometimes non-overlapping motivations for interpretability, and offer myriad notions of what attributes render models interpretable. Despite this ambiguity, many papers proclaim interpretability axiomatically, absent further explanation. In this paper, we seek to refine the discourse on interpretability. First, we examine the motivations underlying interest in interpretability, finding them to be diverse and occasionally discordant. Then, we address model properties and techniques thought to confer interpretability, identifying transparency to humans and post-hoc explanations as competing notions. Throughout, we discuss the feasibility and desirability of different notions, and question the oft-made assertions that linear models are interpretable and that deep neural networks are not.},
archivePrefix = {arXiv},
arxivId = {1606.03490},
author = {Lipton, Zachary C.},
eprint = {1606.03490},
file = {:Users/na399/Downloads/Research Papers/Lipton{\_}2016{\_}The Mythos of Model Interpretability{\_}Unknown.pdf:pdf},
keywords = {rank:n/a,relevancy:C},
mendeley-tags = {rank:n/a,relevancy:C},
month = {jun},
number = {Whi},
title = {{The Mythos of Model Interpretability}},
url = {http://arxiv.org/abs/1606.03490},
year = {2016}
}
@article{Newton2013,
abstract = {BACKGROUND: Genetic studies require precise phenotype definitions, but electronic medical record (EMR) phenotype data are recorded inconsistently and in a variety of formats. OBJECTIVE: To present lessons learned about validation of EMR-based phenotypes from the Electronic Medical Records and Genomics (eMERGE) studies. MATERIALS AND METHODS: The eMERGE network created and validated 13 EMR-derived phenotype algorithms. Network sites are Group Health, Marshfield Clinic, Mayo Clinic, Northwestern University, and Vanderbilt University. RESULTS: By validating EMR-derived phenotypes we learned that: (1) multisite validation improves phenotype algorithm accuracy; (2) targets for validation should be carefully considered and defined; (3) specifying time frames for review of variables eases validation time and improves accuracy; (4) using repeated measures requires defining the relevant time period and specifying the most meaningful value to be studied; (5) patient movement in and out of the health plan (transience) can result in incomplete or fragmented data; (6) the review scope should be defined carefully; (7) particular care is required in combining EMR and research data; (8) medication data can be assessed using claims, medications dispensed, or medications prescribed; (9) algorithm development and validation work best as an iterative process; and (10) validation by content experts or structured chart review can provide accurate results. CONCLUSIONS: Despite the diverse structure of the five EMRs of the eMERGE sites, we developed, validated, and successfully deployed 13 electronic phenotype algorithms. Validation is a worthwhile process that not only measures phenotype performance but also strengthens phenotype algorithm definitions and enhances their inter-institutional sharing.},
author = {Newton, Katherine M. and Peissig, Peggy L. and Kho, Abel Ngo and Bielinski, Suzette J. and Berg, Richard L. and Choudhary, Vidhu and Basford, Melissa and Chute, Christopher G. and Kullo, Iftikhar J. and Li, Rongling and Pacheco, Jennifer A. and Rasmussen, Luke V. and Spangler, Leslie and Denny, Joshua C.},
doi = {10.1136/amiajnl-2012-000896},
file = {:Users/na399/GitHub/thesis/references/papers/Newton et al.{\_}2013{\_}Validation of electronic medical record-based phenotyping algorithms Results and lessons learned from the eMERGE netw.pdf:pdf},
isbn = {1527-974X (Electronic)$\backslash$n1067-5027 (Linking)},
issn = {10675027},
journal = {Journal of the American Medical Informatics Association},
keywords = {rank:90,relevancy:C,topic:EHR,topic:phenotyping,type:research},
mendeley-tags = {rank:90,relevancy:C,topic:EHR,topic:phenotyping,type:research},
number = {E1},
pmid = {23531748},
title = {{Validation of electronic medical record-based phenotyping algorithms: Results and lessons learned from the eMERGE network}},
volume = {20},
year = {2013}
}
@article{Kleinberg2011,
abstract = {Causality is an important concept throughout the health sciences and is particularly vital for informatics work such as finding adverse drug events or risk factors for disease using electronic health records. While philosophers and scientists working for centuries on formalizing what makes something a cause have not reached a consensus, new methods for inference show that we can make progress in this area in many practical cases. This article reviews core concepts in understanding and identifying causality and then reviews current computational methods for inference and explanation, focusing on inference from large-scale observational data. While the problem is not fully solved, we show that graphical models and Granger causality provide useful frameworks for inference and that a more recent approach based on temporal logic addresses some of the limitations of these methods. {\textcopyright} 2011 Elsevier Inc.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Kleinberg, Samantha and Hripcsak, George},
doi = {10.1016/j.jbi.2011.07.001},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/Kleinberg, Hripcsak{\_}2011{\_}A review of causal inference for biomedical informatics{\_}Journal of Biomedical Informatics.pdf:pdf},
isbn = {1532-0480 (Linking)},
issn = {15320464},
journal = {Journal of Biomedical Informatics},
keywords = {Causal explanation,Causal inference,Electronic health records,rank:85,relevancy:A,topic:EHR,topic:prediction,type:review},
mendeley-tags = {rank:85,relevancy:A,type:review,topic:EHR,topic:prediction},
number = {6},
pages = {1102--1112},
pmid = {21782035},
publisher = {Elsevier Inc.},
title = {{A review of causal inference for biomedical informatics}},
url = {http://dx.doi.org/10.1016/j.jbi.2011.07.001},
volume = {44},
year = {2011}
}
@article{Okser2013,
abstract = {A central challenge in systems biology and medical genetics is to understand how interactions among genetic loci contribute to complex phenotypic traits and human diseases. While most studies have so far relied on statistical modeling and association testing procedures, machine learning and predictive modeling approaches are increasingly being applied to mining genotype-phenotype relationships, also among those associations that do not necessarily meet statistical significance at the level of individual variants, yet still contributing to the combined predictive power at the level of variant panels. Network-based analysis of genetic variants and their interaction partners is another emerging trend by which to explore how sub-network level features contribute to complex disease processes and related phenotypes. In this review, we describe the basic concepts and algorithms behind machine learning-based genetic feature selection approaches, their potential benefits and limitations in genome-wide setting, and how physical or genetic interaction networks could be used as a priori information for providing improved predictive power and mechanistic insights into the disease networks. These developments are geared toward explaining a part of the missing heritability, and when combined with individual genomic profiling, such systems medicine approaches may also provide a principled means for tailoring personalized treatment strategies in the future.},
author = {Okser, Sebastian and Pahikkala, Tapio and Aittokallio, Tero},
doi = {10.1186/1756-0381-6-5},
file = {:Users/na399/GitHub/thesis/references/papers/Okser, Pahikkala, Aittokallio{\_}2013{\_}Genetic variants and their interactions in disease risk prediction - Machine learning and network per.pdf:pdf},
isbn = {1756-0381 (Electronic)$\backslash$r1756-0381 (Linking)},
issn = {17560381},
journal = {BioData Mining},
keywords = {rank:70,relevancy:C},
mendeley-tags = {rank:70,relevancy:C},
number = {1},
pages = {1--16},
pmid = {23448398},
title = {{Genetic variants and their interactions in disease risk prediction - Machine learning and network perspectives}},
volume = {6},
year = {2013}
}
@article{CHENG2017,
abstract = {Chronic diseases have been among the major concerns in medical fields since they may cause heavy burden on healthcare resources and disturb the quality of life. In this paper, we propose a novel framework for early assessment on chronic diseases by mining sequential risk patterns with time interval information from diagnostic clinical records using sequential rules mining and classification modeling techniques. With a complete workflow, the proposed framework consists of four phases namely data preprocessing, risk pattern mining, classification modeling and post analysis. For empirical evaluation, we demonstrate the effectiveness of our proposed framework with a case study on early assessment of COPD. Through experimental evaluation on a large-scale nationwide clinical database in Taiwan, our approach can not only derive rich sequential risk patterns but also extract novel patterns with valuable insights for further medical investigation such as discovering novel markers and better treatments. To the best of our knowledge, this is the first work addressing the issue of mining sequential risk patterns with time-intervals as well as classification models for early assessment of chronic diseases.},
author = {CHENG, YITING and Lin, Yu-Feng and Chiang, Kuo-Hwa and Tseng, Vincent},
doi = {10.1109/JBHI.2017.2657802},
file = {:Users/na399/GitHub/thesis/references/papers/CHENG et al.{\_}2017{\_}Mining Sequential Risk Patterns from Large-Scale Clinical Databases for Early Assessment of Chronic Diseases A Case St.pdf:pdf},
isbn = {2168-2194 VO - 21},
issn = {2168-2194},
journal = {IEEE Journal of Biomedical and Health Informatics},
keywords = {disease:COPD,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:COPD,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
number = {2},
pages = {1--1},
pmid = {28129195},
title = {{Mining Sequential Risk Patterns from Large-Scale Clinical Databases for Early Assessment of Chronic Diseases: A Case Study on Chronic Obstructive Pulmonary Disease}},
url = {http://ieeexplore.ieee.org/document/7833052/},
volume = {21},
year = {2017}
}
@article{Bouayad2017,
abstract = {Background: A new generation of user-centric information systems is emerging in health care as patient health record (PHR) systems. These systems create a platform supporting the new vision of health services that empowers patients and enables patient-provider communication, with the goal of improving health outcomes and reducing costs. This evolution has generated new sets of data and capabilities, providing opportunities and challenges at the user, system, and industry levels. Objective: The objective of our study was to assess PHR data types and functionalities through a review of the literature to inform the health care informatics community, and to provide recommendations for PHR design, research, and practice. Methods: We conducted a review of the literature to assess PHR data types and functionalities. We searched PubMed, Embase, and MEDLINE databases from 1966 to 2015 for studies of PHRs, resulting in 1822 articles, from which we selected a total of 106 articles for a detailed review of PHR data content. Results: We present several key findings related to the scope and functionalities in PHR systems. We also present a functional taxonomy and chronological analysis of PHR data types and functionalities, to improve understanding and provide insights for future directions. Functional taxonomy analysis of the extracted data revealed the presence of new PHR data sources such as tracking devices and data types such as time-series data. Chronological data analysis showed an evolution of PHR system functionalities over time, from simple data access to data modification and, more recently, automated assessment, prediction, and recommendation. Conclusions: Efforts are needed to improve (1) PHR data quality through patient-centered user interface design and standardized patient-generated data guidelines, (2) data integrity through consolidation of various types and sources, (3) PHR functionality through application of new data analytics methods, and (4) metrics to evaluate clinical outcomes associated with automated PHR system use, and costs associated with PHR data storage and analytics. [J Med Internet Res 2017;19(11):e388]},
author = {Bouayad, Lina and Ialynytchev, Anna and Padmanabhan, Balaji},
doi = {10.2196/jmir.8073},
file = {:Users/na399/GitHub/thesis/references/papers/Bouayad, Ialynytchev, Padmanabhan{\_}2017{\_}Patient health record systems scope and functionalities Literature review and future directions{\_}J.pdf:pdf},
issn = {14388871},
journal = {Journal of Medical Internet Research},
keywords = {Data analytics,Electronic health records,Health platforms,Health records, personal,Medical informatics,Multiorganizational systems,Patient-centered care,Personal health record systems,Review,Ultralarge systems,personal,rank:95,relevancy:C,topic:EHR,type:review},
mendeley-tags = {rank:95,relevancy:C,topic:EHR,type:review},
number = {11},
pages = {1--14},
pmid = {29141839},
title = {{Patient health record systems scope and functionalities: Literature review and future directions}},
volume = {19},
year = {2017}
}
@article{Nikovski2000,
author = {Nikovski, Daniel},
doi = {10.1109/69.868904},
file = {:Users/na399/GitHub/thesis/references/papers/Nikovski{\_}2000{\_}Constructing Bayesian networks for medical diagnosis from incomplete and partially correct statistics{\_}IEEE Transactions on.pdf:pdf},
issn = {10414347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
keywords = {model:Bayesian,rank:95,relevancy:A,type:education},
mendeley-tags = {model:Bayesian,rank:95,relevancy:A,type:education},
number = {4},
pages = {509--516},
title = {{Constructing Bayesian networks for medical diagnosis from incomplete and partially correct statistics}},
url = {http://ieeexplore.ieee.org/document/868904/},
volume = {12},
year = {2000}
}
@article{Silva2017,
abstract = {Most bioinformatics tools available today were not written by professional software developers, but by people that wanted to solve their own problems, using computational solutions and spending the minimum time and effort possible, since these were just the means to an end. Consequently, a vast number of software applications are currently available, hindering the task of identifying the utility and quality of each. At the same time, this situation has hindered regular adoption of these tools in clinical practice. Typically, they are not sufficiently developed to be used by most clinical researchers and practitioners. To address these issues, it is necessary to re-think how biomedical applications are built and adopt new strategies that ensure quality, efficiency, robustness, correctness and reusability of software components. We also need to engage end-users during the development process to ensure that applications fit their needs. In this review, we present a set of guidelines to support biomedical software development, with an explanation of how they can be implemented and what kind of open-source tools can be used for each specific topic.},
author = {Silva, Luis Bastiao and Jimenez, Rafael C. and Blomberg, Niklas and {Luis Oliveira}, Jos{\'{e}}},
doi = {10.12688/f1000research.10750.2},
file = {:Users/na399/GitHub/thesis/references/papers/Silva et al.{\_}2017{\_}General guidelines for biomedical software development{\_}F1000Research.pdf:pdf},
isbn = {2046-1402},
issn = {2046-1402},
journal = {F1000Research},
keywords = {rank:60,relevancy:B},
mendeley-tags = {rank:60,relevancy:B},
number = {0},
pages = {273},
pmid = {28443186},
title = {{General guidelines for biomedical software development}},
url = {https://f1000research.com/articles/6-273/v2},
volume = {6},
year = {2017}
}
@article{Land2016,
abstract = {Bayesian networks (BNs) have classically been designed by two methods: expert approach (ask an expert for nodes and links) and data driven approach (infer them from data). An unexpected by-product of previous Alzheimer's / dementia research (presented at CAS2015) was yet another approach where the results of a hybrid design were used to configure a BN. A complex adaptive systems approach, (e.g. GA-SVM-oracle hybrid) can sift through the combinatorics of feature subset selection, yielding a modest set of only the most influential features. Then using known likelihoods of demographics associated to dementia, and assuming direct and independent influence of dementia upon speech features, the BN is specified. The conditional probabilities needed can be estimated with far fewer data than the traditional BN data-driven approach. Although BNs have advantages (intuitive interpretation and graceful handling of missing data) they also have challenges. We report initial implementation results that suggest the need to reduce continuous variables to discrete categories, and the still-remaining need to estimate a substantial number of conditional probabilities, remain challenges for BNs. We suggest some ways forward in the application of BNs with the objective of improving / refining Alzheimer's / dementia detection using speech.},
author = {Land, Walker H. and Schaffer, J. David},
doi = {10.1016/j.procs.2016.09.308},
file = {:Users/na399/GitHub/thesis/references/papers/Land, Schaffer{\_}2016{\_}A Machine Intelligence Designed Bayesian Network Applied to Alzheimer's Detection Using Demographics and Speech Data.pdf:pdf},
isbn = {0000000000},
issn = {18770509},
journal = {Procedia Computer Science},
keywords = {Alzheimer's disease diagnosis,Bayesian network,GRNN oracle,Genetic algorithm,Speech,Support vector machine,disease:dementia,model:Bayesian,rank:55,relevancy:A},
mendeley-tags = {rank:55,relevancy:A,disease:dementia,model:Bayesian},
pages = {168--174},
publisher = {Elsevier Masson SAS},
title = {{A Machine Intelligence Designed Bayesian Network Applied to Alzheimer's Detection Using Demographics and Speech Data}},
url = {http://dx.doi.org/10.1016/j.procs.2016.09.308 http://linkinghub.elsevier.com/retrieve/pii/S1877050916324814},
volume = {95},
year = {2016}
}
@article{Powell2017,
abstract = {Within population health information systems, indicators are commonly presented as independent, cross-sectional measures, neglecting the multivariate, longitudinal nature of disease progression, health care use, and profiles of performance. We use administrative claims data of Montreal, Canada to identify patterns across indicators and over time in chronic obstructive pulmonary disease patients. We first cluster regions based on four health service indicators. Our second approach discovers individual-level trajectories based on a hidden Markov model using the same four indicators. Both approaches offer additional insights by facilitating the discovery and interpretation of indicators, such as a dual interpretation of low use of general practitioner services. These approaches to the analysis and visualization of health indicators can provide a foundation for information displays that will help decision makers identify areas of concern, predict future disease burden, and implement appropriate policies.},
author = {Powell, Guido Antonio and Luo, Yu T and Verma, Aman and Stephens, David A and Buckeridge, David L},
doi = {10.3233/978-1-61499-753-5-266},
file = {:Users/na399/GitHub/thesis/references/papers/Powell et al.{\_}2017{\_}Multivariate and Longitudinal Health System Indicators.{\_}Studies in health technology and informatics.pdf:pdf},
isbn = {9781614997535},
issn = {0926-9630 (Print)},
journal = {Studies in Health Technology and Informatics},
keywords = {Adult,Aged,Chronic Obstructive,Cross-Sectional Studies,Female,Health Care,Health Information Systems,Humans,Longitudinal Studies,Male,Markov Chains,Middle Aged,Multivariate Analysis,Patient Acceptance of Health Care,Pulmonary Disease,Quality Assurance,Quebec,methods,organization {\&} administration,rank:10,relevancy:C,statistics {\&} numerical  data,statistics {\&} numerical data,therapy},
mendeley-tags = {rank:10,relevancy:C},
pages = {266--270},
pmid = {28423795},
title = {{Multivariate and Longitudinal Health System Indicators.}},
volume = {235},
year = {2017}
}
@article{Pathak2013,
author = {Pathak, Jyotishman and Kho, Abel N and Denny, Joshua C},
doi = {10.1136/amiajnl-2013-002428},
file = {:Users/na399/GitHub/thesis/references/papers/Pathak, Kho, Denny{\_}2013{\_}Electronic health records-driven phenotyping challenges, recent advances, and perspectives{\_}Journal of the Americ.pdf:pdf},
issn = {1067-5027},
journal = {Journal of the American Medical Informatics Association},
keywords = {rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:commentary},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,topic:phenotyping,type:commentary},
month = {dec},
number = {e2},
pages = {e206--e211},
title = {{Electronic health records-driven phenotyping: challenges, recent advances, and perspectives}},
url = {https://academic.oup.com/jamia/article-lookup/doi/10.1136/amiajnl-2013-002428},
volume = {20},
year = {2013}
}
@article{Pavon2014,
abstract = {OBJECTIVE: To use electronic health record (EHR) data to examine the association between inpatient medication exposure and risk of hospital readmission.$\backslash$n$\backslash$nDESIGN: Retrospective, observational study.$\backslash$n$\backslash$nSETTING: Tertiary and quaternary care academic health system in Durham, North Carolina.$\backslash$n$\backslash$nPARTICIPANTS: All individuals aged 60 and older who were residents of Durham County, North Carolina and were hospitalized and discharged alive from Duke University Hospital between 2007 and 2009 (N = 4,627).$\backslash$n$\backslash$nMEASUREMENTS: Independent variables were inpatient exposure to individual medication classes. Primary outcome was readmission to a Duke Health System hospital within 30 days.$\backslash$n$\backslash$nRESULTS: Readmission rate was 21{\%} (n = 955). In adjusted models, exposure to anticonvulsants (odds ratio OR 1.26, 95{\%} confidence interval (CI) = 1.08-1.48), benzodiazepines (OR = 1.23, 95{\%} CI = 1.04-1.44), corticosteroids (OR = 1.26, 95{\%} CI = 1.07-1.50), and opioids (OR = 1.25, 95{\%} CI = 1.06-1.47) was associated with greater likelihood of readmission. Exposure to antidepressants (OR = 1.85, 95{\%} CI = 1.16-2.96) and opioids on the cardiology service (OR = 1.76, 95{\%} CI = 1.01-3.07) and exposure to opioids on the medicine service (OR = 1.94, 95{\%} CI = 1.17-3.22) were associated with greater odds of readmission than for individuals on the surgery service.$\backslash$n$\backslash$nCONCLUSION: Exposure of hospitalized elderly adults to certain medication classes was associated with greater likelihood of readmission. Incorporating medication data from EHRs may improve the performance of hospital readmission prediction models.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Pavon, Juliessa M. and Zhao, Yanfang and McConnell, Eleanor and Hastings, S. Nicole},
doi = {10.1111/jgs.12829},
eprint = {NIHMS150003},
file = {:Users/na399/GitHub/thesis/references/papers/Pavon et al.{\_}2014{\_}Identifying risk of readmission in hospitalized elderly adults through inpatient medication exposure{\_}Journal of the Am.pdf:pdf},
isbn = {0002-8614},
issn = {15325415},
journal = {Journal of the American Geriatrics Society},
keywords = {electronic health record,medications,rank:75,readmissions,relevancy:C},
mendeley-tags = {rank:75,relevancy:C},
number = {6},
pages = {1116--1121},
pmid = {24802165},
title = {{Identifying risk of readmission in hospitalized elderly adults through inpatient medication exposure}},
volume = {62},
year = {2014}
}
@article{Connolly2011,
abstract = {OBJECTIVES: Dementia is a major and growing health problem. Diagnosis is an important step in the access to care, but many dementia patients remain undiagnosed. This study investigated the magnitude and variation in the difference between 'observed' and 'estimated' prevalence of dementia in general practices. We also explored practice characteristics associated with observed prevalence rates. METHOD: Six Primary Care Trusts (PCTs) provided data on all general practices (N = 351) in their area in terms of number of doctors, patient list size, number of patients over 65 years of age, socio-economic deprivation status of practices and number of patients on dementia registers. RESULTS: The average observed prevalence overall of dementia amongst patients 65 years and over was 3.0{\%} [95CI 2.8, 3.2]. The observed prevalence was 54.5{\%} [95CI 49.2, 58.9] lower than the prevalence observed in the epidemiological studies in the UK. For an average size general practice (list size of 5269 patients) approximately 27 [95CI 22, 32] patients with dementia may remain undiagnosed. Statistically significant differences in prevalence rates were found between the different PCTs (Wald chi-square = 103.8 p {\textless} 0.001). The observed prevalence of dementia was significantly lower among practices run by one GP compared to multiple GPs (p = 0.003), and in more affluent areas (p {\textless} 0.001). CONCLUSION: Just under a half of the expected numbers of patients with dementia are recognised in GP dementia registers. The underdiagnosis of dementia varies with practice characteristics, socio-economic deprivation and between PCTs, which has implications for the local implementation of the National Dementia Strategy.},
author = {Connolly, Amanda and Gaehl, Ella and Martin, Helen and Morris, Julie and Purandare, Nitin},
doi = {10.1080/13607863.2011.596805},
file = {:Users/na399/GitHub/thesis/references/papers/Connolly et al.{\_}2011{\_}Underdiagnosis of dementia in primary care Variations in the observed prevalence and comparisons to the expected pr.pdf:pdf},
isbn = {1360-7863$\backslash$n1364-6915},
issn = {13607863},
journal = {Aging and Mental Health},
keywords = {Dementia,Diagnosis,General practice,Prevalence,Variations,disease:dementia,rank:80,relevancy:B},
mendeley-tags = {rank:80,relevancy:B,disease:dementia},
number = {8},
pages = {978--984},
pmid = {21777080},
title = {{Underdiagnosis of dementia in primary care: Variations in the observed prevalence and comparisons to the expected prevalence}},
volume = {15},
year = {2011}
}
@article{Bandyopadhyay2015,
abstract = {Models for predicting the risk of cardiovascular events based on individual patient characteristics are important tools for managing patient care. Most current and commonly used risk prediction models have been built from carefully selected epidemiological cohorts. However, the homogeneity and limited size of such cohorts restricts the predictive power and generalizability of these risk models to other populations. Electronic health data (EHD) from large health care systems provide access to data on large, heterogeneous, and contemporaneous patient populations. The unique features and challenges of EHD, including missing risk factor information, non-linear relationships between risk factors and cardiovascular event outcomes, and differing effects from different patient subgroups, demand novel machine learning approaches to risk model development. In this paper, we present a machine learning approach based on Bayesian networks trained on EHD to predict the probability of having a cardiovascular event within five years. In such data, event status may be unknown for some individuals as the event time is right-censored due to disenrollment and incomplete follow-up. Since many traditional data mining methods are not well-suited for such data, we describe how to modify both modelling and assessment techniques to account for censored observation times. We show that our approach can lead to better predictive performance than the Cox proportional hazards model (i.e., a regression-based approach commonly used for censored, time-to-event data) or a Bayesian network with {\{}$\backslash$em{\{}ad hoc{\}}{\}} approaches to right-censoring. Our techniques are motivated by and illustrated on data from a large U.S. Midwestern health care system.},
archivePrefix = {arXiv},
arxivId = {1404.2189},
author = {Bandyopadhyay, Sunayan and Wolfson, Julian and Vock, David M. and Vazquez-Benitez, Gabriela and Adomavicius, Gediminas and Elidrisi, Mohamed and Johnson, Paul E. and O'Connor, Patrick J.},
doi = {10.1007/s10618-014-0386-6},
eprint = {1404.2189},
file = {:Users/na399/GitHub/thesis/references/papers/Bandyopadhyay et al.{\_}2015{\_}Data mining for censored time-to-event data a Bayesian network model for predicting cardiovascular risk from e.pdf:pdf},
isbn = {1061801403},
issn = {1384-5810},
journal = {Data Mining and Knowledge Discovery},
keywords = {Bayesian networks,Electronic health data,Inverse probability of censoring weights,Medical decision support,Mining censored data,Risk prediction,Survival analysis,disease:CVD,model:Bayesian,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:CVD,model:Bayesian,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
month = {jul},
number = {4},
pages = {1033--1069},
publisher = {Springer US},
title = {{Data mining for censored time-to-event data: a Bayesian network model for predicting cardiovascular risk from electronic health record data}},
url = {http://dx.doi.org/10.1007/s10618-014-0386-6 http://link.springer.com/10.1007/s10618-014-0386-6},
volume = {29},
year = {2015}
}
@article{Bermingham2015,
abstract = {In this study, we investigated the effect of five feature selection approaches on the performance of a mixed model (G-BLUP) and a Bayesian (Bayes C) prediction method. We predicted height, high density lipoprotein cholesterol (HDL) and body mass index (BMI) within 2,186 Croatian and into 810 UK individuals using genome-wide SNP data. Using all SNP information Bayes C and G-BLUP had similar predictive performance across all traits within the Croatian data, and for the highly polygenic traits height and BMI when predicting into the UK data. Bayes C outperformed G-BLUP in the prediction of HDL, which is influenced by loci of moderate size, in the UK data. Supervised feature selection of a SNP subset in the G-BLUP framework provided a flexible, generalisable and computationally efficient alternative to Bayes C; but careful evaluation of predictive performance is required when supervised feature selection has been used.},
author = {Bermingham, M. L. and Pong-Wong, R. and Spiliopoulou, A. and Hayward, C. and Rudan, I. and Campbell, H. and Wright, A. F. and Wilson, J. F. and Agakov, F. and Navarro, P. and Haley, C. S.},
doi = {10.1038/srep10312},
file = {:Users/na399/GitHub/thesis/references/papers/Bermingham et al.{\_}2015{\_}Application of high-dimensional feature selection Evaluation for genomic prediction in man{\_}Scientific Reports.pdf:pdf},
isbn = {doi:10.1038/srep10312},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {disease:general,model:Bayesian,rank:95,relevancy:A,topic:GWAS,topic:bioinformatics,topic:prediction,type:research},
mendeley-tags = {disease:general,model:Bayesian,rank:95,relevancy:A,topic:GWAS,topic:bioinformatics,topic:prediction,type:research},
month = {sep},
number = {1},
pages = {10312},
pmid = {25988841},
publisher = {Nature Publishing Group},
title = {{Application of high-dimensional feature selection: evaluation for genomic prediction in man}},
url = {http://dx.doi.org/10.1038/srep10312 http://www.nature.com/articles/srep10312},
volume = {5},
year = {2015}
}
@inproceedings{Osuala2017,
abstract = {The increasing trend of systematic collection of medical data (diagnoses, hospital admission emergencies, blood test results, scans etc) by health care providers offers an unprecedented opportunity for the application of modern data mining, pattern recognition, and machine learning algorithms. The ultimate aim is invariably that of improving outcomes, be it directly or indirectly. Notwithstanding the successes of recent research efforts in this realm, a major obstacle of making the developed models usable by medical professionals (rather than computer scientists or statisticians) remains largely unaddressed. Yet, a mounting amount of evidence shows that the ability to understanding and easily use novel technologies is a major factor governing how widely adopted by the target users (doctors, nurses, and patients, amongst others) they are likely to be. In this work we address this technical gap. In particular, we describe a portable, web based interface that allows health care professionals to interact with recently developed machine learning and data driven prognostic algorithms. Our application interfaces a statistical disease progression model and displays its predictions in an intuitive and readily understandable manner. Different types of geometric primitives and their visual properties (such as size or colour), are used to represent abstract quantities such as probability density functions, the rate of change of relative probabilities, and a series of other relevant statistics which the heath care professional can use to explore patients' risk factors or provide personalized, evidence and data driven incentivization to the patient.},
author = {Osuala, Richard and Arandjelovic, Ognjen},
booktitle = {2017 IEEE EMBS International Conference on Biomedical {\&} Health Informatics (BHI)},
doi = {10.1109/BHI.2017.7897250},
file = {:Users/na399/GitHub/thesis/references/papers/Osuala, Arandjelovic, Ieee{\_}2017{\_}Visualization of Patient Specific Disease Risk Prediction{\_}2017 Ieee Embs International Conference on Bio.pdf:pdf},
isbn = {978-1-5090-4179-4},
keywords = {rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
number = {3},
pages = {241--244},
publisher = {IEEE},
title = {{Visualization of patient specific disease risk prediction}},
url = {http://ieeexplore.ieee.org/document/7897250/},
year = {2017}
}
@article{Goldstein2017,
abstract = {An increasingly important data source for the development of clinical risk prediction models is electronic health records (EHRs). One of their key advantages is that they contain data on many individuals collected over time. This allows one to incorporate more clinical information into a risk model. However, traditional methods for developing risk models are not well suited to these irregularly collected clinical covariates. In this paper, we compare a range of approaches for using longitudinal predictors in a clinical risk model. Using data from an EHR for patients undergoing hemodialysis, we incorporate five different clinical predictors into a risk model for patient mortality. We consider different approaches for treating the repeated measurements including use of summary statistics, machine learning methods, functional data analysis, and joint models. We follow up our empirical findings with a simulation study. Overall, our results suggest that simple approaches perform just as well, if not better, than more complex analytic approaches. These results have important implication for development of risk prediction models with EHRs. Copyright {\textcopyright} 2017 John Wiley {\&} Sons, Ltd.},
author = {Goldstein, Benjamin A. and Pomann, Gina Maria and Winkelmayer, Wolfgang C. and Pencina, Michael J.},
doi = {10.1002/sim.7308},
file = {:Users/na399/GitHub/thesis/references/papers/Goldstein et al.{\_}2017{\_}A comparison of risk prediction methods using repeated observations an application to electronic health records fo.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {clinical risk prediction,electronic health records,end-stage renal disease,functional data analysis,hemodialysis,joint models,longitudinal data,rank:90,relevancy:B,topic:EHR,topic:prediction,type:research},
mendeley-tags = {rank:90,relevancy:B,topic:EHR,topic:prediction,type:research},
number = {17},
pages = {2750--2763},
pmid = {28464332},
title = {{A comparison of risk prediction methods using repeated observations: an application to electronic health records for hemodialysis}},
volume = {36},
year = {2017}
}
@article{Chen2017,
abstract = {With big data growth in biomedical and healthcare communities, accurate analysis of medical data benefits early disease detection, patient care, and community services. However, the analysis accuracy is reduced when the quality of medical data is incomplete. Moreover, different regions exhibit unique characteristics of certain regional diseases, which may weaken the prediction of disease outbreaks. In this paper, we streamline machine learning algorithms for effective prediction of chronic disease outbreak in disease-frequent communities. We experiment the modified prediction models over real-life hospital data collected from central China in 2013–2015. To overcome the difficulty of incomplete data, we use a latent factor model to reconstruct the missing data. We experiment on a regional chronic disease of cerebral infarction. We propose a new convolutional neural network (CNN)-based multimodal disease risk prediction algorithm using structured and unstructured data from hospital. To the best of our knowledge, none of the existing work focused on both data types in the area of medical big data analytics. Compared with several typical prediction algorithms, the prediction accuracy of our proposed algorithm reaches 94.8{\%} with a convergence speed, which is faster than that of the CNN-based unimodal disease risk prediction algorithm.},
author = {Chen, Min and Hao, Yixue and Hwang, Kai and Wang, Lu and Wang, Lin},
doi = {10.1109/ACCESS.2017.2694446},
file = {:Users/na399/GitHub/thesis/references/papers/Chen et al.{\_}2017{\_}Disease Prediction by Machine Learning Over Big Data From Healthcare Communities{\_}IEEE Access.pdf:pdf},
issn = {2169-3536},
journal = {IEEE Access},
keywords = {INDEX TERMS Big data analytics,disease:CVD,healthcare,machine learning,model:DeepLearning,rank:95,relevancy:B,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:CVD,model:DeepLearning,rank:95,relevancy:B,topic:EHR,topic:prediction,type:research},
pages = {8869--8879},
title = {{Disease Prediction by Machine Learning Over Big Data From Healthcare Communities}},
url = {http://ieeexplore.ieee.org/document/7912315/},
volume = {5},
year = {2017}
}
@article{Jensen2017,
abstract = {With an aging patient population and increasing complexity in patient disease trajectories, physicians are often met with complex patient histories from which clinical decisions must be made. Due to the increasing rate of adverse events and hospitals facing financial penalties for readmission, there has never been a greater need to enforce evidence-led medical decision-making using available health care data. In the present work, we studied a cohort of 7,741 patients, of whom 4,080 were diagnosed with cancer, surgically treated at a University Hospital in the years 2004-2012. We have developed a methodology that allows disease trajectories of the cancer patients to be estimated from free text in electronic health records (EHRs). By using these disease trajectories, we predict 80{\%} of patient events ahead in time. By control of confounders from 8326 quantified events, we identified 557 events that constitute high subsequent risks (risk {\textgreater} 20{\%}), including six events for cancer and seven events for metastasis. We believe that the presented methodology and findings could be used to improve clinical decision support and personalize trajectories, thereby decreasing adverse events and optimizing cancer treatment.},
author = {Jensen, Kasper and Soguero-Ruiz, Cristina and {Oyvind Mikalsen}, Karl and Lindsetmo, Rolv-Ole and Kouskoumvekaki, Irene and Girolami, Mark and {Olav Skrovseth}, Stein and {Magne Augestad}, Knut},
doi = {10.1038/srep46226},
file = {:Users/na399/GitHub/thesis/references/papers/Jensen et al.{\_}2017{\_}Analysis of free text in electronic health records for identification of cancer patient trajectories{\_}Scientific Repor.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {disease:cancer,model:NLP,rank:95,relevancy:A,topic:EHR,topic:prediction,topic:trajectory,type:research},
mendeley-tags = {disease:cancer,model:NLP,rank:95,relevancy:A,topic:EHR,topic:prediction,topic:trajectory,type:research},
month = {apr},
pages = {46226},
pmid = {28387314},
publisher = {Nature Publishing Group},
title = {{Analysis of free text in electronic health records for identification of cancer patient trajectories}},
url = {http://www.nature.com/articles/srep46226},
volume = {7},
year = {2017}
}
@article{Rotmensch2017,
abstract = {Demand for clinical decision support systems in medicine and self-diagnostic symptom checkers has substantially increased in recent years. Existing platforms rely on knowledge bases manually compiled through a labor-intensive process or automatically derived using simple pairwise statistics. This study explored an automated process to learn high quality knowledge bases linking diseases and symptoms directly from electronic medical records. Medical concepts were extracted from 273,174 de-identified patient records and maximum likelihood estimation of three probabilistic models was used to automatically construct knowledge graphs: logistic regression, naive Bayes classifier and a Bayesian network using noisy OR gates. A graph of disease-symptom relationships was elicited from the learned parameters and the constructed knowledge graphs were evaluated and validated, with permission, against Google's manually-constructed knowledge graph and against expert physician opinions. Our study shows that direct and automated construction of high quality health knowledge graphs from medical records using rudimentary concept extraction is feasible. The noisy OR model produces a high quality knowledge graph reaching precision of 0.85 for a recall of 0.6 in the clinical evaluation. Noisy OR significantly outperforms all tested models across evaluation frameworks (p {\textless} 0.01).},
author = {Rotmensch, Maya and Halpern, Yoni and Tlimat, Abdulhakim and Horng, Steven and Sontag, David},
doi = {10.1038/s41598-017-05778-z},
file = {:Users/na399/GitHub/thesis/references/papers/Rotmensch et al.{\_}2017{\_}Learning a Health Knowledge Graph from Electronic Medical Records{\_}Scientific Reports.pdf:pdf},
isbn = {4159801705778},
issn = {20452322},
journal = {Scientific Reports},
keywords = {disease:general,model:Bayesian,model:NLP,model:logisticRegression,model:naiveBayes,model:network,rank:95,relevancy:A,topic:CDSS,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:general,model:Bayesian,model:NLP,model:logisticRegression,model:naiveBayes,model:network,rank:95,relevancy:A,topic:CDSS,topic:EHR,topic:prediction,type:research},
number = {1},
pages = {1--11},
pmid = {28729710},
publisher = {Springer US},
title = {{Learning a Health Knowledge Graph from Electronic Medical Records}},
url = {http://dx.doi.org/10.1038/s41598-017-05778-z},
volume = {7},
year = {2017}
}
@article{Wang2014c,
author = {Wang, Xiang and Wang, Fei},
file = {:Users/na399/GitHub/thesis/references/papers/Wang, Wang{\_}2014{\_}Unsupervised Learning of Disease Progression Models{\_}Unknown.pdf:pdf},
isbn = {9781450329569},
keywords = {bayesian network,disease progression,markov jump process,medical informatics,modeling,rank:n/a,relevancy:B},
mendeley-tags = {rank:n/a,relevancy:B},
title = {{Unsupervised Learning of Disease Progression Models}},
year = {2014}
}
@article{Escudie2017,
abstract = {Background: Data collected in EHRs have been widely used to identifying specific conditions; however there is still a need for methods to define comorbidities and sources to identify comorbidities burden. We propose an approach to assess comorbidities burden for a specific disease using the literature and EHR data sources in the case of autoimmune diseases in celiac disease (CD). Methods: We generated a restricted set of comorbidities using the literature (via the MeSH{\textregistered} co-occurrence file). We extracted the 15 most co-occurring autoimmune diseases of the CD. We used mappings of the comorbidities to EHR terminologies: ICD-10 (billing codes), ATC (drugs) and UMLS (clinical reports). Finally, we extracted the concepts from the different data sources. We evaluated our approach using the correlation between prevalence estimates in our cohort and co-occurrence ranking in the literature. Results: We retrieved the comorbidities for 741 patients with CD. 18.1{\%} of patients had at least one of the 15 studied autoimmune disorders. Overall, 79.3{\%} of the mapped concepts were detected only in text, 5.3{\%} only in ICD codes and/or drugs prescriptions, and 15.4{\%} could be found in both sources. Prevalence in our cohort were correlated with literature (Spearman's coefficient 0.789, p = 0.0005). The three most prevalent comorbidities were thyroiditis 12.6{\%} (95{\%} CI 10.1-14.9), type 1 diabetes 2.3{\%} (95{\%} CI 1.2-3.4) and dermatitis herpetiformis 2.0{\%} (95{\%} CI 1.0-3.0). Conclusion: We introduced a process that leveraged the MeSH terminology to identify relevant autoimmune comorbidities of the CD and several data sources from EHRs to phenotype a large population of CD patients. We achieved prevalence estimates comparable to the literature. {\textcopyright} 2017 The Author(s).},
author = {Escudi{\'{e}}, Jean Baptiste and Rance, Bastien and Malamut, Georgia and Khater, Sherine and Burgun, Anita and Cellier, Christophe and Jannot, Anne Sophie},
doi = {10.1186/s12911-017-0537-y},
file = {:Users/na399/GitHub/thesis/references/papers/Escudi{\'{e}} et al.{\_}2017{\_}A novel data-driven workflow combining literature and electronic health records to estimate comorbidities burden fo.pdf:pdf},
isbn = {1291101705},
issn = {14726947},
journal = {BMC Medical Informatics and Decision Making},
keywords = {Addison disease,Antiphospholipid syndrome,Arthritis juvenile,Arthritis rheumatoid,Autoimmune diseases,Celiac disease,Dermatitis herpetiformis,Diabetes mellitus type 1,Electronic health records,Graves' disease,Hepatitis autoimmune,Icd 10,Lupus erythematosus systemic,Multiple sclerosis,Myasthenia gravis,Phenotype,Polyendocrinopathies autoimmune,Prevalence study,Sjogren's syndrome,Thyroiditis autoimmune,rank:80,relevancy:B},
mendeley-tags = {rank:80,relevancy:B},
number = {1},
pages = {1--10},
pmid = {28962565},
publisher = {BMC Medical Informatics and Decision Making},
title = {{A novel data-driven workflow combining literature and electronic health records to estimate comorbidities burden for a specific disease: A case study on autoimmune comorbidities in patients with celiac disease}},
volume = {17},
year = {2017}
}
@article{Wolfson2015,
abstract = {Predicting an individual's risk of experiencing a future clinical outcome is a statistical task with important consequences for both practicing clinicians and public health experts. Modern observational databases such as electronic health records provide an alternative to the longitudinal cohort studies traditionally used to construct risk models, bringing with them both opportunities and challenges. Large sample sizes and detailed covariate histories enable the use of sophisticated machine learning techniques to uncover complex associations and interactions, but observational databases are often 'messy', with high levels of missing data and incomplete patient follow-up. In this paper, we propose an adaptation of the well-known Naive Bayes machine learning approach to time-to-event outcomes subject to censoring. We compare the predictive performance of our method with the Cox proportional hazards model which is commonly used for risk prediction in healthcare populations, and illustrate its application to prediction of cardiovascular risk using an electronic health record dataset from a large Midwest integrated healthcare system.},
archivePrefix = {arXiv},
arxivId = {1404.2124},
author = {Wolfson, Julian and Bandyopadhyay, Sunayan and Elidrisi, Mohamed and Vazquez-Benitez, Gabriela and Vock, David M. and Musgrove, Donald and Adomavicius, Gediminas and Johnson, Paul E. and O'Connor, Patrick J.},
doi = {10.1002/sim.6526},
eprint = {1404.2124},
file = {:Users/na399/GitHub/thesis/references/papers/Wolfson et al.{\_}2015{\_}A Naive Bayes machine learning approach to risk prediction using censored, time-to-event data{\_}Statistics in Medicine.pdf:pdf},
isbn = {0324141122},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Electronic health records,Machine learning,Naive Bayes,Risk prediction,Survival analysis,disease:CVD,model:naiveBayes,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
mendeley-tags = {disease:CVD,model:naiveBayes,rank:90,relevancy:A,topic:EHR,topic:prediction,type:research},
number = {21},
pages = {2941--2957},
pmid = {25980520},
title = {{A Naive Bayes machine learning approach to risk prediction using censored, time-to-event data}},
volume = {34},
year = {2015}
}
@article{Richesson2013,
abstract = {Widespread sharing of data from electronic health records and patient-reported outcomes can strengthen the national capacity for conducting cost-effective clinical trials and allow research to be embedded within routine care delivery. While pragmatic clinical trials (PCTs) have been performed for decades, they now can draw on rich sources of clinical and operational data that are continuously fed back to inform research and practice. The Health Care Systems Collaboratory program, initiated by the NIH Common Fund in 2012, engages healthcare systems as partners in discussing and promoting activities, tools, and strategies for supporting active participation in PCTs. The NIH Collaboratory consists of seven demonstration projects, and seven problem-specific working group 'Cores', aimed at leveraging the data captured in heterogeneous 'real-world' environments for research, thereby improving the efficiency, relevance, and generalizability of trials. Here, we introduce the Collaboratory, focusing on its Phenotype, Data Standards, and Data Quality Core, and present early observations from researchers implementing PCTs within large healthcare systems. We also identify gaps in knowledge and present an informatics research agenda that includes identifying methods for the definition and appropriate application of phenotypes in diverse healthcare settings, and methods for validating both the definition and execution of electronic health records based phenotypes.},
author = {Richesson, Rachel L. and Hammond, W. Ed and Nahm, Meredith and Wixted, Douglas and Simon, Gregory E. and Robinson, Jennifer G. and Bauck, Alan E. and Cifelli, Denise and Smerek, Michelle M. and Dickerson, John and Laws, Reesa L. and Madigan, Rosemary A. and Rusincovitch, Shelley A. and Kluchar, Cynthia and Califf, Robert M.},
doi = {10.1136/amiajnl-2013-001926},
file = {:Users/na399/GitHub/thesis/references/papers/Richesson et al.{\_}2013{\_}Electronic health records based phenotyping in next-generation clinical trials A perspective from the NIH health c.pdf:pdf},
isbn = {1527-974X (Electronic)},
issn = {10675027},
journal = {Journal of the American Medical Informatics Association},
keywords = {rank:90,relevancy:D,topic:EHR,type:commentary},
mendeley-tags = {rank:90,relevancy:D,topic:EHR,type:commentary},
number = {E2},
pmid = {23956018},
title = {{Electronic health records based phenotyping in next-generation clinical trials: A perspective from the NIH health care systems collaboratory}},
volume = {20},
year = {2013}
}
@article{Zhang2017b,
abstract = {Objective To review the current state of science using big data to advance Alzheimer's disease (AD) research and practice. In particular, we analyzed the types of research foci addressed, corresponding methods employed and study findings reported using big data in AD. Method Systematic review was conducted for articles published in PubMed from January 1, 2010 through December 31, 2015. Keywords with AD and big data analytics were used for literature retrieval. Articles were reviewed and included if they met the eligibility criteria. Results Thirty-eight articles were included in this review. They can be categorized into seven research foci: diagnosing AD or mild cognitive impairment (MCI) (n = 10), predicting MCI to AD conversion (n = 13), stratifying risks for AD (n = 5), mining the literature for knowledge discovery (n = 4), predicting AD progression (n = 2), describing clinical care for persons with AD (n = 3), and understanding the relationship between cognition and AD (n = 3). The most commonly used datasets are AD Neuroimaging Initiative (ADNI) (n = 16), electronic health records (EHR) (n = 11), MEDLINE (n = 3), and other research datasets (n = 8). Logistic regression (n = 9) and support vector machine (n = 8) are the most used methods for data analysis. Conclusion Big data are increasingly used to address AD-related research questions. While existing research datasets are frequently used, other datasets such as EHR data provide a unique, yet under-utilized opportunity for advancing AD research.},
author = {Zhang, Rui and Simon, Gyorgy and Yu, Fang},
doi = {10.1016/j.ijmedinf.2017.07.002},
file = {:Users/na399/GitHub/thesis/references/papers/Zhang, Simon, Yu{\_}2017{\_}Advancing Alzheimer's research A review of big data promises{\_}International Journal of Medical Informatics.pdf:pdf},
isbn = {1872-8243 (Electronic) 1386-5056 (Linking)},
issn = {18728243},
journal = {International Journal of Medical Informatics},
keywords = {Alzheimer's disease,Alzheimer's disease neuroimaging initiative,Electronic health records,Healthcare big data,Healthcare data analytics,disease:dementia,rank:85,relevancy:A,topic:EHR,topic:dataMining,type:review},
mendeley-tags = {rank:85,type:review,topic:dataMining,relevancy:A,disease:dementia,topic:EHR},
number = {July},
pages = {48--56},
pmid = {28870383},
publisher = {Elsevier},
title = {{Advancing Alzheimer's research: A review of big data promises}},
url = {http://dx.doi.org/10.1016/j.ijmedinf.2017.07.002},
volume = {106},
year = {2017}
}
